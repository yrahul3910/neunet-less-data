{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ivis import Ivis\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import BatchNormalization, Dense, Activation, Lambdabda\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/e-dom/data/defect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fname = 'ant.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{base_path}/{data_fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wmc</th>\n",
       "      <th>dit</th>\n",
       "      <th>noc</th>\n",
       "      <th>cbo</th>\n",
       "      <th>rfc</th>\n",
       "      <th>lcom</th>\n",
       "      <th>ca</th>\n",
       "      <th>ce</th>\n",
       "      <th>npm</th>\n",
       "      <th>lcom3</th>\n",
       "      <th>...</th>\n",
       "      <th>dam</th>\n",
       "      <th>moa</th>\n",
       "      <th>mfa</th>\n",
       "      <th>cam</th>\n",
       "      <th>ic</th>\n",
       "      <th>cbm</th>\n",
       "      <th>amc</th>\n",
       "      <th>max_cc</th>\n",
       "      <th>avg_cc</th>\n",
       "      <th>bug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>288</td>\n",
       "      <td>6692</td>\n",
       "      <td>352</td>\n",
       "      <td>30</td>\n",
       "      <td>103</td>\n",
       "      <td>0.975471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.558333</td>\n",
       "      <td>6</td>\n",
       "      <td>1.4167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>210</td>\n",
       "      <td>844</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.877404</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.127315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.408163</td>\n",
       "      <td>13</td>\n",
       "      <td>1.4490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>109</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709302</td>\n",
       "      <td>0.157051</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32.115385</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>73</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.705882</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>1200</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>0.848864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.607143</td>\n",
       "      <td>14</td>\n",
       "      <td>2.1964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   wmc  dit  noc  cbo  rfc  lcom   ca  ce  npm     lcom3  ...       dam  moa  \\\n",
       "0  120    1    0  365  288  6692  352  30  103  0.975471  ...  0.594595    5   \n",
       "1   49    4    1   31  210   844    1  30   28  0.877404  ...  1.000000    2   \n",
       "2   26    4    0   12  109   233    1  12   20  0.892000  ...  1.000000    1   \n",
       "3   17    1    0   13   73    82    8   6   10  0.820312  ...  1.000000    0   \n",
       "4   56    2    2   51  169  1200   37  16   35  0.848864  ...  0.875000    2   \n",
       "\n",
       "        mfa       cam  ic  cbm        amc  max_cc  avg_cc  bug  \n",
       "0  0.000000  0.090084   0    0  18.558333       6  1.4167    1  \n",
       "1  0.624000  0.127315   0    0  58.408163      13  1.4490    1  \n",
       "2  0.709302  0.157051   2    2  32.115385       4  1.0769    1  \n",
       "3  0.000000  0.183824   0    0  33.705882       3  0.9412    1  \n",
       "4  0.409639  0.155844   1    5  31.607143      14  2.1964    1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 745 entries, 0 to 744\n",
      "Data columns (total 21 columns):\n",
      "wmc       745 non-null int64\n",
      "dit       745 non-null int64\n",
      "noc       745 non-null int64\n",
      "cbo       745 non-null int64\n",
      "rfc       745 non-null int64\n",
      "lcom      745 non-null int64\n",
      "ca        745 non-null int64\n",
      "ce        745 non-null int64\n",
      "npm       745 non-null int64\n",
      "lcom3     745 non-null float64\n",
      "loc       745 non-null int64\n",
      "dam       745 non-null float64\n",
      "moa       745 non-null int64\n",
      "mfa       745 non-null float64\n",
      "cam       745 non-null float64\n",
      "ic        745 non-null int64\n",
      "cbm       745 non-null int64\n",
      "amc       745 non-null float64\n",
      "max_cc    745 non-null int64\n",
      "avg_cc    745 non-null float64\n",
      "bug       745 non-null int64\n",
      "dtypes: float64(6), int64(15)\n",
      "memory usage: 122.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('bug', axis=1)\n",
    "y = df['bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline deep learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "558/558 [==============================] - 8s 14ms/step - loss: 0.6037 - acc: 0.7330\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 0s 312us/step - loss: 0.5934 - acc: 0.7867\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 0s 300us/step - loss: 0.5751 - acc: 0.7832\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 0s 379us/step - loss: 0.5687 - acc: 0.7921\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 0s 321us/step - loss: 0.5706 - acc: 0.8082\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 0s 361us/step - loss: 0.5664 - acc: 0.7867\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 0s 366us/step - loss: 0.5477 - acc: 0.7957\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 0s 316us/step - loss: 0.5555 - acc: 0.7939\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 0s 349us/step - loss: 0.5588 - acc: 0.7778\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 0s 366us/step - loss: 0.5428 - acc: 0.7921\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 0s 321us/step - loss: 0.5334 - acc: 0.8029\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 0s 332us/step - loss: 0.5363 - acc: 0.7975\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 0s 331us/step - loss: 0.5539 - acc: 0.7832\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 0.5276 - acc: 0.8082\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 0.5164 - acc: 0.8136\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 0s 350us/step - loss: 0.5252 - acc: 0.7921\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 0s 341us/step - loss: 0.5203 - acc: 0.8154\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 0s 362us/step - loss: 0.5274 - acc: 0.7921\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 0s 344us/step - loss: 0.5149 - acc: 0.8011\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 0s 344us/step - loss: 0.5027 - acc: 0.8047\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 0s 377us/step - loss: 0.4986 - acc: 0.8047\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 0s 346us/step - loss: 0.5171 - acc: 0.7939\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 0s 338us/step - loss: 0.5068 - acc: 0.8118\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 0s 318us/step - loss: 0.4998 - acc: 0.8208\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 0s 325us/step - loss: 0.4864 - acc: 0.8029\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 0s 296us/step - loss: 0.4884 - acc: 0.8136\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 0s 300us/step - loss: 0.4931 - acc: 0.7957\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 0s 312us/step - loss: 0.4912 - acc: 0.8118\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 0s 307us/step - loss: 0.4797 - acc: 0.8118\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 0s 332us/step - loss: 0.4809 - acc: 0.8100\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 0s 329us/step - loss: 0.4667 - acc: 0.8082\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 0s 298us/step - loss: 0.4891 - acc: 0.7939\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 0s 347us/step - loss: 0.4743 - acc: 0.8082\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 0.4685 - acc: 0.8154\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 0s 365us/step - loss: 0.4774 - acc: 0.8065\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 0s 352us/step - loss: 0.4699 - acc: 0.8136\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 0.4712 - acc: 0.8100\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 0s 351us/step - loss: 0.4625 - acc: 0.8082\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 0s 362us/step - loss: 0.4529 - acc: 0.8244\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 0s 311us/step - loss: 0.4591 - acc: 0.8154\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 0s 337us/step - loss: 0.4584 - acc: 0.8262\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 0s 395us/step - loss: 0.4459 - acc: 0.8136\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 0s 311us/step - loss: 0.4471 - acc: 0.8172\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 0s 371us/step - loss: 0.4400 - acc: 0.8262\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 0s 381us/step - loss: 0.4575 - acc: 0.8029\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 0s 399us/step - loss: 0.4522 - acc: 0.8190\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 0s 352us/step - loss: 0.4404 - acc: 0.8154\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 0s 325us/step - loss: 0.4412 - acc: 0.8136\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 0s 371us/step - loss: 0.4405 - acc: 0.8172\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 0s 378us/step - loss: 0.4530 - acc: 0.8190\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 0s 328us/step - loss: 0.4378 - acc: 0.8136\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 0s 379us/step - loss: 0.4422 - acc: 0.8154\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 0s 354us/step - loss: 0.4387 - acc: 0.8315\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 0s 354us/step - loss: 0.4409 - acc: 0.8136\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 0.4335 - acc: 0.8333\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 0s 368us/step - loss: 0.4323 - acc: 0.8190\n",
      "Epoch 57/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 0.4328 - acc: 0.8262\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 0s 427us/step - loss: 0.4241 - acc: 0.8297\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 0s 361us/step - loss: 0.4316 - acc: 0.8190\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 0s 368us/step - loss: 0.4324 - acc: 0.8315\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 0s 316us/step - loss: 0.4293 - acc: 0.8190\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 0s 378us/step - loss: 0.4241 - acc: 0.8315\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 0s 359us/step - loss: 0.4221 - acc: 0.8190\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 0s 358us/step - loss: 0.4143 - acc: 0.8297\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 0s 339us/step - loss: 0.4173 - acc: 0.8333\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 0s 365us/step - loss: 0.4319 - acc: 0.8154\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 0s 314us/step - loss: 0.4200 - acc: 0.8315\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 0s 356us/step - loss: 0.4222 - acc: 0.8136\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 0s 355us/step - loss: 0.4266 - acc: 0.8190\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 0s 355us/step - loss: 0.4133 - acc: 0.8262\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 0s 436us/step - loss: 0.4070 - acc: 0.8297\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 0s 381us/step - loss: 0.4199 - acc: 0.8065\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 0s 376us/step - loss: 0.4127 - acc: 0.8190\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 0s 381us/step - loss: 0.4210 - acc: 0.8047\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 0s 371us/step - loss: 0.4020 - acc: 0.8423\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 0s 294us/step - loss: 0.4215 - acc: 0.8262\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 0s 329us/step - loss: 0.4193 - acc: 0.8136\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 0s 341us/step - loss: 0.4042 - acc: 0.8244\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 0s 394us/step - loss: 0.3993 - acc: 0.8280\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 0s 361us/step - loss: 0.4080 - acc: 0.8172\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 0s 403us/step - loss: 0.4196 - acc: 0.8244\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 0s 393us/step - loss: 0.4012 - acc: 0.8297\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 0s 346us/step - loss: 0.3963 - acc: 0.8369\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 0s 370us/step - loss: 0.3972 - acc: 0.8244\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 0s 321us/step - loss: 0.3995 - acc: 0.8405\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 0s 335us/step - loss: 0.4043 - acc: 0.8262\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 0s 306us/step - loss: 0.3973 - acc: 0.8351\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 0.4068 - acc: 0.8280\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 0s 336us/step - loss: 0.3990 - acc: 0.8315\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 0s 335us/step - loss: 0.4013 - acc: 0.8369\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 0s 351us/step - loss: 0.3961 - acc: 0.8351\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 0s 347us/step - loss: 0.3959 - acc: 0.8369\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 0s 366us/step - loss: 0.3964 - acc: 0.8280\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 0s 387us/step - loss: 0.4023 - acc: 0.8226\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 0s 319us/step - loss: 0.3969 - acc: 0.8136\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 0s 300us/step - loss: 0.3918 - acc: 0.8244\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 0s 317us/step - loss: 0.3869 - acc: 0.8297\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 0s 320us/step - loss: 0.3850 - acc: 0.8315\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 0.3880 - acc: 0.8333\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 0s 351us/step - loss: 0.4034 - acc: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20369ebc10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(20,)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(20),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(20),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1),\n",
    "    BatchNormalization(),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       140\n",
      "           1       0.74      0.49      0.59        47\n",
      "\n",
      "    accuracy                           0.83       187\n",
      "   macro avg       0.79      0.72      0.74       187\n",
      "weighted avg       0.82      0.83      0.82       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "878/878 [==============================] - 7s 8ms/step - loss: 0.6489 - acc: 0.6720\n",
      "Epoch 2/100\n",
      "878/878 [==============================] - 0s 313us/step - loss: 0.6241 - acc: 0.6788\n",
      "Epoch 3/100\n",
      "878/878 [==============================] - 0s 315us/step - loss: 0.6200 - acc: 0.6879\n",
      "Epoch 4/100\n",
      "878/878 [==============================] - 0s 314us/step - loss: 0.6034 - acc: 0.6925\n",
      "Epoch 5/100\n",
      "878/878 [==============================] - 0s 315us/step - loss: 0.6010 - acc: 0.7027\n",
      "Epoch 6/100\n",
      "878/878 [==============================] - 0s 314us/step - loss: 0.5896 - acc: 0.7118\n",
      "Epoch 7/100\n",
      "878/878 [==============================] - 0s 307us/step - loss: 0.5875 - acc: 0.7335\n",
      "Epoch 8/100\n",
      "878/878 [==============================] - 0s 307us/step - loss: 0.5868 - acc: 0.7221\n",
      "Epoch 9/100\n",
      "878/878 [==============================] - 0s 377us/step - loss: 0.5834 - acc: 0.7164\n",
      "Epoch 10/100\n",
      "878/878 [==============================] - 0s 309us/step - loss: 0.5713 - acc: 0.7358\n",
      "Epoch 11/100\n",
      "878/878 [==============================] - 0s 356us/step - loss: 0.5666 - acc: 0.7392\n",
      "Epoch 12/100\n",
      "878/878 [==============================] - 0s 341us/step - loss: 0.5605 - acc: 0.7449\n",
      "Epoch 13/100\n",
      "878/878 [==============================] - 0s 381us/step - loss: 0.5513 - acc: 0.7597\n",
      "Epoch 14/100\n",
      "878/878 [==============================] - 0s 309us/step - loss: 0.5511 - acc: 0.7506\n",
      "Epoch 15/100\n",
      "878/878 [==============================] - 0s 317us/step - loss: 0.5501 - acc: 0.7608\n",
      "Epoch 16/100\n",
      "878/878 [==============================] - 0s 389us/step - loss: 0.5435 - acc: 0.7392\n",
      "Epoch 17/100\n",
      "878/878 [==============================] - 0s 350us/step - loss: 0.5338 - acc: 0.7574\n",
      "Epoch 18/100\n",
      "878/878 [==============================] - 0s 329us/step - loss: 0.5291 - acc: 0.7597\n",
      "Epoch 19/100\n",
      "878/878 [==============================] - 0s 344us/step - loss: 0.5330 - acc: 0.7540\n",
      "Epoch 20/100\n",
      "878/878 [==============================] - 0s 333us/step - loss: 0.5279 - acc: 0.7631\n",
      "Epoch 21/100\n",
      "878/878 [==============================] - 0s 291us/step - loss: 0.5188 - acc: 0.7597\n",
      "Epoch 22/100\n",
      "878/878 [==============================] - 0s 301us/step - loss: 0.5270 - acc: 0.7574\n",
      "Epoch 23/100\n",
      "878/878 [==============================] - 0s 309us/step - loss: 0.5252 - acc: 0.7665\n",
      "Epoch 24/100\n",
      "878/878 [==============================] - 0s 353us/step - loss: 0.5139 - acc: 0.7779\n",
      "Epoch 25/100\n",
      "878/878 [==============================] - 0s 331us/step - loss: 0.5120 - acc: 0.7790\n",
      "Epoch 26/100\n",
      "878/878 [==============================] - 0s 355us/step - loss: 0.5129 - acc: 0.7768\n",
      "Epoch 27/100\n",
      "878/878 [==============================] - 0s 359us/step - loss: 0.5045 - acc: 0.7802\n",
      "Epoch 28/100\n",
      "878/878 [==============================] - 0s 329us/step - loss: 0.5164 - acc: 0.7745\n",
      "Epoch 29/100\n",
      "878/878 [==============================] - 0s 335us/step - loss: 0.4999 - acc: 0.7745\n",
      "Epoch 30/100\n",
      "878/878 [==============================] - 0s 322us/step - loss: 0.5058 - acc: 0.7745\n",
      "Epoch 31/100\n",
      "878/878 [==============================] - 0s 394us/step - loss: 0.4970 - acc: 0.7733\n",
      "Epoch 32/100\n",
      "878/878 [==============================] - 0s 359us/step - loss: 0.4992 - acc: 0.7688\n",
      "Epoch 33/100\n",
      "878/878 [==============================] - 0s 321us/step - loss: 0.4894 - acc: 0.7904\n",
      "Epoch 34/100\n",
      "878/878 [==============================] - 0s 309us/step - loss: 0.5015 - acc: 0.7688\n",
      "Epoch 35/100\n",
      "878/878 [==============================] - 0s 327us/step - loss: 0.4888 - acc: 0.7768\n",
      "Epoch 36/100\n",
      "878/878 [==============================] - 0s 364us/step - loss: 0.4938 - acc: 0.7779\n",
      "Epoch 37/100\n",
      "878/878 [==============================] - 0s 365us/step - loss: 0.4919 - acc: 0.7733\n",
      "Epoch 38/100\n",
      "878/878 [==============================] - 0s 345us/step - loss: 0.4935 - acc: 0.7813\n",
      "Epoch 39/100\n",
      "878/878 [==============================] - 0s 397us/step - loss: 0.4853 - acc: 0.7825\n",
      "Epoch 40/100\n",
      "878/878 [==============================] - 0s 336us/step - loss: 0.4839 - acc: 0.7802\n",
      "Epoch 41/100\n",
      "878/878 [==============================] - 0s 355us/step - loss: 0.4965 - acc: 0.7654\n",
      "Epoch 42/100\n",
      "878/878 [==============================] - 0s 314us/step - loss: 0.4922 - acc: 0.7847\n",
      "Epoch 43/100\n",
      "878/878 [==============================] - 0s 316us/step - loss: 0.4866 - acc: 0.7825\n",
      "Epoch 44/100\n",
      "878/878 [==============================] - 0s 348us/step - loss: 0.4784 - acc: 0.7859\n",
      "Epoch 45/100\n",
      "878/878 [==============================] - 0s 356us/step - loss: 0.4811 - acc: 0.7802\n",
      "Epoch 46/100\n",
      "878/878 [==============================] - 0s 340us/step - loss: 0.4774 - acc: 0.7825\n",
      "Epoch 47/100\n",
      "878/878 [==============================] - 0s 384us/step - loss: 0.4639 - acc: 0.7916\n",
      "Epoch 48/100\n",
      "878/878 [==============================] - 0s 350us/step - loss: 0.4740 - acc: 0.7802\n",
      "Epoch 49/100\n",
      "878/878 [==============================] - 0s 306us/step - loss: 0.4711 - acc: 0.7916\n",
      "Epoch 50/100\n",
      "878/878 [==============================] - 0s 326us/step - loss: 0.4588 - acc: 0.7938\n",
      "Epoch 51/100\n",
      "878/878 [==============================] - 0s 315us/step - loss: 0.4663 - acc: 0.7904\n",
      "Epoch 52/100\n",
      "878/878 [==============================] - 0s 297us/step - loss: 0.4633 - acc: 0.7916\n",
      "Epoch 53/100\n",
      "878/878 [==============================] - 0s 321us/step - loss: 0.4646 - acc: 0.7768\n",
      "Epoch 54/100\n",
      "878/878 [==============================] - 0s 341us/step - loss: 0.4491 - acc: 0.7938\n",
      "Epoch 55/100\n",
      "878/878 [==============================] - 0s 328us/step - loss: 0.4530 - acc: 0.8064\n",
      "Epoch 56/100\n",
      "878/878 [==============================] - 0s 343us/step - loss: 0.4455 - acc: 0.8109\n",
      "Epoch 57/100\n",
      "878/878 [==============================] - 0s 333us/step - loss: 0.4470 - acc: 0.8007\n",
      "Epoch 58/100\n",
      "878/878 [==============================] - 0s 324us/step - loss: 0.4555 - acc: 0.7938\n",
      "Epoch 59/100\n",
      "878/878 [==============================] - 0s 325us/step - loss: 0.4683 - acc: 0.7950\n",
      "Epoch 60/100\n",
      "878/878 [==============================] - 0s 317us/step - loss: 0.4566 - acc: 0.7973\n",
      "Epoch 61/100\n",
      "878/878 [==============================] - 0s 311us/step - loss: 0.4586 - acc: 0.7870\n",
      "Epoch 62/100\n",
      "878/878 [==============================] - 0s 312us/step - loss: 0.4479 - acc: 0.7938\n",
      "Epoch 63/100\n",
      "878/878 [==============================] - 0s 305us/step - loss: 0.4532 - acc: 0.7870\n",
      "Epoch 64/100\n",
      "878/878 [==============================] - 0s 308us/step - loss: 0.4492 - acc: 0.7961\n",
      "Epoch 65/100\n",
      "878/878 [==============================] - 0s 315us/step - loss: 0.4442 - acc: 0.8064\n",
      "Epoch 66/100\n",
      "878/878 [==============================] - 0s 317us/step - loss: 0.4631 - acc: 0.7825\n",
      "Epoch 67/100\n",
      "878/878 [==============================] - 0s 326us/step - loss: 0.4457 - acc: 0.8064\n",
      "Epoch 68/100\n",
      "878/878 [==============================] - 0s 343us/step - loss: 0.4499 - acc: 0.8041\n",
      "Epoch 69/100\n",
      "878/878 [==============================] - 0s 311us/step - loss: 0.4413 - acc: 0.8041\n",
      "Epoch 70/100\n",
      "878/878 [==============================] - 0s 302us/step - loss: 0.4529 - acc: 0.7836\n",
      "Epoch 71/100\n",
      "878/878 [==============================] - 0s 310us/step - loss: 0.4578 - acc: 0.7995\n",
      "Epoch 72/100\n",
      "878/878 [==============================] - 0s 300us/step - loss: 0.4460 - acc: 0.7984\n",
      "Epoch 73/100\n",
      "878/878 [==============================] - 0s 308us/step - loss: 0.4360 - acc: 0.7995\n",
      "Epoch 74/100\n",
      "878/878 [==============================] - 0s 295us/step - loss: 0.4367 - acc: 0.8018\n",
      "Epoch 75/100\n",
      "878/878 [==============================] - 0s 335us/step - loss: 0.4532 - acc: 0.7961\n",
      "Epoch 76/100\n",
      "878/878 [==============================] - 0s 318us/step - loss: 0.4549 - acc: 0.8007\n",
      "Epoch 77/100\n",
      "878/878 [==============================] - 0s 306us/step - loss: 0.4651 - acc: 0.7995\n",
      "Epoch 78/100\n",
      "878/878 [==============================] - 0s 314us/step - loss: 0.4432 - acc: 0.7916\n",
      "Epoch 79/100\n",
      "878/878 [==============================] - 0s 309us/step - loss: 0.4403 - acc: 0.8109\n",
      "Epoch 80/100\n",
      "878/878 [==============================] - 0s 295us/step - loss: 0.4459 - acc: 0.8052\n",
      "Epoch 81/100\n",
      "878/878 [==============================] - 0s 324us/step - loss: 0.4430 - acc: 0.8041\n",
      "Epoch 82/100\n",
      "878/878 [==============================] - 0s 342us/step - loss: 0.4531 - acc: 0.7984\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 0s 338us/step - loss: 0.4392 - acc: 0.8064\n",
      "Epoch 84/100\n",
      "878/878 [==============================] - 0s 325us/step - loss: 0.4403 - acc: 0.7984\n",
      "Epoch 85/100\n",
      "878/878 [==============================] - 0s 303us/step - loss: 0.4343 - acc: 0.8189\n",
      "Epoch 86/100\n",
      "878/878 [==============================] - 0s 314us/step - loss: 0.4586 - acc: 0.7916\n",
      "Epoch 87/100\n",
      "878/878 [==============================] - 0s 306us/step - loss: 0.4429 - acc: 0.8098\n",
      "Epoch 88/100\n",
      "878/878 [==============================] - 0s 324us/step - loss: 0.4447 - acc: 0.7904\n",
      "Epoch 89/100\n",
      "878/878 [==============================] - 0s 295us/step - loss: 0.4507 - acc: 0.7973\n",
      "Epoch 90/100\n",
      "878/878 [==============================] - 0s 317us/step - loss: 0.4377 - acc: 0.7973\n",
      "Epoch 91/100\n",
      "878/878 [==============================] - 0s 301us/step - loss: 0.4381 - acc: 0.8075\n",
      "Epoch 92/100\n",
      "878/878 [==============================] - 0s 304us/step - loss: 0.4290 - acc: 0.7995\n",
      "Epoch 93/100\n",
      "878/878 [==============================] - 0s 297us/step - loss: 0.4455 - acc: 0.7984\n",
      "Epoch 94/100\n",
      "878/878 [==============================] - 0s 303us/step - loss: 0.4472 - acc: 0.8030\n",
      "Epoch 95/100\n",
      "878/878 [==============================] - 0s 302us/step - loss: 0.4391 - acc: 0.8075\n",
      "Epoch 96/100\n",
      "878/878 [==============================] - 0s 307us/step - loss: 0.4355 - acc: 0.8121\n",
      "Epoch 97/100\n",
      "878/878 [==============================] - 0s 328us/step - loss: 0.4243 - acc: 0.8166\n",
      "Epoch 98/100\n",
      "878/878 [==============================] - 0s 307us/step - loss: 0.4216 - acc: 0.8121\n",
      "Epoch 99/100\n",
      "878/878 [==============================] - 0s 300us/step - loss: 0.4367 - acc: 0.8064\n",
      "Epoch 100/100\n",
      "878/878 [==============================] - 0s 313us/step - loss: 0.4276 - acc: 0.8144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f202b582390>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_res, y_res = RandomOverSampler().fit_resample(x_train, y_train)\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_res, y_res, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       140\n",
      "           1       0.56      0.68      0.62        47\n",
      "\n",
      "    accuracy                           0.79       187\n",
      "   macro avg       0.72      0.75      0.73       187\n",
      "weighted avg       0.80      0.79      0.79       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 55618.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building KNN index\n",
      "Extracting KNN from index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 745/745 [00:00<00:00, 5431.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 5s 1s/step - loss: 20.7020 - stacked_triplets_loss: 12.2239 - supervised_loss: 29.0315\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 10.1295 - stacked_triplets_loss: 8.7866 - supervised_loss: 11.3737\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 64.5300 - stacked_triplets_loss: 20.2468 - supervised_loss: 108.8132\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 6.7783 - stacked_triplets_loss: 9.1699 - supervised_loss: 4.3264\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 15.3156 - stacked_triplets_loss: 9.2292 - supervised_loss: 21.4909\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6597 - stacked_triplets_loss: 9.6022 - supervised_loss: 9.7128\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 3.3337 - stacked_triplets_loss: 4.0748 - supervised_loss: 2.5875\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 14.9545 - stacked_triplets_loss: 7.4753 - supervised_loss: 22.3008\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 4.6287 - stacked_triplets_loss: 5.9421 - supervised_loss: 3.3105\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 4.5913 - stacked_triplets_loss: 5.6038 - supervised_loss: 3.5789\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 3.3101 - stacked_triplets_loss: 3.5077 - supervised_loss: 3.1105\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1865 - stacked_triplets_loss: 4.7828 - supervised_loss: 5.5720\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 4.4253 - stacked_triplets_loss: 4.6562 - supervised_loss: 4.1945\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 3.7103 - stacked_triplets_loss: 4.5755 - supervised_loss: 2.8417\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 4.2795 - stacked_triplets_loss: 4.6543 - supervised_loss: 3.8831\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 4.0927 - stacked_triplets_loss: 5.1691 - supervised_loss: 3.0164\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2.1375 - stacked_triplets_loss: 2.6891 - supervised_loss: 1.5848\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.0464 - stacked_triplets_loss: 3.3244 - supervised_loss: 2.7592\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.2919 - stacked_triplets_loss: 2.7999 - supervised_loss: 1.7852\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 4.5642 - stacked_triplets_loss: 4.8423 - supervised_loss: 4.2630\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.9233 - stacked_triplets_loss: 2.6981 - supervised_loss: 1.1462\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.9084 - stacked_triplets_loss: 3.4802 - supervised_loss: 2.3365\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.7764 - stacked_triplets_loss: 2.8866 - supervised_loss: 2.6497\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.5459 - stacked_triplets_loss: 2.9108 - supervised_loss: 2.1775\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.6685 - stacked_triplets_loss: 3.0454 - supervised_loss: 2.2818\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.8978 - stacked_triplets_loss: 2.2917 - supervised_loss: 1.5038\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 2.1750 - stacked_triplets_loss: 2.7116 - supervised_loss: 1.6347\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.1128 - stacked_triplets_loss: 2.1169 - supervised_loss: 2.0820\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3608 - stacked_triplets_loss: 1.4787 - supervised_loss: 1.2428\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.0999 - stacked_triplets_loss: 2.5801 - supervised_loss: 1.6142\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.9234 - stacked_triplets_loss: 2.1935 - supervised_loss: 1.6469\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.2137 - stacked_triplets_loss: 2.5249 - supervised_loss: 1.8953\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.9579 - stacked_triplets_loss: 2.3030 - supervised_loss: 1.6128\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.5984 - stacked_triplets_loss: 2.0041 - supervised_loss: 1.1927\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.6266 - stacked_triplets_loss: 1.6436 - supervised_loss: 1.5987\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2.1193 - stacked_triplets_loss: 2.4358 - supervised_loss: 1.7897\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.5761 - stacked_triplets_loss: 1.9369 - supervised_loss: 1.2056\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.7200 - stacked_triplets_loss: 1.7541 - supervised_loss: 1.6859\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.2767 - stacked_triplets_loss: 1.3948 - supervised_loss: 1.1574\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.8555 - stacked_triplets_loss: 1.9035 - supervised_loss: 1.7834\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.7408 - stacked_triplets_loss: 1.9171 - supervised_loss: 1.5645\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.6835 - stacked_triplets_loss: 1.9071 - supervised_loss: 1.4538\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.7503 - stacked_triplets_loss: 2.0265 - supervised_loss: 1.4742\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.6236 - stacked_triplets_loss: 1.7020 - supervised_loss: 1.5464\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.2285 - stacked_triplets_loss: 1.5590 - supervised_loss: 0.8957\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.2593 - stacked_triplets_loss: 2.3315 - supervised_loss: 2.1591\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3682 - stacked_triplets_loss: 1.3203 - supervised_loss: 1.4161\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.6647 - stacked_triplets_loss: 1.9139 - supervised_loss: 1.4149\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.6993 - stacked_triplets_loss: 1.8832 - supervised_loss: 1.5155\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0785 - stacked_triplets_loss: 1.0328 - supervised_loss: 1.1255\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.5877 - stacked_triplets_loss: 1.8196 - supervised_loss: 1.3559\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.2320 - stacked_triplets_loss: 1.3567 - supervised_loss: 1.1083\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.3819 - stacked_triplets_loss: 1.6487 - supervised_loss: 1.1150\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.2456 - stacked_triplets_loss: 1.3183 - supervised_loss: 1.1672\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.4303 - stacked_triplets_loss: 1.4814 - supervised_loss: 1.3731\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.4304 - stacked_triplets_loss: 1.8863 - supervised_loss: 0.9712\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.2976 - stacked_triplets_loss: 1.6034 - supervised_loss: 0.9918\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.8085 - stacked_triplets_loss: 0.9290 - supervised_loss: 0.6920\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.4234 - stacked_triplets_loss: 1.2718 - supervised_loss: 1.5652\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4455 - stacked_triplets_loss: 1.4443 - supervised_loss: 1.4447\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.4798 - stacked_triplets_loss: 1.6523 - supervised_loss: 1.3074\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.0296 - stacked_triplets_loss: 1.2160 - supervised_loss: 0.8431\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.3809 - stacked_triplets_loss: 1.5430 - supervised_loss: 1.2118\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0459 - stacked_triplets_loss: 1.1804 - supervised_loss: 0.9027\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9767 - stacked_triplets_loss: 1.3485 - supervised_loss: 0.6049\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.1552 - stacked_triplets_loss: 1.3194 - supervised_loss: 0.9851\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2733 - stacked_triplets_loss: 1.4737 - supervised_loss: 1.0735\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0460 - stacked_triplets_loss: 1.2124 - supervised_loss: 0.8796\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9974 - stacked_triplets_loss: 0.9723 - supervised_loss: 1.0275\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4314 - stacked_triplets_loss: 1.5791 - supervised_loss: 1.2800\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8733 - stacked_triplets_loss: 1.0940 - supervised_loss: 0.6532\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.1144 - stacked_triplets_loss: 1.2717 - supervised_loss: 0.9571\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.1869 - stacked_triplets_loss: 1.2008 - supervised_loss: 1.1715\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.1161 - stacked_triplets_loss: 1.1807 - supervised_loss: 1.0514\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0340 - stacked_triplets_loss: 1.1741 - supervised_loss: 0.8913\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.1270 - stacked_triplets_loss: 1.1822 - supervised_loss: 1.0669\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7949 - stacked_triplets_loss: 0.8120 - supervised_loss: 0.7817\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.9241 - stacked_triplets_loss: 0.9377 - supervised_loss: 0.9104\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.0267 - stacked_triplets_loss: 1.2528 - supervised_loss: 0.7986\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.0909 - stacked_triplets_loss: 1.3178 - supervised_loss: 0.8595\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.9748 - stacked_triplets_loss: 1.2570 - supervised_loss: 0.6893\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6687 - stacked_triplets_loss: 0.8821 - supervised_loss: 0.4562\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4698 - stacked_triplets_loss: 1.4356 - supervised_loss: 1.5041\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.9547 - stacked_triplets_loss: 0.8689 - supervised_loss: 1.0491\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.0738 - stacked_triplets_loss: 1.1152 - supervised_loss: 1.0326\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.2249 - stacked_triplets_loss: 1.2488 - supervised_loss: 1.1940\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.5210 - stacked_triplets_loss: 0.7277 - supervised_loss: 0.3173\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4843 - stacked_triplets_loss: 1.2240 - supervised_loss: 1.7446\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0495 - stacked_triplets_loss: 0.9327 - supervised_loss: 1.1683\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.9649 - stacked_triplets_loss: 1.0794 - supervised_loss: 0.8511\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8468 - stacked_triplets_loss: 0.9158 - supervised_loss: 0.7762\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8855 - stacked_triplets_loss: 0.9652 - supervised_loss: 0.8058\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6320 - stacked_triplets_loss: 0.6709 - supervised_loss: 0.5909\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0064 - stacked_triplets_loss: 0.9956 - supervised_loss: 1.0059\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8732 - stacked_triplets_loss: 1.0395 - supervised_loss: 0.7068\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.9791 - stacked_triplets_loss: 1.0178 - supervised_loss: 0.9406\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6298 - stacked_triplets_loss: 0.6924 - supervised_loss: 0.5670\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.3648 - stacked_triplets_loss: 1.4756 - supervised_loss: 1.2466\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5140 - stacked_triplets_loss: 0.6323 - supervised_loss: 0.3972\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.1686 - stacked_triplets_loss: 1.1845 - supervised_loss: 1.1528\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0760 - stacked_triplets_loss: 1.0612 - supervised_loss: 1.0868\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6089 - stacked_triplets_loss: 0.5804 - supervised_loss: 0.6380\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8724 - stacked_triplets_loss: 0.9626 - supervised_loss: 0.7821\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6831 - stacked_triplets_loss: 1.0339 - supervised_loss: 0.3387\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.3590 - stacked_triplets_loss: 1.0561 - supervised_loss: 1.6500\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6420 - stacked_triplets_loss: 0.5116 - supervised_loss: 0.7730\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9047 - stacked_triplets_loss: 1.0174 - supervised_loss: 0.7920\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5834 - stacked_triplets_loss: 0.6274 - supervised_loss: 0.5402\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7360 - stacked_triplets_loss: 0.7236 - supervised_loss: 0.7483\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7341 - stacked_triplets_loss: 0.8224 - supervised_loss: 0.6399\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.6584 - stacked_triplets_loss: 0.6485 - supervised_loss: 0.6682\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6231 - stacked_triplets_loss: 0.6766 - supervised_loss: 0.5680\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.8219 - stacked_triplets_loss: 0.8096 - supervised_loss: 0.8341\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.7152 - stacked_triplets_loss: 0.8815 - supervised_loss: 0.5454\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7104 - stacked_triplets_loss: 0.9560 - supervised_loss: 0.4663\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7977 - stacked_triplets_loss: 0.9216 - supervised_loss: 0.6737\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 58ms/step - loss: 0.7521 - stacked_triplets_loss: 0.8706 - supervised_loss: 0.6317\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4407 - stacked_triplets_loss: 0.5969 - supervised_loss: 0.2845\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.8807 - stacked_triplets_loss: 0.8116 - supervised_loss: 0.9431\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6495 - stacked_triplets_loss: 0.6145 - supervised_loss: 0.6797\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5528 - stacked_triplets_loss: 0.6398 - supervised_loss: 0.4687\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7062 - stacked_triplets_loss: 0.6980 - supervised_loss: 0.7121\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.0206 - stacked_triplets_loss: 0.9920 - supervised_loss: 1.0491\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7891 - stacked_triplets_loss: 0.7469 - supervised_loss: 0.8323\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7764 - stacked_triplets_loss: 0.9245 - supervised_loss: 0.6283\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5067 - stacked_triplets_loss: 0.5990 - supervised_loss: 0.4132\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7714 - stacked_triplets_loss: 0.8457 - supervised_loss: 0.6971\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7914 - stacked_triplets_loss: 0.8578 - supervised_loss: 0.7197\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4536 - stacked_triplets_loss: 0.5548 - supervised_loss: 0.3525\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.9509 - stacked_triplets_loss: 0.9143 - supervised_loss: 0.9806\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5896 - stacked_triplets_loss: 0.5175 - supervised_loss: 0.6645\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6655 - stacked_triplets_loss: 0.7007 - supervised_loss: 0.6303\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7367 - stacked_triplets_loss: 0.6904 - supervised_loss: 0.7788\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7498 - stacked_triplets_loss: 0.7933 - supervised_loss: 0.7064\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5045 - stacked_triplets_loss: 0.6786 - supervised_loss: 0.3306\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6317 - stacked_triplets_loss: 0.5953 - supervised_loss: 0.6681\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7191 - stacked_triplets_loss: 0.7538 - supervised_loss: 0.6827\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6432 - stacked_triplets_loss: 0.6696 - supervised_loss: 0.6151\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6418 - stacked_triplets_loss: 0.6122 - supervised_loss: 0.6697\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6997 - stacked_triplets_loss: 0.7767 - supervised_loss: 0.6206\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6375 - stacked_triplets_loss: 0.6572 - supervised_loss: 0.6153\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4380 - stacked_triplets_loss: 0.5438 - supervised_loss: 0.3308\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6862 - stacked_triplets_loss: 0.7396 - supervised_loss: 0.6328\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6301 - stacked_triplets_loss: 0.6717 - supervised_loss: 0.5848\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6642 - stacked_triplets_loss: 0.6466 - supervised_loss: 0.6821\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.4895 - stacked_triplets_loss: 0.6036 - supervised_loss: 0.3753\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7468 - stacked_triplets_loss: 0.6342 - supervised_loss: 0.8542\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5802 - stacked_triplets_loss: 0.5265 - supervised_loss: 0.6306\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5224 - stacked_triplets_loss: 0.5074 - supervised_loss: 0.5363\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5924 - stacked_triplets_loss: 0.6142 - supervised_loss: 0.5707\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6658 - stacked_triplets_loss: 0.6438 - supervised_loss: 0.6870\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5234 - stacked_triplets_loss: 0.6604 - supervised_loss: 0.3881\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.7908 - stacked_triplets_loss: 0.7198 - supervised_loss: 0.8618\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5700 - stacked_triplets_loss: 0.5563 - supervised_loss: 0.5862\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5291 - stacked_triplets_loss: 0.5573 - supervised_loss: 0.4979\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6086 - stacked_triplets_loss: 0.6001 - supervised_loss: 0.6147\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5941 - stacked_triplets_loss: 0.6386 - supervised_loss: 0.5466\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5616 - stacked_triplets_loss: 0.5793 - supervised_loss: 0.5439\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5547 - stacked_triplets_loss: 0.5336 - supervised_loss: 0.5729\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5951 - stacked_triplets_loss: 0.6288 - supervised_loss: 0.5608\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4742 - stacked_triplets_loss: 0.6316 - supervised_loss: 0.3169\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7783 - stacked_triplets_loss: 0.7275 - supervised_loss: 0.8250\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7342 - stacked_triplets_loss: 0.5710 - supervised_loss: 0.8935\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6400 - stacked_triplets_loss: 0.6119 - supervised_loss: 0.6721\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6471 - stacked_triplets_loss: 0.6309 - supervised_loss: 0.6632\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3649 - stacked_triplets_loss: 0.4247 - supervised_loss: 0.3070\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9974 - stacked_triplets_loss: 0.7481 - supervised_loss: 1.2467\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5727 - stacked_triplets_loss: 0.6142 - supervised_loss: 0.5325\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4964 - stacked_triplets_loss: 0.4435 - supervised_loss: 0.5497\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6945 - stacked_triplets_loss: 0.7357 - supervised_loss: 0.6500\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5327 - stacked_triplets_loss: 0.6429 - supervised_loss: 0.4225\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8593 - stacked_triplets_loss: 0.6714 - supervised_loss: 1.0409\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5517 - stacked_triplets_loss: 0.5346 - supervised_loss: 0.5698\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5469 - stacked_triplets_loss: 0.5374 - supervised_loss: 0.5571\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5184 - stacked_triplets_loss: 0.5406 - supervised_loss: 0.4951\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6582 - stacked_triplets_loss: 0.5086 - supervised_loss: 0.8029\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4793 - stacked_triplets_loss: 0.5140 - supervised_loss: 0.4446\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4404 - stacked_triplets_loss: 0.4978 - supervised_loss: 0.3821\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4910 - stacked_triplets_loss: 0.4343 - supervised_loss: 0.5465\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5973 - stacked_triplets_loss: 0.6067 - supervised_loss: 0.5862\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6191 - stacked_triplets_loss: 0.6371 - supervised_loss: 0.5996\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5551 - stacked_triplets_loss: 0.5694 - supervised_loss: 0.5408\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6282 - stacked_triplets_loss: 0.6989 - supervised_loss: 0.5529\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4573 - stacked_triplets_loss: 0.5752 - supervised_loss: 0.3394\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5648 - stacked_triplets_loss: 0.4696 - supervised_loss: 0.6559\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5472 - stacked_triplets_loss: 0.5383 - supervised_loss: 0.5532\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6037 - stacked_triplets_loss: 0.5344 - supervised_loss: 0.6722\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6755 - stacked_triplets_loss: 0.7327 - supervised_loss: 0.6182\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5495 - stacked_triplets_loss: 0.4877 - supervised_loss: 0.6104\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6498 - stacked_triplets_loss: 0.6456 - supervised_loss: 0.6540\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5020 - stacked_triplets_loss: 0.5154 - supervised_loss: 0.4888\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4690 - stacked_triplets_loss: 0.5566 - supervised_loss: 0.3807\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5372 - stacked_triplets_loss: 0.5357 - supervised_loss: 0.5362\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.4649 - stacked_triplets_loss: 0.4369 - supervised_loss: 0.4930\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4918 - stacked_triplets_loss: 0.5889 - supervised_loss: 0.3939\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5635 - stacked_triplets_loss: 0.5231 - supervised_loss: 0.6003\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5299 - stacked_triplets_loss: 0.6365 - supervised_loss: 0.4229\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5573 - stacked_triplets_loss: 0.5364 - supervised_loss: 0.5783\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6251 - stacked_triplets_loss: 0.5770 - supervised_loss: 0.6723\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5282 - stacked_triplets_loss: 0.5912 - supervised_loss: 0.4651\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6191 - stacked_triplets_loss: 0.6067 - supervised_loss: 0.6336\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5697 - stacked_triplets_loss: 0.4432 - supervised_loss: 0.6931\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5436 - stacked_triplets_loss: 0.5444 - supervised_loss: 0.5428\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5238 - stacked_triplets_loss: 0.5598 - supervised_loss: 0.4880\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4704 - stacked_triplets_loss: 0.4186 - supervised_loss: 0.5201\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.5275 - stacked_triplets_loss: 0.5516 - supervised_loss: 0.5031\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3650 - stacked_triplets_loss: 0.4310 - supervised_loss: 0.2984\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7836 - stacked_triplets_loss: 0.4710 - supervised_loss: 1.0962\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.5088 - stacked_triplets_loss: 0.4091 - supervised_loss: 0.6095\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5128 - stacked_triplets_loss: 0.4109 - supervised_loss: 0.6173\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3904 - stacked_triplets_loss: 0.3985 - supervised_loss: 0.3831\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.8239 - stacked_triplets_loss: 0.7004 - supervised_loss: 0.9474\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7021 - stacked_triplets_loss: 0.6575 - supervised_loss: 0.7442\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4740 - stacked_triplets_loss: 0.5277 - supervised_loss: 0.4204\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4242 - stacked_triplets_loss: 0.5088 - supervised_loss: 0.3396\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5051 - stacked_triplets_loss: 0.4371 - supervised_loss: 0.5694\n",
      "745/745 [==============================] - 0s 657us/sample\n"
     ]
    }
   ],
   "source": [
    "ivis = Ivis(embedding_dims=2, k=7)\n",
    "x_red = ivis.fit_transform(np.array(x), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efb9dfdc090>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_red.T[0], x_red.T[1], c=y, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 51377.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building KNN index\n",
      "Extracting KNN from index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 745/745 [00:00<00:00, 5381.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 7s 1s/step - loss: 21.3575 - stacked_triplets_loss: 19.8294 - supervised_loss: 22.8883\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.1250 - stacked_triplets_loss: 7.5653 - supervised_loss: 8.6497\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 15.0282 - stacked_triplets_loss: 14.8883 - supervised_loss: 15.1681\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 5.4009 - stacked_triplets_loss: 6.7056 - supervised_loss: 4.0958\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 8.1176 - stacked_triplets_loss: 12.2786 - supervised_loss: 3.9565\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.8819 - stacked_triplets_loss: 4.3724 - supervised_loss: 3.3905\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 6.6599 - stacked_triplets_loss: 6.6430 - supervised_loss: 6.6125\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.4243 - stacked_triplets_loss: 3.5727 - supervised_loss: 1.2731\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 5.8012 - stacked_triplets_loss: 8.0287 - supervised_loss: 3.5511\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 5.2452 - stacked_triplets_loss: 6.9012 - supervised_loss: 3.5892\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.7577 - stacked_triplets_loss: 3.3682 - supervised_loss: 2.1741\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4.6585 - stacked_triplets_loss: 5.4514 - supervised_loss: 3.8341\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.5209 - stacked_triplets_loss: 4.4572 - supervised_loss: 2.5697\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 2.9807 - stacked_triplets_loss: 3.8972 - supervised_loss: 2.0561\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 3.1882 - stacked_triplets_loss: 4.5444 - supervised_loss: 1.8293\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 3.1313 - stacked_triplets_loss: 4.1055 - supervised_loss: 2.1571\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4153 - stacked_triplets_loss: 2.0370 - supervised_loss: 0.7961\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.7056 - stacked_triplets_loss: 3.1688 - supervised_loss: 2.2307\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.4422 - stacked_triplets_loss: 1.9381 - supervised_loss: 0.9444\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 2.9494 - stacked_triplets_loss: 4.1939 - supervised_loss: 1.6825\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 2.9736 - stacked_triplets_loss: 4.7064 - supervised_loss: 1.2409\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4233 - stacked_triplets_loss: 1.9826 - supervised_loss: 0.8594\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 2.5190 - stacked_triplets_loss: 3.1601 - supervised_loss: 1.8780\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8323 - stacked_triplets_loss: 3.8955 - supervised_loss: 1.7611\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.0628 - stacked_triplets_loss: 2.4144 - supervised_loss: 1.6987\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.1181 - stacked_triplets_loss: 1.7082 - supervised_loss: 0.5322\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.7107 - stacked_triplets_loss: 3.1569 - supervised_loss: 2.2645\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.3054 - stacked_triplets_loss: 2.2868 - supervised_loss: 2.3297\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.7268 - stacked_triplets_loss: 2.1375 - supervised_loss: 1.3142\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9209 - stacked_triplets_loss: 2.1206 - supervised_loss: 1.7072\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.6592 - stacked_triplets_loss: 2.1351 - supervised_loss: 1.1779\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7231 - stacked_triplets_loss: 2.2846 - supervised_loss: 1.1529\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9091 - stacked_triplets_loss: 1.3736 - supervised_loss: 0.4431\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.5187 - stacked_triplets_loss: 1.8957 - supervised_loss: 1.1416\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.5970 - stacked_triplets_loss: 2.2750 - supervised_loss: 0.9196\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6380 - stacked_triplets_loss: 2.1513 - supervised_loss: 1.1189\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.3498 - stacked_triplets_loss: 1.7120 - supervised_loss: 0.9857\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.3534 - stacked_triplets_loss: 1.7496 - supervised_loss: 0.9546\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.2435 - stacked_triplets_loss: 1.4870 - supervised_loss: 1.0000\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6453 - stacked_triplets_loss: 0.8895 - supervised_loss: 0.4022\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4617 - stacked_triplets_loss: 1.7387 - supervised_loss: 1.1847\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2880 - stacked_triplets_loss: 1.5592 - supervised_loss: 1.0118\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.3433 - stacked_triplets_loss: 1.7288 - supervised_loss: 0.9579\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.1794 - stacked_triplets_loss: 1.4741 - supervised_loss: 0.8709\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.1758 - stacked_triplets_loss: 1.6088 - supervised_loss: 0.7427\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8681 - stacked_triplets_loss: 1.0853 - supervised_loss: 0.6518\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1064 - stacked_triplets_loss: 1.4190 - supervised_loss: 0.7937\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2013 - stacked_triplets_loss: 1.5926 - supervised_loss: 0.8052\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.2712 - stacked_triplets_loss: 1.5957 - supervised_loss: 0.9488\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4813 - stacked_triplets_loss: 0.7224 - supervised_loss: 0.2385\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.4711 - stacked_triplets_loss: 1.5275 - supervised_loss: 1.4043\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1504 - stacked_triplets_loss: 1.6126 - supervised_loss: 0.6882\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0866 - stacked_triplets_loss: 1.4909 - supervised_loss: 0.6766\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1932 - stacked_triplets_loss: 1.4906 - supervised_loss: 0.8957\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.0820 - stacked_triplets_loss: 1.5053 - supervised_loss: 0.6542\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.6929 - stacked_triplets_loss: 0.7087 - supervised_loss: 0.6770\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9877 - stacked_triplets_loss: 1.3384 - supervised_loss: 0.6326\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4176 - stacked_triplets_loss: 1.6988 - supervised_loss: 1.1365\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6960 - stacked_triplets_loss: 0.7917 - supervised_loss: 0.6004\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1476 - stacked_triplets_loss: 1.6007 - supervised_loss: 0.6940\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.1004 - stacked_triplets_loss: 1.2062 - supervised_loss: 0.9869\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.6727 - stacked_triplets_loss: 0.6948 - supervised_loss: 0.6538\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.2568 - stacked_triplets_loss: 1.6487 - supervised_loss: 0.8649\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7270 - stacked_triplets_loss: 0.9837 - supervised_loss: 0.4629\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3180 - stacked_triplets_loss: 1.8162 - supervised_loss: 0.8197\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.9023 - stacked_triplets_loss: 1.2757 - supervised_loss: 0.5258\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7496 - stacked_triplets_loss: 0.8456 - supervised_loss: 0.6520\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9463 - stacked_triplets_loss: 1.2416 - supervised_loss: 0.6461\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7432 - stacked_triplets_loss: 1.1526 - supervised_loss: 0.3338\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.3255 - stacked_triplets_loss: 1.2415 - supervised_loss: 1.4004\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0746 - stacked_triplets_loss: 1.2935 - supervised_loss: 0.8663\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.0691 - stacked_triplets_loss: 1.4009 - supervised_loss: 0.7428\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.8010 - stacked_triplets_loss: 0.7597 - supervised_loss: 0.8361\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8755 - stacked_triplets_loss: 1.2369 - supervised_loss: 0.5111\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.8142 - stacked_triplets_loss: 0.9254 - supervised_loss: 0.7029\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6914 - stacked_triplets_loss: 0.6936 - supervised_loss: 0.6892\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6108 - stacked_triplets_loss: 0.7244 - supervised_loss: 0.4973\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6561 - stacked_triplets_loss: 0.8569 - supervised_loss: 0.4532\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4981 - stacked_triplets_loss: 0.7013 - supervised_loss: 0.2946\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.8280 - stacked_triplets_loss: 0.7804 - supervised_loss: 0.8756\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9858 - stacked_triplets_loss: 1.1877 - supervised_loss: 0.7820\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8475 - stacked_triplets_loss: 0.9588 - supervised_loss: 0.7344\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4783 - stacked_triplets_loss: 0.5268 - supervised_loss: 0.4291\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7913 - stacked_triplets_loss: 0.8459 - supervised_loss: 0.7306\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7090 - stacked_triplets_loss: 0.7694 - supervised_loss: 0.6451\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.7453 - stacked_triplets_loss: 0.9036 - supervised_loss: 0.5870\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0277 - stacked_triplets_loss: 1.1942 - supervised_loss: 0.8499\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4627 - stacked_triplets_loss: 0.6532 - supervised_loss: 0.2721\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7241 - stacked_triplets_loss: 0.6362 - supervised_loss: 0.8121\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.7473 - stacked_triplets_loss: 0.7780 - supervised_loss: 0.7134\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.7016 - stacked_triplets_loss: 0.7947 - supervised_loss: 0.6086\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.8619 - stacked_triplets_loss: 0.7663 - supervised_loss: 0.9497\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4284 - stacked_triplets_loss: 0.5663 - supervised_loss: 0.2904\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6870 - stacked_triplets_loss: 0.8142 - supervised_loss: 0.5597\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.8001 - stacked_triplets_loss: 1.0729 - supervised_loss: 0.5247\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6998 - stacked_triplets_loss: 0.8336 - supervised_loss: 0.5660\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6748 - stacked_triplets_loss: 0.7225 - supervised_loss: 0.6270\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6094 - stacked_triplets_loss: 0.7333 - supervised_loss: 0.4840\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5767 - stacked_triplets_loss: 0.6031 - supervised_loss: 0.5476\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7829 - stacked_triplets_loss: 0.9062 - supervised_loss: 0.6595\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4906 - stacked_triplets_loss: 0.5268 - supervised_loss: 0.4535\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6973 - stacked_triplets_loss: 0.9099 - supervised_loss: 0.4811\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7433 - stacked_triplets_loss: 0.8339 - supervised_loss: 0.6480\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.3760 - stacked_triplets_loss: 0.4664 - supervised_loss: 0.2855\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.6471 - stacked_triplets_loss: 0.6120 - supervised_loss: 0.6721\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6299 - stacked_triplets_loss: 0.6171 - supervised_loss: 0.6429\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6306 - stacked_triplets_loss: 0.6925 - supervised_loss: 0.5687\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7409 - stacked_triplets_loss: 0.7417 - supervised_loss: 0.7357\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5805 - stacked_triplets_loss: 0.5540 - supervised_loss: 0.6070\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5459 - stacked_triplets_loss: 0.5592 - supervised_loss: 0.5325\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.6735 - stacked_triplets_loss: 0.7405 - supervised_loss: 0.6042\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7344 - stacked_triplets_loss: 0.7459 - supervised_loss: 0.7177\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3720 - stacked_triplets_loss: 0.4738 - supervised_loss: 0.2705\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5696 - stacked_triplets_loss: 0.4748 - supervised_loss: 0.6612\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6350 - stacked_triplets_loss: 0.6239 - supervised_loss: 0.6438\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5532 - stacked_triplets_loss: 0.6795 - supervised_loss: 0.4271\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4607 - stacked_triplets_loss: 0.5029 - supervised_loss: 0.4184\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7245 - stacked_triplets_loss: 0.6179 - supervised_loss: 0.8255\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6170 - stacked_triplets_loss: 0.6223 - supervised_loss: 0.6098\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6144 - stacked_triplets_loss: 0.7040 - supervised_loss: 0.5249\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5386 - stacked_triplets_loss: 0.5028 - supervised_loss: 0.5713\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5761 - stacked_triplets_loss: 0.6062 - supervised_loss: 0.5461\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4446 - stacked_triplets_loss: 0.4264 - supervised_loss: 0.4610\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4675 - stacked_triplets_loss: 0.4281 - supervised_loss: 0.5058\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5782 - stacked_triplets_loss: 0.6033 - supervised_loss: 0.5531\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5490 - stacked_triplets_loss: 0.5407 - supervised_loss: 0.5562\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5546 - stacked_triplets_loss: 0.5728 - supervised_loss: 0.5365\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5818 - stacked_triplets_loss: 0.5701 - supervised_loss: 0.5912\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6005 - stacked_triplets_loss: 0.6368 - supervised_loss: 0.5623\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3360 - stacked_triplets_loss: 0.4691 - supervised_loss: 0.2025\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6999 - stacked_triplets_loss: 0.5145 - supervised_loss: 0.8819\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4596 - stacked_triplets_loss: 0.4327 - supervised_loss: 0.4866\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3564 - stacked_triplets_loss: 0.3636 - supervised_loss: 0.3482\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4897 - stacked_triplets_loss: 0.5294 - supervised_loss: 0.4509\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.8310 - stacked_triplets_loss: 0.7366 - supervised_loss: 0.9253\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4817 - stacked_triplets_loss: 0.3943 - supervised_loss: 0.5695\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5779 - stacked_triplets_loss: 0.5414 - supervised_loss: 0.6133\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5775 - stacked_triplets_loss: 0.5656 - supervised_loss: 0.5856\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5776 - stacked_triplets_loss: 0.5021 - supervised_loss: 0.6486\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4783 - stacked_triplets_loss: 0.3870 - supervised_loss: 0.5696\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7386 - stacked_triplets_loss: 0.6568 - supervised_loss: 0.8195\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4222 - stacked_triplets_loss: 0.4790 - supervised_loss: 0.3642\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7242 - stacked_triplets_loss: 0.6608 - supervised_loss: 0.7877\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4280 - stacked_triplets_loss: 0.5132 - supervised_loss: 0.3434\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5195 - stacked_triplets_loss: 0.4850 - supervised_loss: 0.5529\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4786 - stacked_triplets_loss: 0.4073 - supervised_loss: 0.5478\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3220 - stacked_triplets_loss: 0.3568 - supervised_loss: 0.2873\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7054 - stacked_triplets_loss: 0.6631 - supervised_loss: 0.7428\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3718 - stacked_triplets_loss: 0.3253 - supervised_loss: 0.4193\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4994 - stacked_triplets_loss: 0.4603 - supervised_loss: 0.5400\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5665 - stacked_triplets_loss: 0.4767 - supervised_loss: 0.6523\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3175 - stacked_triplets_loss: 0.3591 - supervised_loss: 0.2752\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5172 - stacked_triplets_loss: 0.4602 - supervised_loss: 0.5728\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5464 - stacked_triplets_loss: 0.5731 - supervised_loss: 0.5197\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6897 - stacked_triplets_loss: 0.7130 - supervised_loss: 0.6630\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3423 - stacked_triplets_loss: 0.3879 - supervised_loss: 0.2958\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4523 - stacked_triplets_loss: 0.3801 - supervised_loss: 0.5221\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4667 - stacked_triplets_loss: 0.4145 - supervised_loss: 0.5157\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2725 - stacked_triplets_loss: 0.2413 - supervised_loss: 0.3033\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4659 - stacked_triplets_loss: 0.4083 - supervised_loss: 0.5235\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5799 - stacked_triplets_loss: 0.5891 - supervised_loss: 0.5681\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4781 - stacked_triplets_loss: 0.4205 - supervised_loss: 0.5335\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3716 - stacked_triplets_loss: 0.3801 - supervised_loss: 0.3639\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4991 - stacked_triplets_loss: 0.4464 - supervised_loss: 0.5493\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.5650 - stacked_triplets_loss: 0.5830 - supervised_loss: 0.5470\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4550 - stacked_triplets_loss: 0.4462 - supervised_loss: 0.4612\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4440 - stacked_triplets_loss: 0.3849 - supervised_loss: 0.5032\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5154 - stacked_triplets_loss: 0.5016 - supervised_loss: 0.5279\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4787 - stacked_triplets_loss: 0.3769 - supervised_loss: 0.5782\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5042 - stacked_triplets_loss: 0.4999 - supervised_loss: 0.5075\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4038 - stacked_triplets_loss: 0.4005 - supervised_loss: 0.4071\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3071 - stacked_triplets_loss: 0.2971 - supervised_loss: 0.3151\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5195 - stacked_triplets_loss: 0.4745 - supervised_loss: 0.5645\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5161 - stacked_triplets_loss: 0.5158 - supervised_loss: 0.5149\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4906 - stacked_triplets_loss: 0.4652 - supervised_loss: 0.5141\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3840 - stacked_triplets_loss: 0.2873 - supervised_loss: 0.4780\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3073 - stacked_triplets_loss: 0.3215 - supervised_loss: 0.2931\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5199 - stacked_triplets_loss: 0.4042 - supervised_loss: 0.6334\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4724 - stacked_triplets_loss: 0.5200 - supervised_loss: 0.4249\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4780 - stacked_triplets_loss: 0.3864 - supervised_loss: 0.5674\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3728 - stacked_triplets_loss: 0.3030 - supervised_loss: 0.4412\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5168 - stacked_triplets_loss: 0.3865 - supervised_loss: 0.6446\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3403 - stacked_triplets_loss: 0.3645 - supervised_loss: 0.3161\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4446 - stacked_triplets_loss: 0.3979 - supervised_loss: 0.4882\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6614 - stacked_triplets_loss: 0.5665 - supervised_loss: 0.7517\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3738 - stacked_triplets_loss: 0.3768 - supervised_loss: 0.3720\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4147 - stacked_triplets_loss: 0.3404 - supervised_loss: 0.4889\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5304 - stacked_triplets_loss: 0.5841 - supervised_loss: 0.4722\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3699 - stacked_triplets_loss: 0.3259 - supervised_loss: 0.4138\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5605 - stacked_triplets_loss: 0.5130 - supervised_loss: 0.6079\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3420 - stacked_triplets_loss: 0.3006 - supervised_loss: 0.3839\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4454 - stacked_triplets_loss: 0.4145 - supervised_loss: 0.4763\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4873 - stacked_triplets_loss: 0.4145 - supervised_loss: 0.5602\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.5231 - stacked_triplets_loss: 0.5038 - supervised_loss: 0.5383\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3056 - stacked_triplets_loss: 0.2260 - supervised_loss: 0.3882\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4864 - stacked_triplets_loss: 0.4411 - supervised_loss: 0.5318\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5183 - stacked_triplets_loss: 0.4064 - supervised_loss: 0.6251\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.4498 - stacked_triplets_loss: 0.4118 - supervised_loss: 0.4877\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4622 - stacked_triplets_loss: 0.4206 - supervised_loss: 0.5019\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4227 - stacked_triplets_loss: 0.3295 - supervised_loss: 0.5158\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3333 - stacked_triplets_loss: 0.3155 - supervised_loss: 0.3501\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3693 - stacked_triplets_loss: 0.3045 - supervised_loss: 0.4341\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4666 - stacked_triplets_loss: 0.4001 - supervised_loss: 0.5305\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4135 - stacked_triplets_loss: 0.3417 - supervised_loss: 0.4840\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3041 - stacked_triplets_loss: 0.3194 - supervised_loss: 0.2887\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5324 - stacked_triplets_loss: 0.4267 - supervised_loss: 0.6346\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5318 - stacked_triplets_loss: 0.3728 - supervised_loss: 0.6895\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3957 - stacked_triplets_loss: 0.3906 - supervised_loss: 0.4009\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3865 - stacked_triplets_loss: 0.3610 - supervised_loss: 0.4115\n",
      "745/745 [==============================] - 1s 2ms/sample\n"
     ]
    }
   ],
   "source": [
    "ivis = Ivis(embedding_dims=2, k=5)\n",
    "x_red = ivis.fit_transform(np.array(x), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7efb1bc72fd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_red.T[0], x_red.T[1], c=y, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well do we do (k=6)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       148\n",
      "           1       0.56      0.38      0.45        39\n",
      "\n",
      "    accuracy                           0.81       187\n",
      "   macro avg       0.70      0.65      0.67       187\n",
      "weighted avg       0.79      0.81      0.79       187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_red, y)\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "print(classification_report(y_test, svm.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       148\n",
      "           1       0.61      0.51      0.56        39\n",
      "\n",
      "    accuracy                           0.83       187\n",
      "   macro avg       0.74      0.71      0.72       187\n",
      "weighted avg       0.82      0.83      0.82       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well do we do (k=5)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       148\n",
      "           1       0.61      0.51      0.56        39\n",
      "\n",
      "    accuracy                           0.83       187\n",
      "   macro avg       0.74      0.71      0.72       187\n",
      "weighted avg       0.82      0.83      0.82       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(2, input_shape=(2,)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(2),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1),\n",
    "    BatchNormalization(),\n",
    "    Activation('sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "558/558 [==============================] - 5s 10ms/step - loss: 0.6051 - acc: 0.7616\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 0s 243us/step - loss: 0.5973 - acc: 0.7670\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 0s 250us/step - loss: 0.5952 - acc: 0.7563\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.5836 - acc: 0.7652\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.5822 - acc: 0.7616\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 0s 253us/step - loss: 0.5822 - acc: 0.7652\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 0s 240us/step - loss: 0.5814 - acc: 0.7563\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 0s 239us/step - loss: 0.5660 - acc: 0.7688\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.5733 - acc: 0.7760\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 0s 241us/step - loss: 0.5647 - acc: 0.7760\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 0s 238us/step - loss: 0.5679 - acc: 0.7581\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 0s 230us/step - loss: 0.5557 - acc: 0.7778\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 0s 240us/step - loss: 0.5617 - acc: 0.7581\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.5454 - acc: 0.7634\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 0s 239us/step - loss: 0.5346 - acc: 0.7885\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 0s 265us/step - loss: 0.5437 - acc: 0.7616\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 0s 240us/step - loss: 0.5297 - acc: 0.7885\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.5425 - acc: 0.7634\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 0s 250us/step - loss: 0.5365 - acc: 0.7760\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 0s 246us/step - loss: 0.5255 - acc: 0.7724\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 0.5139 - acc: 0.7742\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.5143 - acc: 0.7832\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 0s 264us/step - loss: 0.5181 - acc: 0.7688\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 0s 305us/step - loss: 0.5165 - acc: 0.7706\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 0s 284us/step - loss: 0.5023 - acc: 0.7903\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 0s 242us/step - loss: 0.4991 - acc: 0.7921\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 0s 240us/step - loss: 0.4988 - acc: 0.7903\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 0.4983 - acc: 0.7957\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 0s 288us/step - loss: 0.4959 - acc: 0.7796\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 0s 246us/step - loss: 0.4917 - acc: 0.7885\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.4873 - acc: 0.8082\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.4893 - acc: 0.7832\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 0s 267us/step - loss: 0.4853 - acc: 0.8011\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 0s 230us/step - loss: 0.4806 - acc: 0.8065\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 0s 227us/step - loss: 0.4821 - acc: 0.7903\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 0s 237us/step - loss: 0.4830 - acc: 0.7939\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 0s 238us/step - loss: 0.4765 - acc: 0.8029\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 0s 244us/step - loss: 0.4793 - acc: 0.7885\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 0s 227us/step - loss: 0.4787 - acc: 0.7814\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 0s 224us/step - loss: 0.4710 - acc: 0.8065\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.4678 - acc: 0.7903\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 0s 232us/step - loss: 0.4702 - acc: 0.7903\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 0s 237us/step - loss: 0.4767 - acc: 0.7814\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 0s 217us/step - loss: 0.4702 - acc: 0.7832\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 0s 261us/step - loss: 0.4648 - acc: 0.8082\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.4471 - acc: 0.8100\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.4569 - acc: 0.7993\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.4502 - acc: 0.8172\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 0s 338us/step - loss: 0.4527 - acc: 0.8082\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4548 - acc: 0.7832\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.4509 - acc: 0.8208\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 0s 257us/step - loss: 0.4420 - acc: 0.8208\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 0s 227us/step - loss: 0.4473 - acc: 0.8047\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 0s 234us/step - loss: 0.4425 - acc: 0.8154\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 0s 231us/step - loss: 0.4515 - acc: 0.8029\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 0s 241us/step - loss: 0.4384 - acc: 0.8172\n",
      "Epoch 57/100\n",
      "558/558 [==============================] - 0s 244us/step - loss: 0.4477 - acc: 0.7975\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 0s 242us/step - loss: 0.4449 - acc: 0.8047\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.4403 - acc: 0.8172\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 0s 271us/step - loss: 0.4302 - acc: 0.8226\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.4345 - acc: 0.8118\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 0s 256us/step - loss: 0.4315 - acc: 0.8172\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.4467 - acc: 0.7903\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 0s 249us/step - loss: 0.4326 - acc: 0.7975\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 0s 237us/step - loss: 0.4207 - acc: 0.8297\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 0s 259us/step - loss: 0.4254 - acc: 0.8047\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 0s 293us/step - loss: 0.4219 - acc: 0.8226\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 0s 289us/step - loss: 0.4455 - acc: 0.7957\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.4263 - acc: 0.8118\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.4177 - acc: 0.8280\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 0s 239us/step - loss: 0.4320 - acc: 0.8100\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 0s 231us/step - loss: 0.4293 - acc: 0.8190\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.4257 - acc: 0.8065\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 0s 266us/step - loss: 0.4320 - acc: 0.8029\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 0s 257us/step - loss: 0.4266 - acc: 0.8118\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 0s 252us/step - loss: 0.4172 - acc: 0.8297\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 0s 248us/step - loss: 0.4187 - acc: 0.8172\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.4260 - acc: 0.8190\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4242 - acc: 0.8172\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 0s 262us/step - loss: 0.4164 - acc: 0.8136\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 0s 395us/step - loss: 0.4290 - acc: 0.8011\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.4171 - acc: 0.8136\n",
      "Epoch 83/100\n",
      "558/558 [==============================] - 0s 333us/step - loss: 0.4133 - acc: 0.7903\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 0s 349us/step - loss: 0.4081 - acc: 0.8190\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 0s 406us/step - loss: 0.4134 - acc: 0.8082\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 0s 326us/step - loss: 0.4091 - acc: 0.8154\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 0s 317us/step - loss: 0.4139 - acc: 0.8154\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 0s 258us/step - loss: 0.4331 - acc: 0.7903\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 0s 275us/step - loss: 0.4151 - acc: 0.8029\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4196 - acc: 0.8047\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 0s 298us/step - loss: 0.4192 - acc: 0.8082\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.4160 - acc: 0.8172\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4204 - acc: 0.7921\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 0s 242us/step - loss: 0.4086 - acc: 0.8280\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 0s 232us/step - loss: 0.4191 - acc: 0.8172\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 0s 281us/step - loss: 0.4082 - acc: 0.8190\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 0s 287us/step - loss: 0.4128 - acc: 0.8118\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 0s 243us/step - loss: 0.4121 - acc: 0.8172\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 0s 246us/step - loss: 0.4194 - acc: 0.8100\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 0s 260us/step - loss: 0.4093 - acc: 0.8262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb1df63ad0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       148\n",
      "           1       0.68      0.44      0.53        39\n",
      "\n",
      "    accuracy                           0.84       187\n",
      "   macro avg       0.77      0.69      0.72       187\n",
      "weighted avg       0.83      0.84      0.83       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53125"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model.predict_classes(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: k=3-7 were tested. These were the best two results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do 3 dimensions work better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 47064.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building KNN index\n",
      "Extracting KNN from index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 745/745 [00:00<00:00, 5218.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 9s 2s/step - loss: 37.4848 - stacked_triplets_loss: 13.5910 - supervised_loss: 61.3787\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 14.0743 - stacked_triplets_loss: 11.4449 - supervised_loss: 16.5022\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 16.7139 - stacked_triplets_loss: 6.6228 - supervised_loss: 26.8049\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 12.7616 - stacked_triplets_loss: 13.0407 - supervised_loss: 12.5390\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 10.6779 - stacked_triplets_loss: 10.6089 - supervised_loss: 10.7214\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.8756 - stacked_triplets_loss: 4.9767 - supervised_loss: 2.7854\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 3.2559 - stacked_triplets_loss: 4.3049 - supervised_loss: 2.1976\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 10.6229 - stacked_triplets_loss: 9.1370 - supervised_loss: 12.0273\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 5.6183 - stacked_triplets_loss: 3.5901 - supervised_loss: 7.6464\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 4.8944 - stacked_triplets_loss: 4.5866 - supervised_loss: 5.2112\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 5.5844 - stacked_triplets_loss: 6.7495 - supervised_loss: 4.3989\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6363 - stacked_triplets_loss: 4.6204 - supervised_loss: 4.6185\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 4.9198 - stacked_triplets_loss: 5.3260 - supervised_loss: 4.4737\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 4.4918 - stacked_triplets_loss: 4.8228 - supervised_loss: 4.1607\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 4.8098 - stacked_triplets_loss: 5.0171 - supervised_loss: 4.5992\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.7261 - stacked_triplets_loss: 2.2354 - supervised_loss: 1.2205\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 5.5743 - stacked_triplets_loss: 4.6376 - supervised_loss: 6.4688\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6903 - stacked_triplets_loss: 3.0261 - supervised_loss: 2.3640\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.6451 - stacked_triplets_loss: 4.4700 - supervised_loss: 2.8201\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 3.1454 - stacked_triplets_loss: 3.2763 - supervised_loss: 3.0228\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.6077 - stacked_triplets_loss: 2.3926 - supervised_loss: 0.8137\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 4.2097 - stacked_triplets_loss: 2.6503 - supervised_loss: 5.7434\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 3.3031 - stacked_triplets_loss: 4.0712 - supervised_loss: 2.5350\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.9083 - stacked_triplets_loss: 2.8732 - supervised_loss: 2.9403\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 2.2548 - stacked_triplets_loss: 2.5666 - supervised_loss: 1.9408\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 2.7624 - stacked_triplets_loss: 3.4117 - supervised_loss: 2.0985\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 2.3724 - stacked_triplets_loss: 3.1099 - supervised_loss: 1.6349\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.1264 - stacked_triplets_loss: 2.3048 - supervised_loss: 1.9377\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.9850 - stacked_triplets_loss: 2.2530 - supervised_loss: 1.7416\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.7089 - stacked_triplets_loss: 2.4098 - supervised_loss: 2.9855\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 3.1575 - stacked_triplets_loss: 3.0031 - supervised_loss: 3.3025\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.4438 - stacked_triplets_loss: 2.3305 - supervised_loss: 2.5502\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.7780 - stacked_triplets_loss: 1.9413 - supervised_loss: 1.6147\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.8546 - stacked_triplets_loss: 1.6899 - supervised_loss: 2.0100\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.9904 - stacked_triplets_loss: 1.0045 - supervised_loss: 0.9798\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.5606 - stacked_triplets_loss: 3.2657 - supervised_loss: 1.8624\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 2.4615 - stacked_triplets_loss: 2.6932 - supervised_loss: 2.2475\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2575 - stacked_triplets_loss: 1.0935 - supervised_loss: 1.4215\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.2475 - stacked_triplets_loss: 2.2039 - supervised_loss: 2.2803\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.0129 - stacked_triplets_loss: 0.9573 - supervised_loss: 1.0699\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.5693 - stacked_triplets_loss: 1.7561 - supervised_loss: 1.3826\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.6057 - stacked_triplets_loss: 1.6401 - supervised_loss: 1.5651\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.6236 - stacked_triplets_loss: 1.7736 - supervised_loss: 1.4699\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.7803 - stacked_triplets_loss: 2.1830 - supervised_loss: 1.3776\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4426 - stacked_triplets_loss: 1.4192 - supervised_loss: 1.4505\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.8771 - stacked_triplets_loss: 0.9630 - supervised_loss: 0.7912\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.2857 - stacked_triplets_loss: 1.2970 - supervised_loss: 1.2660\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4758 - stacked_triplets_loss: 1.6028 - supervised_loss: 1.3424\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.8022 - stacked_triplets_loss: 2.1543 - supervised_loss: 1.4500\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4390 - stacked_triplets_loss: 1.6999 - supervised_loss: 1.1738\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.8619 - stacked_triplets_loss: 1.8949 - supervised_loss: 1.8289\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5253 - stacked_triplets_loss: 0.6242 - supervised_loss: 0.4265\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.1587 - stacked_triplets_loss: 1.2584 - supervised_loss: 1.0530\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.2132 - stacked_triplets_loss: 1.3979 - supervised_loss: 1.0285\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4667 - stacked_triplets_loss: 1.5821 - supervised_loss: 1.3514\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7787 - stacked_triplets_loss: 0.8097 - supervised_loss: 0.7478\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 2.0259 - stacked_triplets_loss: 2.3535 - supervised_loss: 1.6710\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.9374 - stacked_triplets_loss: 1.0092 - supervised_loss: 0.8656\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8746 - stacked_triplets_loss: 0.8392 - supervised_loss: 0.9143\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.2193 - stacked_triplets_loss: 1.4527 - supervised_loss: 0.9966\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7358 - stacked_triplets_loss: 0.8206 - supervised_loss: 0.6528\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.0533 - stacked_triplets_loss: 1.6658 - supervised_loss: 2.4251\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.3428 - stacked_triplets_loss: 1.3021 - supervised_loss: 1.3837\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9156 - stacked_triplets_loss: 0.7912 - supervised_loss: 1.0399\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1938 - stacked_triplets_loss: 1.0676 - supervised_loss: 1.3084\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0222 - stacked_triplets_loss: 0.9755 - supervised_loss: 1.0689\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5955 - stacked_triplets_loss: 0.6609 - supervised_loss: 0.5307\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9079 - stacked_triplets_loss: 0.8667 - supervised_loss: 0.9473\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0562 - stacked_triplets_loss: 1.1087 - supervised_loss: 1.0045\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.2047 - stacked_triplets_loss: 1.1758 - supervised_loss: 1.2337\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7175 - stacked_triplets_loss: 0.6117 - supervised_loss: 0.8239\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8916 - stacked_triplets_loss: 0.8792 - supervised_loss: 0.9040\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6582 - stacked_triplets_loss: 0.6132 - supervised_loss: 0.7038\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.9403 - stacked_triplets_loss: 0.9800 - supervised_loss: 0.8967\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.4383 - stacked_triplets_loss: 1.3903 - supervised_loss: 1.4824\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.1348 - stacked_triplets_loss: 1.2697 - supervised_loss: 0.9999\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.8276 - stacked_triplets_loss: 0.6214 - supervised_loss: 1.0305\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5061 - stacked_triplets_loss: 0.6315 - supervised_loss: 0.3809\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9916 - stacked_triplets_loss: 0.8332 - supervised_loss: 1.1447\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.1227 - stacked_triplets_loss: 1.3100 - supervised_loss: 0.9355\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7214 - stacked_triplets_loss: 0.6339 - supervised_loss: 0.8090\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7392 - stacked_triplets_loss: 0.7346 - supervised_loss: 0.7452\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5605 - stacked_triplets_loss: 0.5466 - supervised_loss: 0.5735\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.8499 - stacked_triplets_loss: 0.6681 - supervised_loss: 1.0317\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.0427 - stacked_triplets_loss: 0.8409 - supervised_loss: 1.2398\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.8126 - stacked_triplets_loss: 0.7468 - supervised_loss: 0.8783\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.8161 - stacked_triplets_loss: 0.5624 - supervised_loss: 1.0695\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5397 - stacked_triplets_loss: 0.5453 - supervised_loss: 0.5337\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9158 - stacked_triplets_loss: 0.7717 - supervised_loss: 1.0530\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7554 - stacked_triplets_loss: 0.6930 - supervised_loss: 0.8155\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5608 - stacked_triplets_loss: 0.5937 - supervised_loss: 0.5285\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7638 - stacked_triplets_loss: 0.6563 - supervised_loss: 0.8705\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6703 - stacked_triplets_loss: 0.6457 - supervised_loss: 0.6915\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6659 - stacked_triplets_loss: 0.7782 - supervised_loss: 0.5536\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.8445 - stacked_triplets_loss: 0.6263 - supervised_loss: 1.0612\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7324 - stacked_triplets_loss: 0.6571 - supervised_loss: 0.8071\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7976 - stacked_triplets_loss: 0.5876 - supervised_loss: 1.0053\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3644 - stacked_triplets_loss: 0.5528 - supervised_loss: 0.1802\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.0682 - stacked_triplets_loss: 0.8279 - supervised_loss: 1.3026\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5492 - stacked_triplets_loss: 0.3981 - supervised_loss: 0.7003\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6391 - stacked_triplets_loss: 0.6622 - supervised_loss: 0.6178\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.7255 - stacked_triplets_loss: 0.7561 - supervised_loss: 0.6929\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.8089 - stacked_triplets_loss: 0.7537 - supervised_loss: 0.8608\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5721 - stacked_triplets_loss: 0.6064 - supervised_loss: 0.5385\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7831 - stacked_triplets_loss: 0.7840 - supervised_loss: 0.7828\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5378 - stacked_triplets_loss: 0.4844 - supervised_loss: 0.5911\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6057 - stacked_triplets_loss: 0.5700 - supervised_loss: 0.6399\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6759 - stacked_triplets_loss: 0.5235 - supervised_loss: 0.8240\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4532 - stacked_triplets_loss: 0.5421 - supervised_loss: 0.3664\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.8456 - stacked_triplets_loss: 0.7677 - supervised_loss: 0.9209\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5609 - stacked_triplets_loss: 0.4963 - supervised_loss: 0.6255\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5734 - stacked_triplets_loss: 0.6200 - supervised_loss: 0.5244\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5607 - stacked_triplets_loss: 0.4969 - supervised_loss: 0.6244\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.8024 - stacked_triplets_loss: 0.7175 - supervised_loss: 0.8840\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6753 - stacked_triplets_loss: 0.7178 - supervised_loss: 0.6291\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6149 - stacked_triplets_loss: 0.5288 - supervised_loss: 0.7010\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6933 - stacked_triplets_loss: 0.6850 - supervised_loss: 0.7001\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5617 - stacked_triplets_loss: 0.4932 - supervised_loss: 0.6301\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4139 - stacked_triplets_loss: 0.4391 - supervised_loss: 0.3886\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7379 - stacked_triplets_loss: 0.5875 - supervised_loss: 0.8861\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5604 - stacked_triplets_loss: 0.4572 - supervised_loss: 0.6631\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6649 - stacked_triplets_loss: 0.7039 - supervised_loss: 0.6259\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.7674 - stacked_triplets_loss: 0.7732 - supervised_loss: 0.7565\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3935 - stacked_triplets_loss: 0.4477 - supervised_loss: 0.3392\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7892 - stacked_triplets_loss: 0.6260 - supervised_loss: 0.9506\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5480 - stacked_triplets_loss: 0.4518 - supervised_loss: 0.6414\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7637 - stacked_triplets_loss: 0.6300 - supervised_loss: 0.8956\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6676 - stacked_triplets_loss: 0.6571 - supervised_loss: 0.6780\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6787 - stacked_triplets_loss: 0.6367 - supervised_loss: 0.7212\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4712 - stacked_triplets_loss: 0.3846 - supervised_loss: 0.5572\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6386 - stacked_triplets_loss: 0.6870 - supervised_loss: 0.5903\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5782 - stacked_triplets_loss: 0.3946 - supervised_loss: 0.7594\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6425 - stacked_triplets_loss: 0.5680 - supervised_loss: 0.7160\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5158 - stacked_triplets_loss: 0.3851 - supervised_loss: 0.6466\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5247 - stacked_triplets_loss: 0.3999 - supervised_loss: 0.6476\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4771 - stacked_triplets_loss: 0.5867 - supervised_loss: 0.3698\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6145 - stacked_triplets_loss: 0.4832 - supervised_loss: 0.7458\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5802 - stacked_triplets_loss: 0.5720 - supervised_loss: 0.5865\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5891 - stacked_triplets_loss: 0.5428 - supervised_loss: 0.6339\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3754 - stacked_triplets_loss: 0.4613 - supervised_loss: 0.2897\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7103 - stacked_triplets_loss: 0.4477 - supervised_loss: 0.9729\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7085 - stacked_triplets_loss: 0.5540 - supervised_loss: 0.8547\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5920 - stacked_triplets_loss: 0.5506 - supervised_loss: 0.6334\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5782 - stacked_triplets_loss: 0.3614 - supervised_loss: 0.7987\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5035 - stacked_triplets_loss: 0.4048 - supervised_loss: 0.6022\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6174 - stacked_triplets_loss: 0.4387 - supervised_loss: 0.7939\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3554 - stacked_triplets_loss: 0.3911 - supervised_loss: 0.3185\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6790 - stacked_triplets_loss: 0.4564 - supervised_loss: 0.8978\n",
      "745/745 [==============================] - 2s 3ms/sample\n"
     ]
    }
   ],
   "source": [
    "ivis = Ivis(embedding_dims=3, k=3)\n",
    "x_red = ivis.fit_transform(np.array(x), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_red, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       149\n",
      "           1       0.47      0.42      0.44        38\n",
      "\n",
      "    accuracy                           0.79       187\n",
      "   macro avg       0.66      0.65      0.66       187\n",
      "weighted avg       0.78      0.79      0.78       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "558/558 [==============================] - 8s 13ms/step - loss: 0.6932 - acc: 0.4875\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 0s 261us/step - loss: 0.6650 - acc: 0.5269\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.6440 - acc: 0.5323\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 0s 252us/step - loss: 0.6366 - acc: 0.5323\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 0s 244us/step - loss: 0.6206 - acc: 0.5520\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 0s 264us/step - loss: 0.6083 - acc: 0.5591\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 0s 262us/step - loss: 0.6051 - acc: 0.6290\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 0s 325us/step - loss: 0.5942 - acc: 0.6756\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 0s 339us/step - loss: 0.5833 - acc: 0.6720\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 0s 268us/step - loss: 0.5848 - acc: 0.6918\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 0s 259us/step - loss: 0.5753 - acc: 0.7115\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 0s 253us/step - loss: 0.5695 - acc: 0.7330\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.5677 - acc: 0.7348\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 0s 251us/step - loss: 0.5551 - acc: 0.7491\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.5516 - acc: 0.7563\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.5569 - acc: 0.7599\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 0s 243us/step - loss: 0.5498 - acc: 0.7563\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 0s 268us/step - loss: 0.5390 - acc: 0.7814\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.5374 - acc: 0.7796\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 0s 255us/step - loss: 0.5327 - acc: 0.7796\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 0s 252us/step - loss: 0.5294 - acc: 0.7867\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.5257 - acc: 0.7778\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 0s 255us/step - loss: 0.5246 - acc: 0.7867\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 0s 336us/step - loss: 0.5215 - acc: 0.7903\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 0s 307us/step - loss: 0.5239 - acc: 0.7832\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 0s 268us/step - loss: 0.5129 - acc: 0.7939\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 0s 261us/step - loss: 0.5202 - acc: 0.7993\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 0.5147 - acc: 0.7885\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 0.5020 - acc: 0.7957\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4952 - acc: 0.8029\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 0s 265us/step - loss: 0.4984 - acc: 0.7885\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4991 - acc: 0.7975\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 0s 257us/step - loss: 0.4983 - acc: 0.8011\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.4939 - acc: 0.8100\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.4926 - acc: 0.8082\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4900 - acc: 0.8047\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 0s 257us/step - loss: 0.4866 - acc: 0.8011\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 0s 302us/step - loss: 0.4855 - acc: 0.7921\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 0s 316us/step - loss: 0.4805 - acc: 0.8029\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 0s 278us/step - loss: 0.4823 - acc: 0.8065\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 0s 297us/step - loss: 0.4850 - acc: 0.7921\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 0s 297us/step - loss: 0.4805 - acc: 0.7975\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 0.4738 - acc: 0.8172\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 0s 282us/step - loss: 0.4736 - acc: 0.8100\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 0s 264us/step - loss: 0.4723 - acc: 0.7993\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 0s 260us/step - loss: 0.4701 - acc: 0.8172\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 0s 249us/step - loss: 0.4645 - acc: 0.8082\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 0s 256us/step - loss: 0.4641 - acc: 0.8029\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 0.4685 - acc: 0.7975\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 0s 303us/step - loss: 0.4650 - acc: 0.8065\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 0s 344us/step - loss: 0.4610 - acc: 0.8118\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 0.4560 - acc: 0.8208\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 0s 344us/step - loss: 0.4583 - acc: 0.8172\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 0s 338us/step - loss: 0.4511 - acc: 0.8029\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 0s 306us/step - loss: 0.4547 - acc: 0.8065\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 0s 303us/step - loss: 0.4557 - acc: 0.8047\n",
      "Epoch 57/100\n",
      "558/558 [==============================] - 0s 283us/step - loss: 0.4505 - acc: 0.8082\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.4503 - acc: 0.8136\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 0s 260us/step - loss: 0.4493 - acc: 0.8100\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 0s 255us/step - loss: 0.4517 - acc: 0.8154\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 0s 275us/step - loss: 0.4497 - acc: 0.8065\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 0s 307us/step - loss: 0.4428 - acc: 0.8208\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4464 - acc: 0.8118\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.4407 - acc: 0.8118\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 0s 287us/step - loss: 0.4442 - acc: 0.8190\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 0s 310us/step - loss: 0.4378 - acc: 0.8154\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 0s 333us/step - loss: 0.4451 - acc: 0.8047\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 0s 288us/step - loss: 0.4373 - acc: 0.8047\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 0s 294us/step - loss: 0.4416 - acc: 0.7957\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 0s 275us/step - loss: 0.4384 - acc: 0.8082\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 0.4379 - acc: 0.8190\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 0s 260us/step - loss: 0.4401 - acc: 0.8082\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 0s 278us/step - loss: 0.4379 - acc: 0.8082\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 0s 266us/step - loss: 0.4394 - acc: 0.8082\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 0.4298 - acc: 0.8082\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 0s 256us/step - loss: 0.4276 - acc: 0.8118\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 0s 252us/step - loss: 0.4322 - acc: 0.8047\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 0s 258us/step - loss: 0.4375 - acc: 0.8029\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 0s 241us/step - loss: 0.4374 - acc: 0.8154\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 0s 235us/step - loss: 0.4284 - acc: 0.8082\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 0s 253us/step - loss: 0.4305 - acc: 0.8172\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 0s 246us/step - loss: 0.4284 - acc: 0.8118\n",
      "Epoch 83/100\n",
      "558/558 [==============================] - 0s 282us/step - loss: 0.4268 - acc: 0.8100\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.4225 - acc: 0.8029\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 0s 265us/step - loss: 0.4380 - acc: 0.8047\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 0s 289us/step - loss: 0.4287 - acc: 0.8065\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 0s 339us/step - loss: 0.4266 - acc: 0.7993\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 0s 281us/step - loss: 0.4292 - acc: 0.8118\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 0s 260us/step - loss: 0.4251 - acc: 0.8154\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 0.4250 - acc: 0.8136\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 0s 268us/step - loss: 0.4259 - acc: 0.8065\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4201 - acc: 0.8065\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 0s 303us/step - loss: 0.4191 - acc: 0.8154\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 0s 251us/step - loss: 0.4255 - acc: 0.8154\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 0.4249 - acc: 0.8011\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 0s 262us/step - loss: 0.4220 - acc: 0.8190\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 0.4287 - acc: 0.7832\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 0s 266us/step - loss: 0.4154 - acc: 0.8082\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 0s 260us/step - loss: 0.4158 - acc: 0.8047\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 0s 261us/step - loss: 0.4330 - acc: 0.7975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       149\n",
      "           1       0.46      0.45      0.45        38\n",
      "\n",
      "    accuracy                           0.78       187\n",
      "   macro avg       0.66      0.66      0.66       187\n",
      "weighted avg       0.78      0.78      0.78       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(3,)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1),\n",
    "    BatchNormalization(),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)\n",
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 37385.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building KNN index\n",
      "Extracting KNN from index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 745/745 [00:00<00:00, 3978.39it/s]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1025 22:05:40.352408 139779904788096 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4075: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1025 22:05:40.812964 139779904788096 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 10s 2s/step - loss: 13.6346 - stacked_triplets_loss: 12.6352 - supervised_loss: 14.6340\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 10.8724 - stacked_triplets_loss: 10.3863 - supervised_loss: 11.3934\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 12.2327 - stacked_triplets_loss: 16.6476 - supervised_loss: 7.8178\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 4.7268 - stacked_triplets_loss: 4.9716 - supervised_loss: 4.5213\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 8.6785 - stacked_triplets_loss: 11.0166 - supervised_loss: 6.2859\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 5.9996 - stacked_triplets_loss: 6.7081 - supervised_loss: 5.2917\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 4.2127 - stacked_triplets_loss: 5.4876 - supervised_loss: 2.9670\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 4.9437 - stacked_triplets_loss: 6.3904 - supervised_loss: 3.4720\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 5.6403 - stacked_triplets_loss: 5.9899 - supervised_loss: 5.2848\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 4.4841 - stacked_triplets_loss: 5.8155 - supervised_loss: 3.1527\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 4.0960 - stacked_triplets_loss: 4.9912 - supervised_loss: 3.1964\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.9653 - stacked_triplets_loss: 4.6909 - supervised_loss: 3.2155\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 3.9027 - stacked_triplets_loss: 4.4186 - supervised_loss: 3.3868\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 2.6494 - stacked_triplets_loss: 2.2395 - supervised_loss: 3.0544\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 5.0709 - stacked_triplets_loss: 7.1162 - supervised_loss: 3.0095\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.1168 - stacked_triplets_loss: 2.7194 - supervised_loss: 1.5135\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 3.3550 - stacked_triplets_loss: 3.0820 - supervised_loss: 3.6280\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.0391 - stacked_triplets_loss: 4.1026 - supervised_loss: 1.9685\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2.7127 - stacked_triplets_loss: 3.1670 - supervised_loss: 2.2465\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 2.5039 - stacked_triplets_loss: 3.3483 - supervised_loss: 1.6596\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.9761 - stacked_triplets_loss: 2.5644 - supervised_loss: 1.4086\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 2.7966 - stacked_triplets_loss: 2.6309 - supervised_loss: 2.9498\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.3346 - stacked_triplets_loss: 3.2345 - supervised_loss: 1.4303\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.3777 - stacked_triplets_loss: 3.1121 - supervised_loss: 1.6433\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 2.2328 - stacked_triplets_loss: 2.7046 - supervised_loss: 1.7554\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.6396 - stacked_triplets_loss: 3.2968 - supervised_loss: 1.9635\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.5465 - stacked_triplets_loss: 1.9739 - supervised_loss: 1.1191\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 3.5614 - stacked_triplets_loss: 4.7961 - supervised_loss: 2.2978\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.6151 - stacked_triplets_loss: 2.3465 - supervised_loss: 0.8956\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.1335 - stacked_triplets_loss: 2.3936 - supervised_loss: 1.8649\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.2612 - stacked_triplets_loss: 1.7853 - supervised_loss: 0.7341\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.9664 - stacked_triplets_loss: 2.0340 - supervised_loss: 1.8875\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 2.0977 - stacked_triplets_loss: 2.1878 - supervised_loss: 2.0076\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.3206 - stacked_triplets_loss: 2.9346 - supervised_loss: 1.6982\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.3707 - stacked_triplets_loss: 4.3076 - supervised_loss: 2.4288\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.9584 - stacked_triplets_loss: 1.1178 - supervised_loss: 0.8018\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.5546 - stacked_triplets_loss: 1.7510 - supervised_loss: 1.3570\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.5539 - stacked_triplets_loss: 1.8568 - supervised_loss: 1.2508\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.0064 - stacked_triplets_loss: 1.2696 - supervised_loss: 0.7432\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8381 - stacked_triplets_loss: 1.7793 - supervised_loss: 1.8839\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2.1598 - stacked_triplets_loss: 3.1603 - supervised_loss: 1.1545\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1104 - stacked_triplets_loss: 1.2024 - supervised_loss: 1.0351\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.5181 - stacked_triplets_loss: 1.7856 - supervised_loss: 1.2394\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4120 - stacked_triplets_loss: 1.6774 - supervised_loss: 1.1341\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.1252 - stacked_triplets_loss: 1.1734 - supervised_loss: 1.0809\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7435 - stacked_triplets_loss: 0.7766 - supervised_loss: 0.7093\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1278 - stacked_triplets_loss: 1.3502 - supervised_loss: 0.9053\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1255 - stacked_triplets_loss: 1.2111 - supervised_loss: 1.0340\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.2236 - stacked_triplets_loss: 1.5332 - supervised_loss: 0.9068\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.1271 - stacked_triplets_loss: 1.4743 - supervised_loss: 0.7798\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.4561 - stacked_triplets_loss: 2.0143 - supervised_loss: 0.9060\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6753 - stacked_triplets_loss: 0.6716 - supervised_loss: 0.6806\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.4770 - stacked_triplets_loss: 1.6937 - supervised_loss: 1.2532\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5949 - stacked_triplets_loss: 2.2216 - supervised_loss: 0.9734\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.2361 - stacked_triplets_loss: 1.2891 - supervised_loss: 1.1753\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5122 - stacked_triplets_loss: 0.7094 - supervised_loss: 0.3157\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.6710 - stacked_triplets_loss: 1.7008 - supervised_loss: 1.6411\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8553 - stacked_triplets_loss: 0.8066 - supervised_loss: 0.9077\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 54ms/step - loss: 1.2024 - stacked_triplets_loss: 1.5958 - supervised_loss: 0.8090\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.2919 - stacked_triplets_loss: 1.5387 - supervised_loss: 1.0360\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0357 - stacked_triplets_loss: 1.1557 - supervised_loss: 0.9129\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5200 - stacked_triplets_loss: 0.6299 - supervised_loss: 0.4129\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.4116 - stacked_triplets_loss: 1.7952 - supervised_loss: 1.0316\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.0660 - stacked_triplets_loss: 1.2730 - supervised_loss: 0.8590\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0391 - stacked_triplets_loss: 1.2725 - supervised_loss: 0.8115\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.2190 - stacked_triplets_loss: 1.5499 - supervised_loss: 0.8797\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0584 - stacked_triplets_loss: 1.2120 - supervised_loss: 0.8982\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4802 - stacked_triplets_loss: 0.5552 - supervised_loss: 0.4070\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.0595 - stacked_triplets_loss: 1.2790 - supervised_loss: 0.8400\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7972 - stacked_triplets_loss: 0.8595 - supervised_loss: 0.7314\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.0042 - stacked_triplets_loss: 1.2080 - supervised_loss: 0.7990\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9496 - stacked_triplets_loss: 1.1026 - supervised_loss: 0.7961\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5697 - stacked_triplets_loss: 0.7757 - supervised_loss: 0.3666\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.0616 - stacked_triplets_loss: 0.8034 - supervised_loss: 1.3162\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6653 - stacked_triplets_loss: 0.8009 - supervised_loss: 0.5297\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.0689 - stacked_triplets_loss: 1.2410 - supervised_loss: 0.8912\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8168 - stacked_triplets_loss: 0.9058 - supervised_loss: 0.7300\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.8670 - stacked_triplets_loss: 1.0152 - supervised_loss: 0.7133\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0348 - stacked_triplets_loss: 1.1080 - supervised_loss: 0.9577\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9479 - stacked_triplets_loss: 1.1847 - supervised_loss: 0.7112\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7561 - stacked_triplets_loss: 0.8225 - supervised_loss: 0.6887\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8346 - stacked_triplets_loss: 0.8527 - supervised_loss: 0.8153\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4764 - stacked_triplets_loss: 0.7003 - supervised_loss: 0.2543\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7269 - stacked_triplets_loss: 0.5722 - supervised_loss: 0.8760\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5419 - stacked_triplets_loss: 0.6744 - supervised_loss: 0.4130\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.3633 - stacked_triplets_loss: 1.3723 - supervised_loss: 1.3485\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6986 - stacked_triplets_loss: 0.7536 - supervised_loss: 0.6436\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8108 - stacked_triplets_loss: 0.7662 - supervised_loss: 0.8503\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5223 - stacked_triplets_loss: 0.5595 - supervised_loss: 0.4883\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8626 - stacked_triplets_loss: 0.9070 - supervised_loss: 0.8182\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7169 - stacked_triplets_loss: 0.7208 - supervised_loss: 0.7087\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.8632 - stacked_triplets_loss: 0.8173 - supervised_loss: 0.9090\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8833 - stacked_triplets_loss: 1.0321 - supervised_loss: 0.7394\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8060 - stacked_triplets_loss: 0.7551 - supervised_loss: 0.8538\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5087 - stacked_triplets_loss: 0.5149 - supervised_loss: 0.5025\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6486 - stacked_triplets_loss: 0.6985 - supervised_loss: 0.5959\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7660 - stacked_triplets_loss: 0.7319 - supervised_loss: 0.8000\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6697 - stacked_triplets_loss: 0.7023 - supervised_loss: 0.6355\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4286 - stacked_triplets_loss: 0.4205 - supervised_loss: 0.4366\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7344 - stacked_triplets_loss: 0.8581 - supervised_loss: 0.6030\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8680 - stacked_triplets_loss: 1.1029 - supervised_loss: 0.6331\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.7296 - stacked_triplets_loss: 0.8287 - supervised_loss: 0.6376\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6636 - stacked_triplets_loss: 0.5245 - supervised_loss: 0.7986\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.5917 - stacked_triplets_loss: 0.5388 - supervised_loss: 0.6446\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4253 - stacked_triplets_loss: 0.4138 - supervised_loss: 0.4356\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6040 - stacked_triplets_loss: 0.6592 - supervised_loss: 0.5474\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5645 - stacked_triplets_loss: 0.4589 - supervised_loss: 0.6683\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6993 - stacked_triplets_loss: 0.7911 - supervised_loss: 0.6076\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6167 - stacked_triplets_loss: 0.6383 - supervised_loss: 0.5933\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.8074 - stacked_triplets_loss: 0.9232 - supervised_loss: 0.6912\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4174 - stacked_triplets_loss: 0.3486 - supervised_loss: 0.4868\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7926 - stacked_triplets_loss: 0.7356 - supervised_loss: 0.8496\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4611 - stacked_triplets_loss: 0.4275 - supervised_loss: 0.4948\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7783 - stacked_triplets_loss: 0.8153 - supervised_loss: 0.7386\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6549 - stacked_triplets_loss: 0.7073 - supervised_loss: 0.6026\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5837 - stacked_triplets_loss: 0.4898 - supervised_loss: 0.6745\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5991 - stacked_triplets_loss: 0.5820 - supervised_loss: 0.6147\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4683 - stacked_triplets_loss: 0.4199 - supervised_loss: 0.5181\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5993 - stacked_triplets_loss: 0.4706 - supervised_loss: 0.7280\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6267 - stacked_triplets_loss: 0.7338 - supervised_loss: 0.5267\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5459 - stacked_triplets_loss: 0.5185 - supervised_loss: 0.5733\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.6124 - stacked_triplets_loss: 0.5514 - supervised_loss: 0.6731\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5649 - stacked_triplets_loss: 0.5550 - supervised_loss: 0.5747\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5857 - stacked_triplets_loss: 0.5194 - supervised_loss: 0.6491\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3366 - stacked_triplets_loss: 0.2810 - supervised_loss: 0.3924\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7667 - stacked_triplets_loss: 0.8421 - supervised_loss: 0.6899\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6350 - stacked_triplets_loss: 0.6832 - supervised_loss: 0.5827\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5044 - stacked_triplets_loss: 0.4827 - supervised_loss: 0.5268\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5818 - stacked_triplets_loss: 0.6653 - supervised_loss: 0.4995\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.8147 - stacked_triplets_loss: 0.8495 - supervised_loss: 0.7756\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3901 - stacked_triplets_loss: 0.3663 - supervised_loss: 0.4139\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5054 - stacked_triplets_loss: 0.4271 - supervised_loss: 0.5814\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6102 - stacked_triplets_loss: 0.6014 - supervised_loss: 0.6176\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4991 - stacked_triplets_loss: 0.5142 - supervised_loss: 0.4840\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5094 - stacked_triplets_loss: 0.5900 - supervised_loss: 0.4274\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6293 - stacked_triplets_loss: 0.5708 - supervised_loss: 0.6799\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5114 - stacked_triplets_loss: 0.4931 - supervised_loss: 0.5296\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4675 - stacked_triplets_loss: 0.4571 - supervised_loss: 0.4792\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4846 - stacked_triplets_loss: 0.4249 - supervised_loss: 0.5453\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4062 - stacked_triplets_loss: 0.4435 - supervised_loss: 0.3713\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.7521 - stacked_triplets_loss: 0.5426 - supervised_loss: 0.9615\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4456 - stacked_triplets_loss: 0.4697 - supervised_loss: 0.4231\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4555 - stacked_triplets_loss: 0.3760 - supervised_loss: 0.5338\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4533 - stacked_triplets_loss: 0.3799 - supervised_loss: 0.5267\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4758 - stacked_triplets_loss: 0.3795 - supervised_loss: 0.5693\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2899 - stacked_triplets_loss: 0.2880 - supervised_loss: 0.2924\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5894 - stacked_triplets_loss: 0.4236 - supervised_loss: 0.7551\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4769 - stacked_triplets_loss: 0.4100 - supervised_loss: 0.5432\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4246 - stacked_triplets_loss: 0.3984 - supervised_loss: 0.4540\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5548 - stacked_triplets_loss: 0.5380 - supervised_loss: 0.5700\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4611 - stacked_triplets_loss: 0.4262 - supervised_loss: 0.4961\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5542 - stacked_triplets_loss: 0.5189 - supervised_loss: 0.5850\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5128 - stacked_triplets_loss: 0.4422 - supervised_loss: 0.5817\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3997 - stacked_triplets_loss: 0.3308 - supervised_loss: 0.4685\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3190 - stacked_triplets_loss: 0.3528 - supervised_loss: 0.2862\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5176 - stacked_triplets_loss: 0.4662 - supervised_loss: 0.5669\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4704 - stacked_triplets_loss: 0.4279 - supervised_loss: 0.5129\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3707 - stacked_triplets_loss: 0.4118 - supervised_loss: 0.3335\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5088 - stacked_triplets_loss: 0.3754 - supervised_loss: 0.6389\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6835 - stacked_triplets_loss: 0.6429 - supervised_loss: 0.7241\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3218 - stacked_triplets_loss: 0.2900 - supervised_loss: 0.3546\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4854 - stacked_triplets_loss: 0.4445 - supervised_loss: 0.5240\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.4067 - stacked_triplets_loss: 0.3824 - supervised_loss: 0.4288\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4458 - stacked_triplets_loss: 0.3685 - supervised_loss: 0.5205\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4773 - stacked_triplets_loss: 0.4379 - supervised_loss: 0.5195\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4789 - stacked_triplets_loss: 0.4442 - supervised_loss: 0.5136\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3871 - stacked_triplets_loss: 0.3433 - supervised_loss: 0.4297\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4300 - stacked_triplets_loss: 0.4227 - supervised_loss: 0.4355\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2666 - stacked_triplets_loss: 0.2492 - supervised_loss: 0.2840\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6583 - stacked_triplets_loss: 0.4559 - supervised_loss: 0.8548\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4396 - stacked_triplets_loss: 0.4338 - supervised_loss: 0.4449\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4738 - stacked_triplets_loss: 0.4194 - supervised_loss: 0.5284\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3084 - stacked_triplets_loss: 0.2861 - supervised_loss: 0.3307\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5910 - stacked_triplets_loss: 0.4536 - supervised_loss: 0.7250\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2865 - stacked_triplets_loss: 0.2849 - supervised_loss: 0.2870\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4827 - stacked_triplets_loss: 0.3934 - supervised_loss: 0.5707\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4240 - stacked_triplets_loss: 0.3411 - supervised_loss: 0.5068\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5513 - stacked_triplets_loss: 0.5122 - supervised_loss: 0.5882\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3343 - stacked_triplets_loss: 0.2069 - supervised_loss: 0.4602\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3748 - stacked_triplets_loss: 0.2804 - supervised_loss: 0.4692\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4920 - stacked_triplets_loss: 0.4283 - supervised_loss: 0.5533\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4772 - stacked_triplets_loss: 0.5283 - supervised_loss: 0.4247\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3809 - stacked_triplets_loss: 0.4183 - supervised_loss: 0.3435\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.4099 - stacked_triplets_loss: 0.3390 - supervised_loss: 0.4762\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4600 - stacked_triplets_loss: 0.3408 - supervised_loss: 0.5791\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3932 - stacked_triplets_loss: 0.3389 - supervised_loss: 0.4454\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.3970 - stacked_triplets_loss: 0.3406 - supervised_loss: 0.4510\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2853 - stacked_triplets_loss: 0.2397 - supervised_loss: 0.3300\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4426 - stacked_triplets_loss: 0.4467 - supervised_loss: 0.4357\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4581 - stacked_triplets_loss: 0.4003 - supervised_loss: 0.5159\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4758 - stacked_triplets_loss: 0.4558 - supervised_loss: 0.4948\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3947 - stacked_triplets_loss: 0.3100 - supervised_loss: 0.4779\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.5081 - stacked_triplets_loss: 0.5103 - supervised_loss: 0.5025\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4652 - stacked_triplets_loss: 0.4258 - supervised_loss: 0.5023\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2874 - stacked_triplets_loss: 0.2953 - supervised_loss: 0.2796\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4290 - stacked_triplets_loss: 0.3273 - supervised_loss: 0.5285\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4395 - stacked_triplets_loss: 0.3405 - supervised_loss: 0.5371\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3943 - stacked_triplets_loss: 0.2840 - supervised_loss: 0.5025\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4213 - stacked_triplets_loss: 0.3382 - supervised_loss: 0.5029\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2858 - stacked_triplets_loss: 0.2642 - supervised_loss: 0.3069\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4888 - stacked_triplets_loss: 0.3540 - supervised_loss: 0.6237\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3478 - stacked_triplets_loss: 0.3446 - supervised_loss: 0.3529\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4517 - stacked_triplets_loss: 0.3896 - supervised_loss: 0.5139\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3959 - stacked_triplets_loss: 0.2925 - supervised_loss: 0.4981\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3547 - stacked_triplets_loss: 0.2937 - supervised_loss: 0.4150\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2997 - stacked_triplets_loss: 0.2473 - supervised_loss: 0.3515\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3320 - stacked_triplets_loss: 0.1626 - supervised_loss: 0.5014\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4907 - stacked_triplets_loss: 0.2945 - supervised_loss: 0.6833\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3578 - stacked_triplets_loss: 0.2457 - supervised_loss: 0.4683\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3489 - stacked_triplets_loss: 0.2769 - supervised_loss: 0.4209\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3847 - stacked_triplets_loss: 0.2653 - supervised_loss: 0.5030\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.4329 - stacked_triplets_loss: 0.4351 - supervised_loss: 0.4300\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4748 - stacked_triplets_loss: 0.3475 - supervised_loss: 0.6022\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3354 - stacked_triplets_loss: 0.3865 - supervised_loss: 0.2839\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3929 - stacked_triplets_loss: 0.3229 - supervised_loss: 0.4577\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4185 - stacked_triplets_loss: 0.3174 - supervised_loss: 0.5197\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4196 - stacked_triplets_loss: 0.3127 - supervised_loss: 0.5265\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3651 - stacked_triplets_loss: 0.2553 - supervised_loss: 0.4732\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3086 - stacked_triplets_loss: 0.2643 - supervised_loss: 0.3508\n",
      "745/745 [==============================] - 0s 547us/sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ivis = Ivis(embedding_dims=3, k=4)\n",
    "x_red = ivis.fit_transform(np.array(x), np.array(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_red, y)\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       144\n",
      "           1       0.51      0.47      0.49        43\n",
      "\n",
      "    accuracy                           0.78       187\n",
      "   macro avg       0.68      0.67      0.67       187\n",
      "weighted avg       0.77      0.78      0.77       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "558/558 [==============================] - 5s 9ms/step - loss: 0.8437 - acc: 0.4659\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 0s 389us/step - loss: 0.7925 - acc: 0.4875\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 0s 306us/step - loss: 0.7612 - acc: 0.4875\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 0s 328us/step - loss: 0.7296 - acc: 0.5125\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 0s 310us/step - loss: 0.7201 - acc: 0.5215\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 0s 385us/step - loss: 0.6981 - acc: 0.5215\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 0s 298us/step - loss: 0.6716 - acc: 0.5358\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 0.6649 - acc: 0.5448\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 0s 310us/step - loss: 0.6458 - acc: 0.5645\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 0s 299us/step - loss: 0.6419 - acc: 0.5806\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 0s 294us/step - loss: 0.6361 - acc: 0.5896\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 0s 314us/step - loss: 0.6318 - acc: 0.5896\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 0s 300us/step - loss: 0.6106 - acc: 0.6452\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 0.6105 - acc: 0.6613\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 0s 321us/step - loss: 0.6099 - acc: 0.6774\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 0s 301us/step - loss: 0.6051 - acc: 0.6649\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 0s 361us/step - loss: 0.5949 - acc: 0.6720\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 0s 374us/step - loss: 0.5945 - acc: 0.6631\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 0.5898 - acc: 0.6756\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 0s 349us/step - loss: 0.5815 - acc: 0.6882\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 0s 290us/step - loss: 0.5755 - acc: 0.6846\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 0s 329us/step - loss: 0.5719 - acc: 0.6882\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 0s 313us/step - loss: 0.5662 - acc: 0.6846\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 0s 373us/step - loss: 0.5630 - acc: 0.6882\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 0s 358us/step - loss: 0.5665 - acc: 0.6756\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 0s 302us/step - loss: 0.5623 - acc: 0.6774\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 0s 355us/step - loss: 0.5555 - acc: 0.6882\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 0s 357us/step - loss: 0.5494 - acc: 0.7043\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 0s 352us/step - loss: 0.5486 - acc: 0.6810\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 0s 357us/step - loss: 0.5510 - acc: 0.6900\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 0s 300us/step - loss: 0.5432 - acc: 0.7061\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 0s 320us/step - loss: 0.5392 - acc: 0.7168\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 0s 373us/step - loss: 0.5381 - acc: 0.7079\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 0s 296us/step - loss: 0.5351 - acc: 0.7097\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 0s 347us/step - loss: 0.5370 - acc: 0.7133\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 0s 360us/step - loss: 0.5307 - acc: 0.7097\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 0s 300us/step - loss: 0.5299 - acc: 0.7186\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 0s 339us/step - loss: 0.5305 - acc: 0.7204\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 0s 296us/step - loss: 0.5243 - acc: 0.7276\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 0s 306us/step - loss: 0.5129 - acc: 0.7366\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 0s 301us/step - loss: 0.5180 - acc: 0.7366\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 0s 307us/step - loss: 0.5156 - acc: 0.7312\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 0s 305us/step - loss: 0.5147 - acc: 0.7294\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 0s 330us/step - loss: 0.5096 - acc: 0.7384\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 0s 318us/step - loss: 0.5134 - acc: 0.7186\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 0s 298us/step - loss: 0.5033 - acc: 0.7473\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 0s 329us/step - loss: 0.5065 - acc: 0.7401\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.5041 - acc: 0.7437\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 0s 302us/step - loss: 0.4964 - acc: 0.7419\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 0.5036 - acc: 0.7348\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 0s 295us/step - loss: 0.4955 - acc: 0.7366\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 0s 336us/step - loss: 0.4969 - acc: 0.7437\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 0s 294us/step - loss: 0.4893 - acc: 0.7616\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 0s 330us/step - loss: 0.4906 - acc: 0.7688\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 0s 339us/step - loss: 0.4907 - acc: 0.7419\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 0s 292us/step - loss: 0.4916 - acc: 0.7563\n",
      "Epoch 57/100\n",
      "558/558 [==============================] - 0s 334us/step - loss: 0.4859 - acc: 0.7455\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 0s 299us/step - loss: 0.4858 - acc: 0.7652\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 0s 336us/step - loss: 0.4827 - acc: 0.7867\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 0s 292us/step - loss: 0.4803 - acc: 0.8047\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.4785 - acc: 0.7706\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 0s 252us/step - loss: 0.4864 - acc: 0.7688\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 0s 256us/step - loss: 0.4779 - acc: 0.7724\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.4824 - acc: 0.7724\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 0s 246us/step - loss: 0.4833 - acc: 0.7921\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 0s 243us/step - loss: 0.4811 - acc: 0.7581\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 0s 241us/step - loss: 0.4677 - acc: 0.7778\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 0s 258us/step - loss: 0.4756 - acc: 0.7867\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 0s 250us/step - loss: 0.4712 - acc: 0.7760\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 0s 247us/step - loss: 0.4752 - acc: 0.7903\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 0s 259us/step - loss: 0.4708 - acc: 0.7832\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 0s 231us/step - loss: 0.4690 - acc: 0.7760\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 0s 261us/step - loss: 0.4672 - acc: 0.7796\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 0s 295us/step - loss: 0.4664 - acc: 0.7867\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 0.4634 - acc: 0.7832\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 0s 265us/step - loss: 0.4618 - acc: 0.7760\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 0s 290us/step - loss: 0.4625 - acc: 0.7832\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 0s 261us/step - loss: 0.4618 - acc: 0.7581\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 0.4663 - acc: 0.7652\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 0s 241us/step - loss: 0.4640 - acc: 0.7599\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 0.4650 - acc: 0.7778\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.4569 - acc: 0.7796\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 0s 288us/step - loss: 0.4591 - acc: 0.7832\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.4565 - acc: 0.7885\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 0s 258us/step - loss: 0.4588 - acc: 0.7832\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.4550 - acc: 0.7832\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 0s 246us/step - loss: 0.4475 - acc: 0.7778\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4586 - acc: 0.7921\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 0s 250us/step - loss: 0.4654 - acc: 0.7724\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 0s 245us/step - loss: 0.4518 - acc: 0.8047\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 0s 248us/step - loss: 0.4555 - acc: 0.8011\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 0s 251us/step - loss: 0.4564 - acc: 0.7867\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 0s 241us/step - loss: 0.4519 - acc: 0.7867\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4480 - acc: 0.7957\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 0s 242us/step - loss: 0.4411 - acc: 0.7957\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 0s 251us/step - loss: 0.4463 - acc: 0.8047\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 0s 232us/step - loss: 0.4420 - acc: 0.8136\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 0s 262us/step - loss: 0.4442 - acc: 0.7903\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.4431 - acc: 0.7993\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.4400 - acc: 0.7688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83       144\n",
      "           1       0.44      0.49      0.46        43\n",
      "\n",
      "    accuracy                           0.74       187\n",
      "   macro avg       0.64      0.65      0.64       187\n",
      "weighted avg       0.75      0.74      0.74       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(3,)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1),\n",
    "    BatchNormalization(),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)\n",
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling trick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_res, y_res = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "870/870 [==============================] - 4s 5ms/step - loss: 0.6844 - acc: 0.5621\n",
      "Epoch 2/100\n",
      "870/870 [==============================] - 0s 319us/step - loss: 0.6648 - acc: 0.5805\n",
      "Epoch 3/100\n",
      "870/870 [==============================] - 0s 291us/step - loss: 0.6538 - acc: 0.6000\n",
      "Epoch 4/100\n",
      "870/870 [==============================] - 0s 289us/step - loss: 0.6503 - acc: 0.6379\n",
      "Epoch 5/100\n",
      "870/870 [==============================] - 0s 300us/step - loss: 0.6440 - acc: 0.6218\n",
      "Epoch 6/100\n",
      "870/870 [==============================] - 0s 318us/step - loss: 0.6359 - acc: 0.6770\n",
      "Epoch 7/100\n",
      "870/870 [==============================] - 0s 276us/step - loss: 0.6294 - acc: 0.6793\n",
      "Epoch 8/100\n",
      "870/870 [==============================] - 0s 299us/step - loss: 0.6200 - acc: 0.7023\n",
      "Epoch 9/100\n",
      "870/870 [==============================] - 0s 308us/step - loss: 0.6163 - acc: 0.7069\n",
      "Epoch 10/100\n",
      "870/870 [==============================] - 0s 301us/step - loss: 0.6108 - acc: 0.7149\n",
      "Epoch 11/100\n",
      "870/870 [==============================] - 0s 283us/step - loss: 0.5980 - acc: 0.7080\n",
      "Epoch 12/100\n",
      "870/870 [==============================] - 0s 264us/step - loss: 0.5960 - acc: 0.7356\n",
      "Epoch 13/100\n",
      "870/870 [==============================] - 0s 278us/step - loss: 0.5971 - acc: 0.7299\n",
      "Epoch 14/100\n",
      "870/870 [==============================] - 0s 277us/step - loss: 0.5887 - acc: 0.7230\n",
      "Epoch 15/100\n",
      "870/870 [==============================] - 0s 261us/step - loss: 0.5840 - acc: 0.7368\n",
      "Epoch 16/100\n",
      "870/870 [==============================] - 0s 280us/step - loss: 0.5826 - acc: 0.7483\n",
      "Epoch 17/100\n",
      "870/870 [==============================] - 0s 257us/step - loss: 0.5737 - acc: 0.7299\n",
      "Epoch 18/100\n",
      "870/870 [==============================] - 0s 271us/step - loss: 0.5737 - acc: 0.7483\n",
      "Epoch 19/100\n",
      "870/870 [==============================] - 0s 319us/step - loss: 0.5733 - acc: 0.7448\n",
      "Epoch 20/100\n",
      "870/870 [==============================] - 0s 278us/step - loss: 0.5534 - acc: 0.7540\n",
      "Epoch 21/100\n",
      "870/870 [==============================] - 0s 264us/step - loss: 0.5635 - acc: 0.7460\n",
      "Epoch 22/100\n",
      "870/870 [==============================] - 0s 314us/step - loss: 0.5622 - acc: 0.7667\n",
      "Epoch 23/100\n",
      "870/870 [==============================] - 0s 283us/step - loss: 0.5509 - acc: 0.7552\n",
      "Epoch 24/100\n",
      "870/870 [==============================] - 0s 271us/step - loss: 0.5633 - acc: 0.7506\n",
      "Epoch 25/100\n",
      "870/870 [==============================] - 0s 283us/step - loss: 0.5497 - acc: 0.7483\n",
      "Epoch 26/100\n",
      "870/870 [==============================] - 0s 279us/step - loss: 0.5511 - acc: 0.7586\n",
      "Epoch 27/100\n",
      "870/870 [==============================] - 0s 276us/step - loss: 0.5532 - acc: 0.7345\n",
      "Epoch 28/100\n",
      "870/870 [==============================] - 0s 285us/step - loss: 0.5431 - acc: 0.7483\n",
      "Epoch 29/100\n",
      "870/870 [==============================] - 0s 271us/step - loss: 0.5387 - acc: 0.7483\n",
      "Epoch 30/100\n",
      "870/870 [==============================] - 0s 345us/step - loss: 0.5366 - acc: 0.7552\n",
      "Epoch 31/100\n",
      "870/870 [==============================] - 0s 280us/step - loss: 0.5407 - acc: 0.7540\n",
      "Epoch 32/100\n",
      "870/870 [==============================] - 0s 283us/step - loss: 0.5356 - acc: 0.7506\n",
      "Epoch 33/100\n",
      "870/870 [==============================] - 0s 279us/step - loss: 0.5429 - acc: 0.7494\n",
      "Epoch 34/100\n",
      "870/870 [==============================] - 0s 354us/step - loss: 0.5213 - acc: 0.7586\n",
      "Epoch 35/100\n",
      "870/870 [==============================] - 0s 359us/step - loss: 0.5352 - acc: 0.7529\n",
      "Epoch 36/100\n",
      "870/870 [==============================] - 0s 349us/step - loss: 0.5344 - acc: 0.7586\n",
      "Epoch 37/100\n",
      "870/870 [==============================] - 0s 309us/step - loss: 0.5336 - acc: 0.7540\n",
      "Epoch 38/100\n",
      "870/870 [==============================] - 0s 295us/step - loss: 0.5235 - acc: 0.7586\n",
      "Epoch 39/100\n",
      "870/870 [==============================] - 0s 296us/step - loss: 0.5301 - acc: 0.7575\n",
      "Epoch 40/100\n",
      "870/870 [==============================] - 0s 281us/step - loss: 0.5350 - acc: 0.7517\n",
      "Epoch 41/100\n",
      "870/870 [==============================] - 0s 310us/step - loss: 0.5150 - acc: 0.7690\n",
      "Epoch 42/100\n",
      "870/870 [==============================] - 0s 271us/step - loss: 0.5293 - acc: 0.7437\n",
      "Epoch 43/100\n",
      "870/870 [==============================] - 0s 272us/step - loss: 0.5221 - acc: 0.7690\n",
      "Epoch 44/100\n",
      "870/870 [==============================] - 0s 274us/step - loss: 0.5234 - acc: 0.7483\n",
      "Epoch 45/100\n",
      "870/870 [==============================] - 0s 282us/step - loss: 0.5199 - acc: 0.7552\n",
      "Epoch 46/100\n",
      "870/870 [==============================] - 0s 282us/step - loss: 0.5195 - acc: 0.7575\n",
      "Epoch 47/100\n",
      "870/870 [==============================] - 0s 284us/step - loss: 0.5197 - acc: 0.7598\n",
      "Epoch 48/100\n",
      "870/870 [==============================] - 0s 281us/step - loss: 0.5183 - acc: 0.7621\n",
      "Epoch 49/100\n",
      "870/870 [==============================] - 0s 324us/step - loss: 0.5142 - acc: 0.7690\n",
      "Epoch 50/100\n",
      "870/870 [==============================] - 0s 302us/step - loss: 0.5169 - acc: 0.7552\n",
      "Epoch 51/100\n",
      "870/870 [==============================] - 0s 299us/step - loss: 0.5182 - acc: 0.7690\n",
      "Epoch 52/100\n",
      "870/870 [==============================] - 0s 324us/step - loss: 0.5151 - acc: 0.7621\n",
      "Epoch 53/100\n",
      "870/870 [==============================] - 0s 332us/step - loss: 0.5028 - acc: 0.7736\n",
      "Epoch 54/100\n",
      "870/870 [==============================] - 0s 290us/step - loss: 0.5135 - acc: 0.7575\n",
      "Epoch 55/100\n",
      "870/870 [==============================] - 0s 270us/step - loss: 0.5049 - acc: 0.7724\n",
      "Epoch 56/100\n",
      "870/870 [==============================] - 0s 282us/step - loss: 0.4958 - acc: 0.7667\n",
      "Epoch 57/100\n",
      "870/870 [==============================] - 0s 287us/step - loss: 0.5022 - acc: 0.7621\n",
      "Epoch 58/100\n",
      "870/870 [==============================] - 0s 269us/step - loss: 0.5094 - acc: 0.7575\n",
      "Epoch 59/100\n",
      "870/870 [==============================] - 0s 264us/step - loss: 0.5165 - acc: 0.7575\n",
      "Epoch 60/100\n",
      "870/870 [==============================] - 0s 280us/step - loss: 0.5202 - acc: 0.7552\n",
      "Epoch 61/100\n",
      "870/870 [==============================] - 0s 284us/step - loss: 0.5078 - acc: 0.7655\n",
      "Epoch 62/100\n",
      "870/870 [==============================] - 0s 285us/step - loss: 0.5138 - acc: 0.7540\n",
      "Epoch 63/100\n",
      "870/870 [==============================] - 0s 292us/step - loss: 0.5194 - acc: 0.7621\n",
      "Epoch 64/100\n",
      "870/870 [==============================] - 0s 258us/step - loss: 0.4957 - acc: 0.7506\n",
      "Epoch 65/100\n",
      "870/870 [==============================] - 0s 281us/step - loss: 0.5063 - acc: 0.7609\n",
      "Epoch 66/100\n",
      "870/870 [==============================] - 0s 276us/step - loss: 0.5072 - acc: 0.7713\n",
      "Epoch 67/100\n",
      "870/870 [==============================] - 0s 303us/step - loss: 0.5038 - acc: 0.7540\n",
      "Epoch 68/100\n",
      "870/870 [==============================] - 0s 273us/step - loss: 0.4978 - acc: 0.7586\n",
      "Epoch 69/100\n",
      "870/870 [==============================] - 0s 290us/step - loss: 0.5084 - acc: 0.7632\n",
      "Epoch 70/100\n",
      "870/870 [==============================] - 0s 291us/step - loss: 0.5144 - acc: 0.7632\n",
      "Epoch 71/100\n",
      "870/870 [==============================] - 0s 281us/step - loss: 0.5052 - acc: 0.7690\n",
      "Epoch 72/100\n",
      "870/870 [==============================] - 0s 268us/step - loss: 0.5141 - acc: 0.7471\n",
      "Epoch 73/100\n",
      "870/870 [==============================] - 0s 286us/step - loss: 0.5138 - acc: 0.7529\n",
      "Epoch 74/100\n",
      "870/870 [==============================] - 0s 355us/step - loss: 0.5001 - acc: 0.7621\n",
      "Epoch 75/100\n",
      "870/870 [==============================] - 0s 321us/step - loss: 0.4987 - acc: 0.7724\n",
      "Epoch 76/100\n",
      "870/870 [==============================] - 0s 336us/step - loss: 0.4991 - acc: 0.7632\n",
      "Epoch 77/100\n",
      "870/870 [==============================] - 0s 331us/step - loss: 0.5204 - acc: 0.7598\n",
      "Epoch 78/100\n",
      "870/870 [==============================] - 0s 342us/step - loss: 0.5010 - acc: 0.7598\n",
      "Epoch 79/100\n",
      "870/870 [==============================] - 0s 362us/step - loss: 0.4939 - acc: 0.7655\n",
      "Epoch 80/100\n",
      "870/870 [==============================] - 0s 343us/step - loss: 0.5061 - acc: 0.7529\n",
      "Epoch 81/100\n",
      "870/870 [==============================] - 0s 298us/step - loss: 0.5057 - acc: 0.7598\n",
      "Epoch 82/100\n",
      "870/870 [==============================] - 0s 341us/step - loss: 0.4997 - acc: 0.7621\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870/870 [==============================] - 0s 354us/step - loss: 0.5027 - acc: 0.7575\n",
      "Epoch 84/100\n",
      "870/870 [==============================] - 0s 341us/step - loss: 0.4963 - acc: 0.7586\n",
      "Epoch 85/100\n",
      "870/870 [==============================] - 0s 323us/step - loss: 0.4901 - acc: 0.7621\n",
      "Epoch 86/100\n",
      "870/870 [==============================] - 0s 354us/step - loss: 0.5023 - acc: 0.7494\n",
      "Epoch 87/100\n",
      "870/870 [==============================] - 0s 373us/step - loss: 0.5003 - acc: 0.7690\n",
      "Epoch 88/100\n",
      "870/870 [==============================] - 0s 353us/step - loss: 0.5083 - acc: 0.7552\n",
      "Epoch 89/100\n",
      "870/870 [==============================] - 0s 322us/step - loss: 0.4906 - acc: 0.7586\n",
      "Epoch 90/100\n",
      "870/870 [==============================] - 0s 302us/step - loss: 0.4925 - acc: 0.7632\n",
      "Epoch 91/100\n",
      "870/870 [==============================] - 0s 245us/step - loss: 0.4969 - acc: 0.7529\n",
      "Epoch 92/100\n",
      "870/870 [==============================] - 0s 264us/step - loss: 0.4970 - acc: 0.7655\n",
      "Epoch 93/100\n",
      "870/870 [==============================] - 0s 254us/step - loss: 0.5086 - acc: 0.7402\n",
      "Epoch 94/100\n",
      "870/870 [==============================] - 0s 278us/step - loss: 0.5003 - acc: 0.7609\n",
      "Epoch 95/100\n",
      "870/870 [==============================] - 0s 259us/step - loss: 0.4945 - acc: 0.7586\n",
      "Epoch 96/100\n",
      "870/870 [==============================] - 0s 290us/step - loss: 0.4932 - acc: 0.7667\n",
      "Epoch 97/100\n",
      "870/870 [==============================] - 0s 284us/step - loss: 0.4984 - acc: 0.7632\n",
      "Epoch 98/100\n",
      "870/870 [==============================] - 0s 334us/step - loss: 0.4929 - acc: 0.7690\n",
      "Epoch 99/100\n",
      "870/870 [==============================] - 0s 315us/step - loss: 0.5125 - acc: 0.7517\n",
      "Epoch 100/100\n",
      "870/870 [==============================] - 0s 245us/step - loss: 0.4993 - acc: 0.7494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.82       144\n",
      "           1       0.45      0.70      0.55        43\n",
      "\n",
      "    accuracy                           0.74       187\n",
      "   macro avg       0.67      0.72      0.68       187\n",
      "weighted avg       0.79      0.74      0.75       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_res, y_res, epochs=100)\n",
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 44481.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building KNN index\n",
      "Extracting KNN from index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 745/745 [00:00<00:00, 5144.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 6s 1s/step - loss: 19.7825 - stacked_triplets_loss: 15.3720 - supervised_loss: 24.1044\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 13.4486 - stacked_triplets_loss: 19.4793 - supervised_loss: 7.3829\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 13.9127 - stacked_triplets_loss: 11.0004 - supervised_loss: 16.8249\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 4.3754 - stacked_triplets_loss: 6.3122 - supervised_loss: 2.4240\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 7.8593 - stacked_triplets_loss: 9.8008 - supervised_loss: 5.9170\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0066 - stacked_triplets_loss: 10.7858 - supervised_loss: 5.2113\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.0148 - stacked_triplets_loss: 4.1466 - supervised_loss: 1.8785\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 10.3918 - stacked_triplets_loss: 9.9159 - supervised_loss: 10.8677\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 6.1445 - stacked_triplets_loss: 6.8153 - supervised_loss: 5.4721\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 3.9535 - stacked_triplets_loss: 3.7309 - supervised_loss: 4.1683\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 7.3732 - stacked_triplets_loss: 7.0143 - supervised_loss: 7.7322\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7993 - stacked_triplets_loss: 5.7362 - supervised_loss: 3.8438\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 4.6484 - stacked_triplets_loss: 4.9344 - supervised_loss: 4.3625\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 4.2937 - stacked_triplets_loss: 5.0931 - supervised_loss: 3.5160\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.6594 - stacked_triplets_loss: 6.4841 - supervised_loss: 4.7818\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.9745 - stacked_triplets_loss: 2.8851 - supervised_loss: 1.0640\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 3.6050 - stacked_triplets_loss: 4.7104 - supervised_loss: 2.4932\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.5021 - stacked_triplets_loss: 4.3521 - supervised_loss: 2.6340\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.1698 - stacked_triplets_loss: 4.4939 - supervised_loss: 1.8367\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 2.6257 - stacked_triplets_loss: 3.7363 - supervised_loss: 1.5143\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.5114 - stacked_triplets_loss: 3.0745 - supervised_loss: 1.9483\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 3.1265 - stacked_triplets_loss: 3.9080 - supervised_loss: 2.3276\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.2264 - stacked_triplets_loss: 2.7363 - supervised_loss: 1.7127\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6313 - stacked_triplets_loss: 2.7919 - supervised_loss: 2.4647\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.4440 - stacked_triplets_loss: 3.0703 - supervised_loss: 1.8100\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.1414 - stacked_triplets_loss: 2.9707 - supervised_loss: 1.3117\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.3709 - stacked_triplets_loss: 3.0616 - supervised_loss: 1.6801\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 3.0115 - stacked_triplets_loss: 3.8751 - supervised_loss: 2.1032\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.7936 - stacked_triplets_loss: 2.1020 - supervised_loss: 1.4852\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.9275 - stacked_triplets_loss: 2.9196 - supervised_loss: 0.9293\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.9969 - stacked_triplets_loss: 2.1543 - supervised_loss: 1.8250\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.8339 - stacked_triplets_loss: 2.5316 - supervised_loss: 1.1363\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.4696 - stacked_triplets_loss: 3.7959 - supervised_loss: 1.1489\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.1666 - stacked_triplets_loss: 1.3216 - supervised_loss: 1.0117\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.6846 - stacked_triplets_loss: 1.8649 - supervised_loss: 1.4965\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.0974 - stacked_triplets_loss: 2.9904 - supervised_loss: 1.2093\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.1514 - stacked_triplets_loss: 1.2798 - supervised_loss: 1.0264\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 2.7344 - stacked_triplets_loss: 3.4883 - supervised_loss: 1.9805\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.7866 - stacked_triplets_loss: 2.3558 - supervised_loss: 1.2131\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.9005 - stacked_triplets_loss: 1.3035 - supervised_loss: 0.5004\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.9385 - stacked_triplets_loss: 2.0094 - supervised_loss: 1.8527\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.2716 - stacked_triplets_loss: 3.0781 - supervised_loss: 1.4474\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.5883 - stacked_triplets_loss: 1.8724 - supervised_loss: 1.2978\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.6848 - stacked_triplets_loss: 1.6586 - supervised_loss: 1.7151\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.8898 - stacked_triplets_loss: 1.2585 - supervised_loss: 0.5212\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.3479 - stacked_triplets_loss: 2.8053 - supervised_loss: 1.8723\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.3529 - stacked_triplets_loss: 1.5369 - supervised_loss: 1.1780\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.6788 - stacked_triplets_loss: 2.1550 - supervised_loss: 1.1921\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.7019 - stacked_triplets_loss: 2.4054 - supervised_loss: 0.9876\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.0389 - stacked_triplets_loss: 1.3356 - supervised_loss: 0.7422\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4678 - stacked_triplets_loss: 1.7855 - supervised_loss: 1.1385\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.4721 - stacked_triplets_loss: 1.9235 - supervised_loss: 1.0113\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.3145 - stacked_triplets_loss: 1.5998 - supervised_loss: 1.0344\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9181 - stacked_triplets_loss: 1.1940 - supervised_loss: 0.6388\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.3371 - stacked_triplets_loss: 1.5187 - supervised_loss: 1.1555\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7060 - stacked_triplets_loss: 0.8970 - supervised_loss: 0.5103\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.3954 - stacked_triplets_loss: 1.9080 - supervised_loss: 0.8829\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.2142 - stacked_triplets_loss: 1.4589 - supervised_loss: 0.9675\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 51ms/step - loss: 1.4428 - stacked_triplets_loss: 1.9232 - supervised_loss: 0.9592\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2426 - stacked_triplets_loss: 1.4982 - supervised_loss: 0.9811\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.2474 - stacked_triplets_loss: 1.4245 - supervised_loss: 1.0667\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.9232 - stacked_triplets_loss: 0.9054 - supervised_loss: 0.9397\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.2695 - stacked_triplets_loss: 1.4000 - supervised_loss: 1.1390\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8913 - stacked_triplets_loss: 1.1680 - supervised_loss: 0.6186\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.5982 - stacked_triplets_loss: 2.1300 - supervised_loss: 1.0599\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6616 - stacked_triplets_loss: 0.8192 - supervised_loss: 0.5037\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.9770 - stacked_triplets_loss: 1.0417 - supervised_loss: 0.9124\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6267 - stacked_triplets_loss: 0.9408 - supervised_loss: 0.3190\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0698 - stacked_triplets_loss: 1.0680 - supervised_loss: 1.0716\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.2602 - stacked_triplets_loss: 1.6270 - supervised_loss: 0.8878\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6466 - stacked_triplets_loss: 0.7351 - supervised_loss: 0.5579\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.1559 - stacked_triplets_loss: 1.0528 - supervised_loss: 1.2499\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.4548 - stacked_triplets_loss: 1.5915 - supervised_loss: 1.3249\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0243 - stacked_triplets_loss: 1.1579 - supervised_loss: 0.8907\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.6833 - stacked_triplets_loss: 0.8807 - supervised_loss: 0.4881\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.1780 - stacked_triplets_loss: 1.0040 - supervised_loss: 1.3521\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3021 - stacked_triplets_loss: 1.7474 - supervised_loss: 0.8498\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8322 - stacked_triplets_loss: 1.0909 - supervised_loss: 0.5782\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6691 - stacked_triplets_loss: 0.6725 - supervised_loss: 0.6667\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.4077 - stacked_triplets_loss: 1.3781 - supervised_loss: 1.4334\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.9255 - stacked_triplets_loss: 1.1649 - supervised_loss: 0.6852\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9303 - stacked_triplets_loss: 1.2046 - supervised_loss: 0.6560\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5749 - stacked_triplets_loss: 0.7139 - supervised_loss: 0.4359\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.1329 - stacked_triplets_loss: 1.1023 - supervised_loss: 1.1536\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.9781 - stacked_triplets_loss: 0.9336 - supervised_loss: 1.0218\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7679 - stacked_triplets_loss: 0.8153 - supervised_loss: 0.7225\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1248 - stacked_triplets_loss: 1.4193 - supervised_loss: 0.8269\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7763 - stacked_triplets_loss: 1.0218 - supervised_loss: 0.5309\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.9054 - stacked_triplets_loss: 1.1903 - supervised_loss: 0.6147\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.9194 - stacked_triplets_loss: 1.1566 - supervised_loss: 0.6822\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8894 - stacked_triplets_loss: 0.9766 - supervised_loss: 0.8032\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5447 - stacked_triplets_loss: 0.6587 - supervised_loss: 0.4322\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9487 - stacked_triplets_loss: 0.8732 - supervised_loss: 1.0198\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6719 - stacked_triplets_loss: 0.6570 - supervised_loss: 0.6868\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6411 - stacked_triplets_loss: 0.7434 - supervised_loss: 0.5414\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7536 - stacked_triplets_loss: 0.8359 - supervised_loss: 0.6662\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7492 - stacked_triplets_loss: 0.8044 - supervised_loss: 0.6939\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7551 - stacked_triplets_loss: 0.8846 - supervised_loss: 0.6243\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4409 - stacked_triplets_loss: 0.4493 - supervised_loss: 0.4343\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7283 - stacked_triplets_loss: 0.8102 - supervised_loss: 0.6437\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6215 - stacked_triplets_loss: 0.6703 - supervised_loss: 0.5727\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6277 - stacked_triplets_loss: 0.5684 - supervised_loss: 0.6871\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7240 - stacked_triplets_loss: 0.8067 - supervised_loss: 0.6401\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6570 - stacked_triplets_loss: 0.7047 - supervised_loss: 0.6092\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7562 - stacked_triplets_loss: 0.7980 - supervised_loss: 0.7107\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5747 - stacked_triplets_loss: 0.7868 - supervised_loss: 0.3652\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7302 - stacked_triplets_loss: 0.7448 - supervised_loss: 0.7156\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6949 - stacked_triplets_loss: 0.7164 - supervised_loss: 0.6741\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5651 - stacked_triplets_loss: 0.4540 - supervised_loss: 0.6738\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.7016 - stacked_triplets_loss: 0.7452 - supervised_loss: 0.6549\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5435 - stacked_triplets_loss: 0.5980 - supervised_loss: 0.4867\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5177 - stacked_triplets_loss: 0.7011 - supervised_loss: 0.3344\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7960 - stacked_triplets_loss: 0.7705 - supervised_loss: 0.8160\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5441 - stacked_triplets_loss: 0.6201 - supervised_loss: 0.4675\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6243 - stacked_triplets_loss: 0.5474 - supervised_loss: 0.7001\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.7395 - stacked_triplets_loss: 0.8020 - supervised_loss: 0.6735\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5307 - stacked_triplets_loss: 0.7456 - supervised_loss: 0.3158\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6705 - stacked_triplets_loss: 0.6446 - supervised_loss: 0.6912\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5809 - stacked_triplets_loss: 0.5906 - supervised_loss: 0.5711\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6192 - stacked_triplets_loss: 0.6352 - supervised_loss: 0.6032\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4086 - stacked_triplets_loss: 0.5139 - supervised_loss: 0.3035\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5482 - stacked_triplets_loss: 0.4553 - supervised_loss: 0.6411\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5690 - stacked_triplets_loss: 0.5537 - supervised_loss: 0.5776\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6865 - stacked_triplets_loss: 0.6256 - supervised_loss: 0.7474\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4458 - stacked_triplets_loss: 0.3312 - supervised_loss: 0.5622\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5434 - stacked_triplets_loss: 0.4599 - supervised_loss: 0.6269\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5928 - stacked_triplets_loss: 0.6603 - supervised_loss: 0.5240\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5923 - stacked_triplets_loss: 0.5626 - supervised_loss: 0.6221\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6616 - stacked_triplets_loss: 0.7258 - supervised_loss: 0.5931\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4959 - stacked_triplets_loss: 0.6217 - supervised_loss: 0.3702\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7372 - stacked_triplets_loss: 0.6749 - supervised_loss: 0.7956\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4925 - stacked_triplets_loss: 0.4989 - supervised_loss: 0.4833\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5888 - stacked_triplets_loss: 0.6334 - supervised_loss: 0.5425\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5436 - stacked_triplets_loss: 0.4805 - supervised_loss: 0.6067\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.5552 - stacked_triplets_loss: 0.6390 - supervised_loss: 0.4693\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6506 - stacked_triplets_loss: 0.6214 - supervised_loss: 0.6767\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3786 - stacked_triplets_loss: 0.4387 - supervised_loss: 0.3196\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6695 - stacked_triplets_loss: 0.5949 - supervised_loss: 0.7410\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5441 - stacked_triplets_loss: 0.4020 - supervised_loss: 0.6837\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4630 - stacked_triplets_loss: 0.5375 - supervised_loss: 0.3887\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6475 - stacked_triplets_loss: 0.5886 - supervised_loss: 0.7063\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5038 - stacked_triplets_loss: 0.5777 - supervised_loss: 0.4314\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4391 - stacked_triplets_loss: 0.4061 - supervised_loss: 0.4690\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6403 - stacked_triplets_loss: 0.6062 - supervised_loss: 0.6743\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5537 - stacked_triplets_loss: 0.5432 - supervised_loss: 0.5612\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3473 - stacked_triplets_loss: 0.3355 - supervised_loss: 0.3588\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4801 - stacked_triplets_loss: 0.4698 - supervised_loss: 0.4904\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5097 - stacked_triplets_loss: 0.4581 - supervised_loss: 0.5590\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4410 - stacked_triplets_loss: 0.3787 - supervised_loss: 0.5020\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6005 - stacked_triplets_loss: 0.6836 - supervised_loss: 0.5164\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5181 - stacked_triplets_loss: 0.4914 - supervised_loss: 0.5452\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3788 - stacked_triplets_loss: 0.4153 - supervised_loss: 0.3413\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6795 - stacked_triplets_loss: 0.6372 - supervised_loss: 0.7218\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5312 - stacked_triplets_loss: 0.5076 - supervised_loss: 0.5531\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3595 - stacked_triplets_loss: 0.3834 - supervised_loss: 0.3365\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5330 - stacked_triplets_loss: 0.4247 - supervised_loss: 0.6414\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5859 - stacked_triplets_loss: 0.5304 - supervised_loss: 0.6414\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4714 - stacked_triplets_loss: 0.4851 - supervised_loss: 0.4561\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6159 - stacked_triplets_loss: 0.6374 - supervised_loss: 0.5944\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5200 - stacked_triplets_loss: 0.3997 - supervised_loss: 0.6398\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3041 - stacked_triplets_loss: 0.3601 - supervised_loss: 0.2479\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4957 - stacked_triplets_loss: 0.4064 - supervised_loss: 0.5815\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4365 - stacked_triplets_loss: 0.2915 - supervised_loss: 0.5788\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3587 - stacked_triplets_loss: 0.3668 - supervised_loss: 0.3500\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4075 - stacked_triplets_loss: 0.4008 - supervised_loss: 0.4129\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5787 - stacked_triplets_loss: 0.4146 - supervised_loss: 0.7405\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3381 - stacked_triplets_loss: 0.2812 - supervised_loss: 0.3950\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4776 - stacked_triplets_loss: 0.3748 - supervised_loss: 0.5769\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.4234 - stacked_triplets_loss: 0.4179 - supervised_loss: 0.4278\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4742 - stacked_triplets_loss: 0.3898 - supervised_loss: 0.5585\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4836 - stacked_triplets_loss: 0.4565 - supervised_loss: 0.5094\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4608 - stacked_triplets_loss: 0.3607 - supervised_loss: 0.5615\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3179 - stacked_triplets_loss: 0.3259 - supervised_loss: 0.3102\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4966 - stacked_triplets_loss: 0.3828 - supervised_loss: 0.6073\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4421 - stacked_triplets_loss: 0.3637 - supervised_loss: 0.5184\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4419 - stacked_triplets_loss: 0.3690 - supervised_loss: 0.5147\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4305 - stacked_triplets_loss: 0.4021 - supervised_loss: 0.4581\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3204 - stacked_triplets_loss: 0.3099 - supervised_loss: 0.3310\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5131 - stacked_triplets_loss: 0.4632 - supervised_loss: 0.5630\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4578 - stacked_triplets_loss: 0.3879 - supervised_loss: 0.5251\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3173 - stacked_triplets_loss: 0.2676 - supervised_loss: 0.3672\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4194 - stacked_triplets_loss: 0.3777 - supervised_loss: 0.4587\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5802 - stacked_triplets_loss: 0.4124 - supervised_loss: 0.7481\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4111 - stacked_triplets_loss: 0.3762 - supervised_loss: 0.4467\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4302 - stacked_triplets_loss: 0.3357 - supervised_loss: 0.5233\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4053 - stacked_triplets_loss: 0.3467 - supervised_loss: 0.4627\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4006 - stacked_triplets_loss: 0.4162 - supervised_loss: 0.3838\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5052 - stacked_triplets_loss: 0.3955 - supervised_loss: 0.6129\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3124 - stacked_triplets_loss: 0.3408 - supervised_loss: 0.2837\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5257 - stacked_triplets_loss: 0.3749 - supervised_loss: 0.6765\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2891 - stacked_triplets_loss: 0.2452 - supervised_loss: 0.3328\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4351 - stacked_triplets_loss: 0.3435 - supervised_loss: 0.5249\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4147 - stacked_triplets_loss: 0.3031 - supervised_loss: 0.5243\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2207 - stacked_triplets_loss: 0.2538 - supervised_loss: 0.1878\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4987 - stacked_triplets_loss: 0.3322 - supervised_loss: 0.6652\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4442 - stacked_triplets_loss: 0.3800 - supervised_loss: 0.5070\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5305 - stacked_triplets_loss: 0.3467 - supervised_loss: 0.7143\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3289 - stacked_triplets_loss: 0.2834 - supervised_loss: 0.3740\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4446 - stacked_triplets_loss: 0.3912 - supervised_loss: 0.4978\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2773 - stacked_triplets_loss: 0.2651 - supervised_loss: 0.2891\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4441 - stacked_triplets_loss: 0.3525 - supervised_loss: 0.5356\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4512 - stacked_triplets_loss: 0.4379 - supervised_loss: 0.4607\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4022 - stacked_triplets_loss: 0.3064 - supervised_loss: 0.4980\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4192 - stacked_triplets_loss: 0.3448 - supervised_loss: 0.4934\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4235 - stacked_triplets_loss: 0.3241 - supervised_loss: 0.5205\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2817 - stacked_triplets_loss: 0.3906 - supervised_loss: 0.1734\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4741 - stacked_triplets_loss: 0.2871 - supervised_loss: 0.6583\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4177 - stacked_triplets_loss: 0.4077 - supervised_loss: 0.4278\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4655 - stacked_triplets_loss: 0.3255 - supervised_loss: 0.6032\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3406 - stacked_triplets_loss: 0.2774 - supervised_loss: 0.4031\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4180 - stacked_triplets_loss: 0.2815 - supervised_loss: 0.5529\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3664 - stacked_triplets_loss: 0.2843 - supervised_loss: 0.4468\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3225 - stacked_triplets_loss: 0.2948 - supervised_loss: 0.3501\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4472 - stacked_triplets_loss: 0.4459 - supervised_loss: 0.4436\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3830 - stacked_triplets_loss: 0.2858 - supervised_loss: 0.4803\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4373 - stacked_triplets_loss: 0.3495 - supervised_loss: 0.5228\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4335 - stacked_triplets_loss: 0.3653 - supervised_loss: 0.5007\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4246 - stacked_triplets_loss: 0.4098 - supervised_loss: 0.4379\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4182 - stacked_triplets_loss: 0.3432 - supervised_loss: 0.4921\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4030 - stacked_triplets_loss: 0.3261 - supervised_loss: 0.4780\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2963 - stacked_triplets_loss: 0.2678 - supervised_loss: 0.3237\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4290 - stacked_triplets_loss: 0.3834 - supervised_loss: 0.4746\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4483 - stacked_triplets_loss: 0.4169 - supervised_loss: 0.4785\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2644 - stacked_triplets_loss: 0.2087 - supervised_loss: 0.3200\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4862 - stacked_triplets_loss: 0.3419 - supervised_loss: 0.6282\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2968 - stacked_triplets_loss: 0.2508 - supervised_loss: 0.3435\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4556 - stacked_triplets_loss: 0.3666 - supervised_loss: 0.5447\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4274 - stacked_triplets_loss: 0.3176 - supervised_loss: 0.5361\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4166 - stacked_triplets_loss: 0.3026 - supervised_loss: 0.5300\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3006 - stacked_triplets_loss: 0.2822 - supervised_loss: 0.3189\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3745 - stacked_triplets_loss: 0.3074 - supervised_loss: 0.4375\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4102 - stacked_triplets_loss: 0.2650 - supervised_loss: 0.5554\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4556 - stacked_triplets_loss: 0.3391 - supervised_loss: 0.5707\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3841 - stacked_triplets_loss: 0.3466 - supervised_loss: 0.4210\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4061 - stacked_triplets_loss: 0.3184 - supervised_loss: 0.4925\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3637 - stacked_triplets_loss: 0.2859 - supervised_loss: 0.4415\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3120 - stacked_triplets_loss: 0.2770 - supervised_loss: 0.3456\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3947 - stacked_triplets_loss: 0.2913 - supervised_loss: 0.4961\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3811 - stacked_triplets_loss: 0.2806 - supervised_loss: 0.4805\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3946 - stacked_triplets_loss: 0.3657 - supervised_loss: 0.4229\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4079 - stacked_triplets_loss: 0.2745 - supervised_loss: 0.5413\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3906 - stacked_triplets_loss: 0.2589 - supervised_loss: 0.5201\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3306 - stacked_triplets_loss: 0.2821 - supervised_loss: 0.3782\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3438 - stacked_triplets_loss: 0.3153 - supervised_loss: 0.3716\n",
      "745/745 [==============================] - 1s 1ms/sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ivis = Ivis(embedding_dims=3, k=5)\n",
    "x_red = ivis.fit_transform(np.array(x), np.array(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_red, y)\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       147\n",
      "           1       0.83      0.50      0.62        40\n",
      "\n",
      "    accuracy                           0.87       187\n",
      "   macro avg       0.86      0.74      0.77       187\n",
      "weighted avg       0.87      0.87      0.86       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "x_res, y_res = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       147\n",
      "           1       0.45      0.65      0.53        40\n",
      "\n",
      "    accuracy                           0.75       187\n",
      "   macro avg       0.67      0.72      0.68       187\n",
      "weighted avg       0.80      0.75      0.77       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_res, y_res)\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.79      0.85       147\n",
      "           1       0.48      0.72      0.58        40\n",
      "\n",
      "    accuracy                           0.78       187\n",
      "   macro avg       0.70      0.76      0.71       187\n",
      "weighted avg       0.82      0.78      0.79       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adasyn = ADASYN()\n",
    "_x_res, _y_res = adasyn.fit_resample(x_train, y_train)\n",
    "model.fit(_x_res, _y_res)\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       147\n",
      "           1       0.48      0.72      0.57        40\n",
      "\n",
      "    accuracy                           0.77       187\n",
      "   macro avg       0.69      0.75      0.71       187\n",
      "weighted avg       0.82      0.77      0.79       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand = RandomOverSampler()\n",
    "_x_res, _y_res = rand.fit_resample(x_train, y_train)\n",
    "model.fit(_x_res, _y_res)\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could we use SMOTUNED here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "558/558 [==============================] - 5s 9ms/step - loss: 0.6692 - acc: 0.7079\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 0.6286 - acc: 0.7240\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 0s 275us/step - loss: 0.6241 - acc: 0.7563\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.6176 - acc: 0.7401\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 0s 290us/step - loss: 0.6157 - acc: 0.7294\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.5993 - acc: 0.7509\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 0s 289us/step - loss: 0.6072 - acc: 0.7312\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.5992 - acc: 0.7294\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.5841 - acc: 0.7527\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 0s 295us/step - loss: 0.5882 - acc: 0.7455\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 0.5842 - acc: 0.7366\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.5689 - acc: 0.7527\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.5760 - acc: 0.7527\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 0s 282us/step - loss: 0.5642 - acc: 0.7616\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 0s 258us/step - loss: 0.5522 - acc: 0.7706\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.5565 - acc: 0.7616\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 0s 285us/step - loss: 0.5574 - acc: 0.7563\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.5510 - acc: 0.7706\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 0.5532 - acc: 0.7599\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.5386 - acc: 0.7778\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 0s 289us/step - loss: 0.5479 - acc: 0.7473\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.5426 - acc: 0.7688\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 0s 297us/step - loss: 0.5301 - acc: 0.7742\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 0.5271 - acc: 0.7724\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 0s 256us/step - loss: 0.5390 - acc: 0.7724\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 0s 262us/step - loss: 0.5269 - acc: 0.7670\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 0s 283us/step - loss: 0.5160 - acc: 0.7814\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 0s 295us/step - loss: 0.5206 - acc: 0.7796\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 0s 265us/step - loss: 0.5191 - acc: 0.7724\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 0s 312us/step - loss: 0.5244 - acc: 0.7599\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.5088 - acc: 0.7796\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 0s 254us/step - loss: 0.5186 - acc: 0.7616\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 0s 264us/step - loss: 0.5016 - acc: 0.7778\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 0.5070 - acc: 0.7849\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 0s 284us/step - loss: 0.5003 - acc: 0.7921\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 0s 290us/step - loss: 0.5006 - acc: 0.7921\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 0s 283us/step - loss: 0.4893 - acc: 0.7921\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 0s 293us/step - loss: 0.4945 - acc: 0.7814\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 0s 297us/step - loss: 0.4834 - acc: 0.7957\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.4853 - acc: 0.7939\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4870 - acc: 0.7832\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 0s 261us/step - loss: 0.4839 - acc: 0.7975\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 0s 319us/step - loss: 0.4832 - acc: 0.7975\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 0s 268us/step - loss: 0.4867 - acc: 0.7903\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 0s 291us/step - loss: 0.4810 - acc: 0.7921\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 0s 276us/step - loss: 0.4849 - acc: 0.7796\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 0s 293us/step - loss: 0.4815 - acc: 0.7742\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 0s 281us/step - loss: 0.4734 - acc: 0.7939\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 0.4864 - acc: 0.7670\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 0s 318us/step - loss: 0.4742 - acc: 0.8065\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 0s 318us/step - loss: 0.4725 - acc: 0.7975\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 0s 298us/step - loss: 0.4675 - acc: 0.8047\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 0.4737 - acc: 0.7760\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 0s 285us/step - loss: 0.4663 - acc: 0.8029\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 0s 366us/step - loss: 0.4647 - acc: 0.7939\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 0s 325us/step - loss: 0.4673 - acc: 0.7939\n",
      "Epoch 57/100\n",
      "558/558 [==============================] - 0s 298us/step - loss: 0.4710 - acc: 0.8047\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 0s 326us/step - loss: 0.4617 - acc: 0.8100\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 0s 344us/step - loss: 0.4687 - acc: 0.7832\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 0s 316us/step - loss: 0.4653 - acc: 0.7957\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 0.4559 - acc: 0.8154\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 0s 289us/step - loss: 0.4709 - acc: 0.7993\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4635 - acc: 0.7867\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4553 - acc: 0.7975\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 0.4596 - acc: 0.7939\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4570 - acc: 0.8029\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 0s 291us/step - loss: 0.4555 - acc: 0.7957\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 0s 369us/step - loss: 0.4605 - acc: 0.7885\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 0s 312us/step - loss: 0.4512 - acc: 0.8082\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 0s 287us/step - loss: 0.4489 - acc: 0.7957\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 0s 278us/step - loss: 0.4461 - acc: 0.8029\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 0s 318us/step - loss: 0.4437 - acc: 0.8100\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4536 - acc: 0.7993\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.4497 - acc: 0.8047\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 0s 260us/step - loss: 0.4437 - acc: 0.7993\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.4460 - acc: 0.8100\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4465 - acc: 0.8082\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 0s 287us/step - loss: 0.4412 - acc: 0.8047\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 0s 271us/step - loss: 0.4429 - acc: 0.8047\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 0s 283us/step - loss: 0.4337 - acc: 0.8208\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 0s 275us/step - loss: 0.4473 - acc: 0.8118\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 0s 312us/step - loss: 0.4416 - acc: 0.8047\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 0s 340us/step - loss: 0.4422 - acc: 0.7957\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 0.4296 - acc: 0.8190\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4379 - acc: 0.8011\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 0s 268us/step - loss: 0.4446 - acc: 0.8029\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.4390 - acc: 0.8065\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4427 - acc: 0.8011\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4444 - acc: 0.8011\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 0s 259us/step - loss: 0.4380 - acc: 0.8118\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 0s 288us/step - loss: 0.4371 - acc: 0.8047\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 0.4469 - acc: 0.7939\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4389 - acc: 0.8172\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 0.4373 - acc: 0.8136\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 0.4291 - acc: 0.8082\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 0s 282us/step - loss: 0.4401 - acc: 0.8065\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 0s 263us/step - loss: 0.4331 - acc: 0.8100\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 0.4445 - acc: 0.8029\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 0s 278us/step - loss: 0.4381 - acc: 0.8029\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 0.4408 - acc: 0.8136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f205520f910>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(3,)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1),\n",
    "    BatchNormalization(),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       147\n",
      "           1       0.77      0.50      0.61        40\n",
      "\n",
      "    accuracy                           0.86       187\n",
      "   macro avg       0.82      0.73      0.76       187\n",
      "weighted avg       0.85      0.86      0.85       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.6883 - acc: 0.6331\n",
      "Epoch 2/100\n",
      "864/864 [==============================] - 0s 308us/step - loss: 0.6729 - acc: 0.6111\n",
      "Epoch 3/100\n",
      "864/864 [==============================] - 0s 306us/step - loss: 0.6574 - acc: 0.6146\n",
      "Epoch 4/100\n",
      "864/864 [==============================] - 0s 313us/step - loss: 0.6449 - acc: 0.6215\n",
      "Epoch 5/100\n",
      "864/864 [==============================] - 0s 319us/step - loss: 0.6377 - acc: 0.6308\n",
      "Epoch 6/100\n",
      "864/864 [==============================] - 0s 297us/step - loss: 0.6285 - acc: 0.6690\n",
      "Epoch 7/100\n",
      "864/864 [==============================] - 0s 319us/step - loss: 0.6213 - acc: 0.6678\n",
      "Epoch 8/100\n",
      "864/864 [==============================] - 0s 321us/step - loss: 0.6213 - acc: 0.6817\n",
      "Epoch 9/100\n",
      "864/864 [==============================] - 0s 326us/step - loss: 0.6244 - acc: 0.6713\n",
      "Epoch 10/100\n",
      "864/864 [==============================] - 0s 371us/step - loss: 0.6051 - acc: 0.6933\n",
      "Epoch 11/100\n",
      "864/864 [==============================] - 0s 372us/step - loss: 0.5963 - acc: 0.6887\n",
      "Epoch 12/100\n",
      "864/864 [==============================] - 0s 293us/step - loss: 0.6013 - acc: 0.6875\n",
      "Epoch 13/100\n",
      "864/864 [==============================] - 0s 398us/step - loss: 0.6014 - acc: 0.7049\n",
      "Epoch 14/100\n",
      "864/864 [==============================] - 0s 314us/step - loss: 0.5862 - acc: 0.6968\n",
      "Epoch 15/100\n",
      "864/864 [==============================] - 0s 312us/step - loss: 0.5809 - acc: 0.7130\n",
      "Epoch 16/100\n",
      "864/864 [==============================] - 0s 334us/step - loss: 0.5818 - acc: 0.7037\n",
      "Epoch 17/100\n",
      "864/864 [==============================] - 0s 346us/step - loss: 0.5741 - acc: 0.7106\n",
      "Epoch 18/100\n",
      "864/864 [==============================] - 0s 312us/step - loss: 0.5746 - acc: 0.7188\n",
      "Epoch 19/100\n",
      "864/864 [==============================] - 0s 328us/step - loss: 0.5643 - acc: 0.7164\n",
      "Epoch 20/100\n",
      "864/864 [==============================] - 0s 337us/step - loss: 0.5638 - acc: 0.7141\n",
      "Epoch 21/100\n",
      "864/864 [==============================] - 0s 394us/step - loss: 0.5599 - acc: 0.7350\n",
      "Epoch 22/100\n",
      "864/864 [==============================] - 0s 424us/step - loss: 0.5600 - acc: 0.7211\n",
      "Epoch 23/100\n",
      "864/864 [==============================] - 0s 404us/step - loss: 0.5605 - acc: 0.7373\n",
      "Epoch 24/100\n",
      "864/864 [==============================] - 0s 350us/step - loss: 0.5602 - acc: 0.7384\n",
      "Epoch 25/100\n",
      "864/864 [==============================] - 0s 316us/step - loss: 0.5561 - acc: 0.7361\n",
      "Epoch 26/100\n",
      "864/864 [==============================] - 0s 308us/step - loss: 0.5553 - acc: 0.7292\n",
      "Epoch 27/100\n",
      "864/864 [==============================] - 0s 334us/step - loss: 0.5477 - acc: 0.7292\n",
      "Epoch 28/100\n",
      "864/864 [==============================] - 0s 362us/step - loss: 0.5452 - acc: 0.7350\n",
      "Epoch 29/100\n",
      "864/864 [==============================] - 0s 345us/step - loss: 0.5438 - acc: 0.7419\n",
      "Epoch 30/100\n",
      "864/864 [==============================] - 0s 302us/step - loss: 0.5560 - acc: 0.7280\n",
      "Epoch 31/100\n",
      "864/864 [==============================] - 0s 334us/step - loss: 0.5525 - acc: 0.7361\n",
      "Epoch 32/100\n",
      "864/864 [==============================] - 0s 341us/step - loss: 0.5401 - acc: 0.7488\n",
      "Epoch 33/100\n",
      "864/864 [==============================] - 0s 373us/step - loss: 0.5422 - acc: 0.7431\n",
      "Epoch 34/100\n",
      "864/864 [==============================] - 0s 358us/step - loss: 0.5190 - acc: 0.7442\n",
      "Epoch 35/100\n",
      "864/864 [==============================] - 0s 387us/step - loss: 0.5463 - acc: 0.7338\n",
      "Epoch 36/100\n",
      "864/864 [==============================] - 0s 348us/step - loss: 0.5338 - acc: 0.7338\n",
      "Epoch 37/100\n",
      "864/864 [==============================] - 0s 372us/step - loss: 0.5346 - acc: 0.7407\n",
      "Epoch 38/100\n",
      "864/864 [==============================] - 0s 326us/step - loss: 0.5462 - acc: 0.7350\n",
      "Epoch 39/100\n",
      "864/864 [==============================] - 0s 361us/step - loss: 0.5311 - acc: 0.7465\n",
      "Epoch 40/100\n",
      "864/864 [==============================] - 0s 382us/step - loss: 0.5338 - acc: 0.7373\n",
      "Epoch 41/100\n",
      "864/864 [==============================] - 0s 357us/step - loss: 0.5219 - acc: 0.7373\n",
      "Epoch 42/100\n",
      "864/864 [==============================] - 0s 349us/step - loss: 0.5400 - acc: 0.7384\n",
      "Epoch 43/100\n",
      "864/864 [==============================] - 0s 330us/step - loss: 0.5322 - acc: 0.7558\n",
      "Epoch 44/100\n",
      "864/864 [==============================] - 0s 346us/step - loss: 0.5294 - acc: 0.7442\n",
      "Epoch 45/100\n",
      "864/864 [==============================] - 0s 323us/step - loss: 0.5285 - acc: 0.7326\n",
      "Epoch 46/100\n",
      "864/864 [==============================] - 0s 327us/step - loss: 0.5232 - acc: 0.7384\n",
      "Epoch 47/100\n",
      "864/864 [==============================] - 0s 355us/step - loss: 0.5386 - acc: 0.7407\n",
      "Epoch 48/100\n",
      "864/864 [==============================] - 0s 372us/step - loss: 0.5195 - acc: 0.7419\n",
      "Epoch 49/100\n",
      "864/864 [==============================] - 0s 362us/step - loss: 0.5332 - acc: 0.7407\n",
      "Epoch 50/100\n",
      "864/864 [==============================] - 0s 373us/step - loss: 0.5259 - acc: 0.7500\n",
      "Epoch 51/100\n",
      "864/864 [==============================] - 0s 386us/step - loss: 0.5239 - acc: 0.7558\n",
      "Epoch 52/100\n",
      "864/864 [==============================] - 0s 289us/step - loss: 0.5233 - acc: 0.7569\n",
      "Epoch 53/100\n",
      "864/864 [==============================] - 0s 311us/step - loss: 0.5314 - acc: 0.7338\n",
      "Epoch 54/100\n",
      "864/864 [==============================] - 0s 363us/step - loss: 0.5231 - acc: 0.7257\n",
      "Epoch 55/100\n",
      "864/864 [==============================] - 0s 359us/step - loss: 0.5239 - acc: 0.7465\n",
      "Epoch 56/100\n",
      "864/864 [==============================] - 0s 328us/step - loss: 0.5184 - acc: 0.7442\n",
      "Epoch 57/100\n",
      "864/864 [==============================] - 0s 318us/step - loss: 0.5174 - acc: 0.7465\n",
      "Epoch 58/100\n",
      "864/864 [==============================] - 0s 330us/step - loss: 0.5226 - acc: 0.7431\n",
      "Epoch 59/100\n",
      "864/864 [==============================] - 0s 307us/step - loss: 0.5225 - acc: 0.7419\n",
      "Epoch 60/100\n",
      "864/864 [==============================] - 0s 323us/step - loss: 0.5221 - acc: 0.7442\n",
      "Epoch 61/100\n",
      "864/864 [==============================] - 0s 314us/step - loss: 0.5289 - acc: 0.7442\n",
      "Epoch 62/100\n",
      "864/864 [==============================] - 0s 320us/step - loss: 0.5180 - acc: 0.7407\n",
      "Epoch 63/100\n",
      "864/864 [==============================] - 0s 291us/step - loss: 0.5361 - acc: 0.7361\n",
      "Epoch 64/100\n",
      "864/864 [==============================] - 0s 328us/step - loss: 0.5307 - acc: 0.7558\n",
      "Epoch 65/100\n",
      "864/864 [==============================] - 0s 333us/step - loss: 0.5370 - acc: 0.7361\n",
      "Epoch 66/100\n",
      "864/864 [==============================] - 0s 299us/step - loss: 0.5210 - acc: 0.7407\n",
      "Epoch 67/100\n",
      "864/864 [==============================] - 0s 331us/step - loss: 0.5108 - acc: 0.7523\n",
      "Epoch 68/100\n",
      "864/864 [==============================] - 0s 304us/step - loss: 0.5128 - acc: 0.7431\n",
      "Epoch 69/100\n",
      "864/864 [==============================] - 0s 310us/step - loss: 0.5199 - acc: 0.7477\n",
      "Epoch 70/100\n",
      "864/864 [==============================] - 0s 300us/step - loss: 0.5295 - acc: 0.7292\n",
      "Epoch 71/100\n",
      "864/864 [==============================] - 0s 310us/step - loss: 0.5188 - acc: 0.7465\n",
      "Epoch 72/100\n",
      "864/864 [==============================] - 0s 318us/step - loss: 0.5137 - acc: 0.7488\n",
      "Epoch 73/100\n",
      "864/864 [==============================] - 0s 313us/step - loss: 0.5273 - acc: 0.7454\n",
      "Epoch 74/100\n",
      "864/864 [==============================] - 0s 349us/step - loss: 0.5028 - acc: 0.7650\n",
      "Epoch 75/100\n",
      "864/864 [==============================] - 0s 310us/step - loss: 0.5211 - acc: 0.7361\n",
      "Epoch 76/100\n",
      "864/864 [==============================] - 0s 342us/step - loss: 0.5131 - acc: 0.7407\n",
      "Epoch 77/100\n",
      "864/864 [==============================] - 0s 327us/step - loss: 0.5131 - acc: 0.7500\n",
      "Epoch 78/100\n",
      "864/864 [==============================] - 0s 329us/step - loss: 0.5257 - acc: 0.7303\n",
      "Epoch 79/100\n",
      "864/864 [==============================] - 0s 357us/step - loss: 0.5130 - acc: 0.7431\n",
      "Epoch 80/100\n",
      "864/864 [==============================] - 0s 358us/step - loss: 0.5284 - acc: 0.7315\n",
      "Epoch 81/100\n",
      "864/864 [==============================] - 0s 369us/step - loss: 0.5239 - acc: 0.7350\n",
      "Epoch 82/100\n",
      "864/864 [==============================] - 0s 345us/step - loss: 0.5137 - acc: 0.7558\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 0s 324us/step - loss: 0.5112 - acc: 0.7454\n",
      "Epoch 84/100\n",
      "864/864 [==============================] - 0s 311us/step - loss: 0.5061 - acc: 0.7593\n",
      "Epoch 85/100\n",
      "864/864 [==============================] - 0s 316us/step - loss: 0.5196 - acc: 0.7442\n",
      "Epoch 86/100\n",
      "864/864 [==============================] - 0s 316us/step - loss: 0.5109 - acc: 0.7523\n",
      "Epoch 87/100\n",
      "864/864 [==============================] - 0s 296us/step - loss: 0.5182 - acc: 0.7454\n",
      "Epoch 88/100\n",
      "864/864 [==============================] - 0s 309us/step - loss: 0.5149 - acc: 0.7512\n",
      "Epoch 89/100\n",
      "864/864 [==============================] - 0s 297us/step - loss: 0.5163 - acc: 0.7407\n",
      "Epoch 90/100\n",
      "864/864 [==============================] - 0s 325us/step - loss: 0.5143 - acc: 0.7500\n",
      "Epoch 91/100\n",
      "864/864 [==============================] - 0s 310us/step - loss: 0.5234 - acc: 0.7245\n",
      "Epoch 92/100\n",
      "864/864 [==============================] - 0s 309us/step - loss: 0.5158 - acc: 0.7512\n",
      "Epoch 93/100\n",
      "864/864 [==============================] - 0s 320us/step - loss: 0.5250 - acc: 0.7500\n",
      "Epoch 94/100\n",
      "864/864 [==============================] - 0s 356us/step - loss: 0.5146 - acc: 0.7419\n",
      "Epoch 95/100\n",
      "864/864 [==============================] - 0s 299us/step - loss: 0.5168 - acc: 0.7361\n",
      "Epoch 96/100\n",
      "864/864 [==============================] - 0s 318us/step - loss: 0.5210 - acc: 0.7396\n",
      "Epoch 97/100\n",
      "864/864 [==============================] - 0s 313us/step - loss: 0.5204 - acc: 0.7407\n",
      "Epoch 98/100\n",
      "864/864 [==============================] - 0s 313us/step - loss: 0.5134 - acc: 0.7465\n",
      "Epoch 99/100\n",
      "864/864 [==============================] - 0s 365us/step - loss: 0.5229 - acc: 0.7419\n",
      "Epoch 100/100\n",
      "864/864 [==============================] - 0s 339us/step - loss: 0.5246 - acc: 0.7384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f205705ffd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(_x_res, _y_res, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.82       147\n",
      "           1       0.44      0.78      0.56        40\n",
      "\n",
      "    accuracy                           0.74       187\n",
      "   macro avg       0.68      0.75      0.69       187\n",
      "weighted avg       0.82      0.74      0.76       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 45485.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building KNN index\n",
      "Extracting KNN from index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 745/745 [00:00<00:00, 4953.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 9s 2s/step - loss: 26.7461 - stacked_triplets_loss: 19.7766 - supervised_loss: 33.4669\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 13.3267 - stacked_triplets_loss: 15.9387 - supervised_loss: 10.7031\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 13.2631 - stacked_triplets_loss: 15.1134 - supervised_loss: 11.3227\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 5.3228 - stacked_triplets_loss: 9.0205 - supervised_loss: 1.6250\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 11.5862 - stacked_triplets_loss: 14.9376 - supervised_loss: 8.1818\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.3627 - stacked_triplets_loss: 5.2766 - supervised_loss: 5.4370\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.7729 - stacked_triplets_loss: 5.6202 - supervised_loss: 1.9118\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 11.6098 - stacked_triplets_loss: 10.0202 - supervised_loss: 13.1247\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 6.1624 - stacked_triplets_loss: 5.3366 - supervised_loss: 6.9882\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 4.6081 - stacked_triplets_loss: 5.6883 - supervised_loss: 3.5271\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 6.1936 - stacked_triplets_loss: 6.7216 - supervised_loss: 5.6655\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.1287 - stacked_triplets_loss: 5.4216 - supervised_loss: 2.8114\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 4.6540 - stacked_triplets_loss: 5.6478 - supervised_loss: 3.6554\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 3.3292 - stacked_triplets_loss: 2.6517 - supervised_loss: 4.0079\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 3.9060 - stacked_triplets_loss: 5.1477 - supervised_loss: 2.6643\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 3.4584 - stacked_triplets_loss: 4.0650 - supervised_loss: 2.8427\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 3.9427 - stacked_triplets_loss: 4.5917 - supervised_loss: 3.2982\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.0550 - stacked_triplets_loss: 4.0425 - supervised_loss: 2.0482\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4.0516 - stacked_triplets_loss: 4.8984 - supervised_loss: 3.1881\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 2.8748 - stacked_triplets_loss: 3.4111 - supervised_loss: 2.3383\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 2.6068 - stacked_triplets_loss: 2.9012 - supervised_loss: 2.3064\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 3.0211 - stacked_triplets_loss: 3.9487 - supervised_loss: 2.0935\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 3.2452 - stacked_triplets_loss: 4.1272 - supervised_loss: 2.3477\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.9604 - stacked_triplets_loss: 1.7087 - supervised_loss: 2.2168\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2.3387 - stacked_triplets_loss: 2.5851 - supervised_loss: 2.0923\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.5447 - stacked_triplets_loss: 3.3370 - supervised_loss: 1.7492\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.6192 - stacked_triplets_loss: 2.1213 - supervised_loss: 1.1205\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 2.0194 - stacked_triplets_loss: 2.4105 - supervised_loss: 1.6283\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.4747 - stacked_triplets_loss: 3.1917 - supervised_loss: 1.7454\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2334 - stacked_triplets_loss: 1.5762 - supervised_loss: 0.8928\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.1035 - stacked_triplets_loss: 1.6457 - supervised_loss: 0.5569\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 3.1471 - stacked_triplets_loss: 2.8729 - supervised_loss: 3.4213\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.6837 - stacked_triplets_loss: 1.4670 - supervised_loss: 1.9075\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.7181 - stacked_triplets_loss: 2.1179 - supervised_loss: 1.3158\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.9411 - stacked_triplets_loss: 2.2221 - supervised_loss: 1.6354\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9729 - stacked_triplets_loss: 1.9936 - supervised_loss: 1.9523\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2.0610 - stacked_triplets_loss: 2.4537 - supervised_loss: 1.6640\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4189 - stacked_triplets_loss: 1.7151 - supervised_loss: 1.1152\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.8530 - stacked_triplets_loss: 1.5016 - supervised_loss: 0.2048\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 2.8427 - stacked_triplets_loss: 2.1388 - supervised_loss: 3.5199\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.1478 - stacked_triplets_loss: 1.0716 - supervised_loss: 1.2297\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.6999 - stacked_triplets_loss: 1.9945 - supervised_loss: 1.4052\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.5661 - stacked_triplets_loss: 1.8885 - supervised_loss: 1.2396\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.7144 - stacked_triplets_loss: 1.0918 - supervised_loss: 0.3364\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 2.0098 - stacked_triplets_loss: 1.8201 - supervised_loss: 2.1815\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.5020 - stacked_triplets_loss: 2.0754 - supervised_loss: 0.9286\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.5406 - stacked_triplets_loss: 1.6475 - supervised_loss: 1.4338\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9130 - stacked_triplets_loss: 1.0726 - supervised_loss: 0.7519\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.3928 - stacked_triplets_loss: 1.3900 - supervised_loss: 1.3956\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1332 - stacked_triplets_loss: 1.4518 - supervised_loss: 0.8094\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.9187 - stacked_triplets_loss: 1.0978 - supervised_loss: 0.7424\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9888 - stacked_triplets_loss: 1.2436 - supervised_loss: 0.7340\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1579 - stacked_triplets_loss: 1.1279 - supervised_loss: 1.1814\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.2201 - stacked_triplets_loss: 1.1981 - supervised_loss: 1.2345\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.2604 - stacked_triplets_loss: 1.2537 - supervised_loss: 1.2643\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.8996 - stacked_triplets_loss: 1.1447 - supervised_loss: 0.6527\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0746 - stacked_triplets_loss: 1.2472 - supervised_loss: 0.8989\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.0648 - stacked_triplets_loss: 0.9809 - supervised_loss: 1.1411\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 35ms/step - loss: 1.0141 - stacked_triplets_loss: 1.0308 - supervised_loss: 0.9963\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9489 - stacked_triplets_loss: 0.9666 - supervised_loss: 0.9313\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.9798 - stacked_triplets_loss: 1.0200 - supervised_loss: 0.9395\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.8852 - stacked_triplets_loss: 0.9587 - supervised_loss: 0.8088\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9922 - stacked_triplets_loss: 0.9795 - supervised_loss: 1.0003\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8724 - stacked_triplets_loss: 0.8789 - supervised_loss: 0.8663\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7948 - stacked_triplets_loss: 0.8818 - supervised_loss: 0.7078\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.1160 - stacked_triplets_loss: 1.2861 - supervised_loss: 0.9388\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9422 - stacked_triplets_loss: 1.0994 - supervised_loss: 0.7805\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7071 - stacked_triplets_loss: 0.7155 - supervised_loss: 0.6988\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.8811 - stacked_triplets_loss: 0.9422 - supervised_loss: 0.8152\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5670 - stacked_triplets_loss: 0.6370 - supervised_loss: 0.4950\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.9406 - stacked_triplets_loss: 0.9693 - supervised_loss: 0.9057\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.7371 - stacked_triplets_loss: 0.7874 - supervised_loss: 0.6868\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.7131 - stacked_triplets_loss: 0.8154 - supervised_loss: 0.6125\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0249 - stacked_triplets_loss: 0.8803 - supervised_loss: 1.1647\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7844 - stacked_triplets_loss: 0.8727 - supervised_loss: 0.6961\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7980 - stacked_triplets_loss: 0.7757 - supervised_loss: 0.8118\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.9905 - stacked_triplets_loss: 1.1047 - supervised_loss: 0.8693\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.8181 - stacked_triplets_loss: 0.9988 - supervised_loss: 0.6374\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.6761 - stacked_triplets_loss: 0.6945 - supervised_loss: 0.6578\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.9666 - stacked_triplets_loss: 1.0002 - supervised_loss: 0.9272\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8693 - stacked_triplets_loss: 0.8963 - supervised_loss: 0.8423\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5407 - stacked_triplets_loss: 0.7970 - supervised_loss: 0.2839\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9939 - stacked_triplets_loss: 1.0254 - supervised_loss: 0.9544\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.7513 - stacked_triplets_loss: 0.7794 - supervised_loss: 0.7246\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6162 - stacked_triplets_loss: 0.6900 - supervised_loss: 0.5417\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.0650 - stacked_triplets_loss: 0.9523 - supervised_loss: 1.1720\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6334 - stacked_triplets_loss: 0.6471 - supervised_loss: 0.6174\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7502 - stacked_triplets_loss: 0.8185 - supervised_loss: 0.6819\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5763 - stacked_triplets_loss: 0.6069 - supervised_loss: 0.5451\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7222 - stacked_triplets_loss: 0.8393 - supervised_loss: 0.6048\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7677 - stacked_triplets_loss: 0.8507 - supervised_loss: 0.6800\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7523 - stacked_triplets_loss: 0.6638 - supervised_loss: 0.8344\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6296 - stacked_triplets_loss: 0.7399 - supervised_loss: 0.5186\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5514 - stacked_triplets_loss: 0.5743 - supervised_loss: 0.5289\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7301 - stacked_triplets_loss: 0.7035 - supervised_loss: 0.7568\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6609 - stacked_triplets_loss: 0.7454 - supervised_loss: 0.5722\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4576 - stacked_triplets_loss: 0.5740 - supervised_loss: 0.3424\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7872 - stacked_triplets_loss: 0.8121 - supervised_loss: 0.7589\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4966 - stacked_triplets_loss: 0.4668 - supervised_loss: 0.5264\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6001 - stacked_triplets_loss: 0.6538 - supervised_loss: 0.5434\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.9265 - stacked_triplets_loss: 0.7841 - supervised_loss: 1.0621\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5550 - stacked_triplets_loss: 0.5635 - supervised_loss: 0.5469\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6664 - stacked_triplets_loss: 0.6169 - supervised_loss: 0.7129\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6526 - stacked_triplets_loss: 0.8083 - supervised_loss: 0.4956\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.5346 - stacked_triplets_loss: 0.6760 - supervised_loss: 0.3933\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.8606 - stacked_triplets_loss: 0.8491 - supervised_loss: 0.8651\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4919 - stacked_triplets_loss: 0.4206 - supervised_loss: 0.5619\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6921 - stacked_triplets_loss: 0.7632 - supervised_loss: 0.6168\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5766 - stacked_triplets_loss: 0.6162 - supervised_loss: 0.5345\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5933 - stacked_triplets_loss: 0.5680 - supervised_loss: 0.6186\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7175 - stacked_triplets_loss: 0.7440 - supervised_loss: 0.6910\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5817 - stacked_triplets_loss: 0.5704 - supervised_loss: 0.5884\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6202 - stacked_triplets_loss: 0.6752 - supervised_loss: 0.5653\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4185 - stacked_triplets_loss: 0.4646 - supervised_loss: 0.3725\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5798 - stacked_triplets_loss: 0.5772 - supervised_loss: 0.5798\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7193 - stacked_triplets_loss: 0.8291 - supervised_loss: 0.6073\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5789 - stacked_triplets_loss: 0.5463 - supervised_loss: 0.6114\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5561 - stacked_triplets_loss: 0.5108 - supervised_loss: 0.6034\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6101 - stacked_triplets_loss: 0.4988 - supervised_loss: 0.7174\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6343 - stacked_triplets_loss: 0.5823 - supervised_loss: 0.6829\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6029 - stacked_triplets_loss: 0.5463 - supervised_loss: 0.6589\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5831 - stacked_triplets_loss: 0.4908 - supervised_loss: 0.6736\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4999 - stacked_triplets_loss: 0.5763 - supervised_loss: 0.4233\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.5499 - stacked_triplets_loss: 0.5676 - supervised_loss: 0.5323\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6514 - stacked_triplets_loss: 0.6776 - supervised_loss: 0.6208\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5930 - stacked_triplets_loss: 0.6198 - supervised_loss: 0.5641\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5471 - stacked_triplets_loss: 0.4722 - supervised_loss: 0.6226\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4236 - stacked_triplets_loss: 0.4235 - supervised_loss: 0.4237\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6327 - stacked_triplets_loss: 0.5725 - supervised_loss: 0.6882\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7431 - stacked_triplets_loss: 0.6288 - supervised_loss: 0.8574\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5634 - stacked_triplets_loss: 0.5646 - supervised_loss: 0.5632\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5514 - stacked_triplets_loss: 0.4753 - supervised_loss: 0.6244\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5957 - stacked_triplets_loss: 0.6585 - supervised_loss: 0.5306\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4308 - stacked_triplets_loss: 0.4894 - supervised_loss: 0.3722\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5740 - stacked_triplets_loss: 0.4753 - supervised_loss: 0.6690\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5502 - stacked_triplets_loss: 0.6077 - supervised_loss: 0.4927\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5019 - stacked_triplets_loss: 0.4290 - supervised_loss: 0.5738\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5813 - stacked_triplets_loss: 0.5595 - supervised_loss: 0.5995\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5833 - stacked_triplets_loss: 0.5577 - supervised_loss: 0.6078\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5273 - stacked_triplets_loss: 0.5120 - supervised_loss: 0.5425\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4328 - stacked_triplets_loss: 0.4076 - supervised_loss: 0.4574\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6583 - stacked_triplets_loss: 0.6028 - supervised_loss: 0.7138\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4291 - stacked_triplets_loss: 0.4588 - supervised_loss: 0.3997\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5981 - stacked_triplets_loss: 0.4445 - supervised_loss: 0.7487\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5226 - stacked_triplets_loss: 0.4576 - supervised_loss: 0.5861\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.5104 - stacked_triplets_loss: 0.4191 - supervised_loss: 0.6017\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5364 - stacked_triplets_loss: 0.5034 - supervised_loss: 0.5666\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5175 - stacked_triplets_loss: 0.4937 - supervised_loss: 0.5414\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4405 - stacked_triplets_loss: 0.4119 - supervised_loss: 0.4684\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4496 - stacked_triplets_loss: 0.4325 - supervised_loss: 0.4653\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5049 - stacked_triplets_loss: 0.4839 - supervised_loss: 0.5249\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5491 - stacked_triplets_loss: 0.4321 - supervised_loss: 0.6647\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5322 - stacked_triplets_loss: 0.5447 - supervised_loss: 0.5197\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3060 - stacked_triplets_loss: 0.3678 - supervised_loss: 0.2452\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5674 - stacked_triplets_loss: 0.4561 - supervised_loss: 0.6753\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4957 - stacked_triplets_loss: 0.4777 - supervised_loss: 0.5104\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5166 - stacked_triplets_loss: 0.4743 - supervised_loss: 0.5580\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.5507 - stacked_triplets_loss: 0.6062 - supervised_loss: 0.4934\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3700 - stacked_triplets_loss: 0.4651 - supervised_loss: 0.2733\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.7034 - stacked_triplets_loss: 0.4975 - supervised_loss: 0.9093\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5031 - stacked_triplets_loss: 0.4234 - supervised_loss: 0.5817\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5600 - stacked_triplets_loss: 0.4825 - supervised_loss: 0.6372\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4942 - stacked_triplets_loss: 0.4649 - supervised_loss: 0.5235\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.4985 - stacked_triplets_loss: 0.4495 - supervised_loss: 0.5463\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4767 - stacked_triplets_loss: 0.4724 - supervised_loss: 0.4792\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3674 - stacked_triplets_loss: 0.3554 - supervised_loss: 0.3786\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4571 - stacked_triplets_loss: 0.3723 - supervised_loss: 0.5394\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.4513 - stacked_triplets_loss: 0.4030 - supervised_loss: 0.4991\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4843 - stacked_triplets_loss: 0.4707 - supervised_loss: 0.4956\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.6324 - stacked_triplets_loss: 0.5525 - supervised_loss: 0.7123\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4416 - stacked_triplets_loss: 0.3482 - supervised_loss: 0.5330\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3164 - stacked_triplets_loss: 0.3652 - supervised_loss: 0.2678\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4735 - stacked_triplets_loss: 0.4183 - supervised_loss: 0.5268\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5399 - stacked_triplets_loss: 0.4682 - supervised_loss: 0.6099\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5297 - stacked_triplets_loss: 0.5152 - supervised_loss: 0.5424\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3460 - stacked_triplets_loss: 0.4083 - supervised_loss: 0.2843\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7985 - stacked_triplets_loss: 0.6020 - supervised_loss: 0.9949\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4336 - stacked_triplets_loss: 0.3606 - supervised_loss: 0.5067\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4848 - stacked_triplets_loss: 0.4532 - supervised_loss: 0.5143\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5138 - stacked_triplets_loss: 0.4309 - supervised_loss: 0.5933\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3001 - stacked_triplets_loss: 0.3484 - supervised_loss: 0.2518\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.6162 - stacked_triplets_loss: 0.4426 - supervised_loss: 0.7899\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4597 - stacked_triplets_loss: 0.4004 - supervised_loss: 0.5194\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5081 - stacked_triplets_loss: 0.4296 - supervised_loss: 0.5865\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3260 - stacked_triplets_loss: 0.3823 - supervised_loss: 0.2703\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4973 - stacked_triplets_loss: 0.3690 - supervised_loss: 0.6222\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4410 - stacked_triplets_loss: 0.4381 - supervised_loss: 0.4422\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5171 - stacked_triplets_loss: 0.4712 - supervised_loss: 0.5638\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4730 - stacked_triplets_loss: 0.4464 - supervised_loss: 0.4980\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3427 - stacked_triplets_loss: 0.2961 - supervised_loss: 0.3893\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4810 - stacked_triplets_loss: 0.4385 - supervised_loss: 0.5207\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4634 - stacked_triplets_loss: 0.4055 - supervised_loss: 0.5204\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4414 - stacked_triplets_loss: 0.3304 - supervised_loss: 0.5516\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.5213 - stacked_triplets_loss: 0.4674 - supervised_loss: 0.5751\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2490 - stacked_triplets_loss: 0.3721 - supervised_loss: 0.1254\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6874 - stacked_triplets_loss: 0.4540 - supervised_loss: 0.9207\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4413 - stacked_triplets_loss: 0.3996 - supervised_loss: 0.4841\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5600 - stacked_triplets_loss: 0.4459 - supervised_loss: 0.6737\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4874 - stacked_triplets_loss: 0.4461 - supervised_loss: 0.5262\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4129 - stacked_triplets_loss: 0.3728 - supervised_loss: 0.4505\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3837 - stacked_triplets_loss: 0.4041 - supervised_loss: 0.3624\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4894 - stacked_triplets_loss: 0.4559 - supervised_loss: 0.5229\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5474 - stacked_triplets_loss: 0.4604 - supervised_loss: 0.6313\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3459 - stacked_triplets_loss: 0.3583 - supervised_loss: 0.3326\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4566 - stacked_triplets_loss: 0.4155 - supervised_loss: 0.4959\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4454 - stacked_triplets_loss: 0.3575 - supervised_loss: 0.5332\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3212 - stacked_triplets_loss: 0.3155 - supervised_loss: 0.3264\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3802 - stacked_triplets_loss: 0.3463 - supervised_loss: 0.4105\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5795 - stacked_triplets_loss: 0.4696 - supervised_loss: 0.6894\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3538 - stacked_triplets_loss: 0.3188 - supervised_loss: 0.3892\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3922 - stacked_triplets_loss: 0.3982 - supervised_loss: 0.3848\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5248 - stacked_triplets_loss: 0.3415 - supervised_loss: 0.7080\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4202 - stacked_triplets_loss: 0.3633 - supervised_loss: 0.4745\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4493 - stacked_triplets_loss: 0.4464 - supervised_loss: 0.4527\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3387 - stacked_triplets_loss: 0.2624 - supervised_loss: 0.4161\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5443 - stacked_triplets_loss: 0.4133 - supervised_loss: 0.6754\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.2753 - stacked_triplets_loss: 0.3194 - supervised_loss: 0.2310\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4949 - stacked_triplets_loss: 0.4318 - supervised_loss: 0.5581\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5392 - stacked_triplets_loss: 0.5039 - supervised_loss: 0.5694\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4381 - stacked_triplets_loss: 0.3281 - supervised_loss: 0.5481\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3033 - stacked_triplets_loss: 0.2880 - supervised_loss: 0.3177\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5024 - stacked_triplets_loss: 0.4030 - supervised_loss: 0.5983\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4818 - stacked_triplets_loss: 0.3863 - supervised_loss: 0.5774\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4377 - stacked_triplets_loss: 0.3145 - supervised_loss: 0.5590\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2962 - stacked_triplets_loss: 0.3385 - supervised_loss: 0.2539\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3910 - stacked_triplets_loss: 0.2580 - supervised_loss: 0.5215\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4630 - stacked_triplets_loss: 0.3350 - supervised_loss: 0.5885\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4064 - stacked_triplets_loss: 0.3761 - supervised_loss: 0.4353\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4243 - stacked_triplets_loss: 0.3497 - supervised_loss: 0.4979\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4755 - stacked_triplets_loss: 0.3726 - supervised_loss: 0.5760\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2463 - stacked_triplets_loss: 0.2904 - supervised_loss: 0.2023\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4404 - stacked_triplets_loss: 0.3175 - supervised_loss: 0.5612\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4354 - stacked_triplets_loss: 0.3228 - supervised_loss: 0.5461\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4050 - stacked_triplets_loss: 0.3353 - supervised_loss: 0.4731\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3233 - stacked_triplets_loss: 0.3412 - supervised_loss: 0.3053\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.6703 - stacked_triplets_loss: 0.3533 - supervised_loss: 0.9872\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4391 - stacked_triplets_loss: 0.2769 - supervised_loss: 0.6012\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4267 - stacked_triplets_loss: 0.3388 - supervised_loss: 0.5146\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4214 - stacked_triplets_loss: 0.3277 - supervised_loss: 0.5128\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4630 - stacked_triplets_loss: 0.3392 - supervised_loss: 0.5843\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3332 - stacked_triplets_loss: 0.2992 - supervised_loss: 0.3674\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5024 - stacked_triplets_loss: 0.3475 - supervised_loss: 0.6551\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2713 - stacked_triplets_loss: 0.2779 - supervised_loss: 0.2646\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4273 - stacked_triplets_loss: 0.3639 - supervised_loss: 0.4908\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3709 - stacked_triplets_loss: 0.2425 - supervised_loss: 0.4957\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3994 - stacked_triplets_loss: 0.2967 - supervised_loss: 0.5021\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4130 - stacked_triplets_loss: 0.3568 - supervised_loss: 0.4691\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3995 - stacked_triplets_loss: 0.3550 - supervised_loss: 0.4411\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3773 - stacked_triplets_loss: 0.2990 - supervised_loss: 0.4557\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3250 - stacked_triplets_loss: 0.2916 - supervised_loss: 0.3590\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4129 - stacked_triplets_loss: 0.3011 - supervised_loss: 0.5228\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4162 - stacked_triplets_loss: 0.3365 - supervised_loss: 0.4938\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4277 - stacked_triplets_loss: 0.3641 - supervised_loss: 0.4910\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3170 - stacked_triplets_loss: 0.3160 - supervised_loss: 0.3181\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5323 - stacked_triplets_loss: 0.3606 - supervised_loss: 0.7003\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3521 - stacked_triplets_loss: 0.2685 - supervised_loss: 0.4356\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3647 - stacked_triplets_loss: 0.3309 - supervised_loss: 0.3989\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3789 - stacked_triplets_loss: 0.3187 - supervised_loss: 0.4372\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4613 - stacked_triplets_loss: 0.3511 - supervised_loss: 0.5680\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3912 - stacked_triplets_loss: 0.2935 - supervised_loss: 0.4868\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3191 - stacked_triplets_loss: 0.2292 - supervised_loss: 0.4082\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3969 - stacked_triplets_loss: 0.2794 - supervised_loss: 0.5143\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4177 - stacked_triplets_loss: 0.2854 - supervised_loss: 0.5471\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2947 - stacked_triplets_loss: 0.3160 - supervised_loss: 0.2728\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4071 - stacked_triplets_loss: 0.2944 - supervised_loss: 0.5187\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4204 - stacked_triplets_loss: 0.3021 - supervised_loss: 0.5373\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2730 - stacked_triplets_loss: 0.2654 - supervised_loss: 0.2799\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4116 - stacked_triplets_loss: 0.3122 - supervised_loss: 0.5110\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4068 - stacked_triplets_loss: 0.3221 - supervised_loss: 0.4892\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4171 - stacked_triplets_loss: 0.3292 - supervised_loss: 0.5050\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4127 - stacked_triplets_loss: 0.3056 - supervised_loss: 0.5179\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3764 - stacked_triplets_loss: 0.2979 - supervised_loss: 0.4539\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4458 - stacked_triplets_loss: 0.4250 - supervised_loss: 0.4667\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2599 - stacked_triplets_loss: 0.2671 - supervised_loss: 0.2536\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4476 - stacked_triplets_loss: 0.3585 - supervised_loss: 0.5341\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4019 - stacked_triplets_loss: 0.2762 - supervised_loss: 0.5262\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3836 - stacked_triplets_loss: 0.2800 - supervised_loss: 0.4865\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2344 - stacked_triplets_loss: 0.2280 - supervised_loss: 0.2409\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5416 - stacked_triplets_loss: 0.2804 - supervised_loss: 0.8029\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3401 - stacked_triplets_loss: 0.2857 - supervised_loss: 0.3948\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3613 - stacked_triplets_loss: 0.2698 - supervised_loss: 0.4528\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4070 - stacked_triplets_loss: 0.3066 - supervised_loss: 0.5055\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3449 - stacked_triplets_loss: 0.2235 - supervised_loss: 0.4652\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3464 - stacked_triplets_loss: 0.2934 - supervised_loss: 0.3994\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3723 - stacked_triplets_loss: 0.2839 - supervised_loss: 0.4581\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3205 - stacked_triplets_loss: 0.2916 - supervised_loss: 0.3495\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3316 - stacked_triplets_loss: 0.2458 - supervised_loss: 0.4164\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3982 - stacked_triplets_loss: 0.2746 - supervised_loss: 0.5197\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3504 - stacked_triplets_loss: 0.2828 - supervised_loss: 0.4164\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4119 - stacked_triplets_loss: 0.3134 - supervised_loss: 0.5094\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3473 - stacked_triplets_loss: 0.3020 - supervised_loss: 0.3915\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4876 - stacked_triplets_loss: 0.2776 - supervised_loss: 0.6976\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2439 - stacked_triplets_loss: 0.2204 - supervised_loss: 0.2671\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3805 - stacked_triplets_loss: 0.2439 - supervised_loss: 0.5160\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3765 - stacked_triplets_loss: 0.3093 - supervised_loss: 0.4438\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4010 - stacked_triplets_loss: 0.2944 - supervised_loss: 0.5039\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.4044 - stacked_triplets_loss: 0.2711 - supervised_loss: 0.5377\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2143 - stacked_triplets_loss: 0.2294 - supervised_loss: 0.1992\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3804 - stacked_triplets_loss: 0.3016 - supervised_loss: 0.4593\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3889 - stacked_triplets_loss: 0.3116 - supervised_loss: 0.4643\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3251 - stacked_triplets_loss: 0.2478 - supervised_loss: 0.4013\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3875 - stacked_triplets_loss: 0.2610 - supervised_loss: 0.5122\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2875 - stacked_triplets_loss: 0.2418 - supervised_loss: 0.3331\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3599 - stacked_triplets_loss: 0.2531 - supervised_loss: 0.4627\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4355 - stacked_triplets_loss: 0.3239 - supervised_loss: 0.5447\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3840 - stacked_triplets_loss: 0.2585 - supervised_loss: 0.5094\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3417 - stacked_triplets_loss: 0.2060 - supervised_loss: 0.4762\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2921 - stacked_triplets_loss: 0.2959 - supervised_loss: 0.2880\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5657 - stacked_triplets_loss: 0.2682 - supervised_loss: 0.8633\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3286 - stacked_triplets_loss: 0.2364 - supervised_loss: 0.4207\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3441 - stacked_triplets_loss: 0.2337 - supervised_loss: 0.4545\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3862 - stacked_triplets_loss: 0.2478 - supervised_loss: 0.5219\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4510 - stacked_triplets_loss: 0.3599 - supervised_loss: 0.5420\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3834 - stacked_triplets_loss: 0.2593 - supervised_loss: 0.5048\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2981 - stacked_triplets_loss: 0.2047 - supervised_loss: 0.3921\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4573 - stacked_triplets_loss: 0.2955 - supervised_loss: 0.6190\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2869 - stacked_triplets_loss: 0.2723 - supervised_loss: 0.3016\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3686 - stacked_triplets_loss: 0.2623 - supervised_loss: 0.4734\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3821 - stacked_triplets_loss: 0.3215 - supervised_loss: 0.4412\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3249 - stacked_triplets_loss: 0.2393 - supervised_loss: 0.4087\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.2539 - stacked_triplets_loss: 0.2500 - supervised_loss: 0.2577\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.4506 - stacked_triplets_loss: 0.2978 - supervised_loss: 0.6035\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4295 - stacked_triplets_loss: 0.2920 - supervised_loss: 0.5646\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3127 - stacked_triplets_loss: 0.2604 - supervised_loss: 0.3649\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3652 - stacked_triplets_loss: 0.2661 - supervised_loss: 0.4633\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3548 - stacked_triplets_loss: 0.2793 - supervised_loss: 0.4287\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2324 - stacked_triplets_loss: 0.2318 - supervised_loss: 0.2326\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.4942 - stacked_triplets_loss: 0.2518 - supervised_loss: 0.7365\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3707 - stacked_triplets_loss: 0.2684 - supervised_loss: 0.4738\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3958 - stacked_triplets_loss: 0.2318 - supervised_loss: 0.5578\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3577 - stacked_triplets_loss: 0.2021 - supervised_loss: 0.5111\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3282 - stacked_triplets_loss: 0.2148 - supervised_loss: 0.4408\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2434 - stacked_triplets_loss: 0.2532 - supervised_loss: 0.2337\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4356 - stacked_triplets_loss: 0.2594 - supervised_loss: 0.6091\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3105 - stacked_triplets_loss: 0.2360 - supervised_loss: 0.3836\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3474 - stacked_triplets_loss: 0.2203 - supervised_loss: 0.4740\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3372 - stacked_triplets_loss: 0.2221 - supervised_loss: 0.4515\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2778 - stacked_triplets_loss: 0.2104 - supervised_loss: 0.3434\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3680 - stacked_triplets_loss: 0.2297 - supervised_loss: 0.5035\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3628 - stacked_triplets_loss: 0.2423 - supervised_loss: 0.4808\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2785 - stacked_triplets_loss: 0.1891 - supervised_loss: 0.3678\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3693 - stacked_triplets_loss: 0.2762 - supervised_loss: 0.4615\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2418 - stacked_triplets_loss: 0.2325 - supervised_loss: 0.2512\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.4945 - stacked_triplets_loss: 0.2454 - supervised_loss: 0.7398\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3503 - stacked_triplets_loss: 0.2497 - supervised_loss: 0.4509\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3784 - stacked_triplets_loss: 0.2799 - supervised_loss: 0.4773\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2382 - stacked_triplets_loss: 0.2290 - supervised_loss: 0.2463\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.4572 - stacked_triplets_loss: 0.2330 - supervised_loss: 0.6778\n",
      "745/745 [==============================] - 2s 3ms/sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ivis = Ivis(embedding_dims=3, k=7)\n",
    "x_red = ivis.fit_transform(np.array(x), np.array(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_red, y)\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87       143\n",
      "           1       0.56      0.23      0.32        44\n",
      "\n",
      "    accuracy                           0.78       187\n",
      "   macro avg       0.68      0.59      0.59       187\n",
      "weighted avg       0.74      0.78      0.74       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further experiments on the best results above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression? LipschitzLR? Lesser extent of oversampling? Parabola?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression: ivis (dims=3, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 745/745 [00:00<00:00, 46349.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building KNN index\n",
      "Extracting KNN from index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 745/745 [00:00<00:00, 3839.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network\n",
      "Epoch 1/1000\n",
      "5/5 [==============================] - 10s 2s/step - loss: 12.2807 - stacked_triplets_loss: 13.8482 - supervised_loss: 10.7132\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 22.6190 - stacked_triplets_loss: 9.9997 - supervised_loss: 34.7341\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 9.7758 - stacked_triplets_loss: 11.5113 - supervised_loss: 8.0139\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 7.9252 - stacked_triplets_loss: 5.8900 - supervised_loss: 9.9604\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 6.6583 - stacked_triplets_loss: 7.2729 - supervised_loss: 6.0358\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9117 - stacked_triplets_loss: 6.2213 - supervised_loss: 5.5671\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 5.5154 - stacked_triplets_loss: 6.0590 - supervised_loss: 4.9717\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 5.1788 - stacked_triplets_loss: 6.7491 - supervised_loss: 3.5815\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 5.2302 - stacked_triplets_loss: 6.9701 - supervised_loss: 3.4552\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2.2248 - stacked_triplets_loss: 2.7696 - supervised_loss: 1.6956\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 4.9939 - stacked_triplets_loss: 6.2757 - supervised_loss: 3.7122\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2715 - stacked_triplets_loss: 4.7498 - supervised_loss: 3.8010\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.6539 - stacked_triplets_loss: 4.1208 - supervised_loss: 3.1789\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 3.6353 - stacked_triplets_loss: 3.7889 - supervised_loss: 3.4751\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.9168 - stacked_triplets_loss: 3.6214 - supervised_loss: 2.2027\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 3.2329 - stacked_triplets_loss: 4.8773 - supervised_loss: 1.5885\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 3.5270 - stacked_triplets_loss: 5.0512 - supervised_loss: 1.9964\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.9600 - stacked_triplets_loss: 2.2776 - supervised_loss: 1.6407\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 1.6593 - stacked_triplets_loss: 2.5376 - supervised_loss: 0.7795\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 2.9744 - stacked_triplets_loss: 3.1264 - supervised_loss: 2.8049\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2.7378 - stacked_triplets_loss: 3.2550 - supervised_loss: 2.2206\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.6545 - stacked_triplets_loss: 3.5835 - supervised_loss: 1.7094\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.6251 - stacked_triplets_loss: 2.2607 - supervised_loss: 0.9899\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8930 - stacked_triplets_loss: 2.9755 - supervised_loss: 2.7923\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.1970 - stacked_triplets_loss: 2.8226 - supervised_loss: 1.5615\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 2.3118 - stacked_triplets_loss: 3.1244 - supervised_loss: 1.4928\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.6847 - stacked_triplets_loss: 2.6202 - supervised_loss: 0.7491\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 3.5599 - stacked_triplets_loss: 3.2907 - supervised_loss: 3.8015\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 2.2354 - stacked_triplets_loss: 2.4473 - supervised_loss: 2.0290\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.2780 - stacked_triplets_loss: 2.5913 - supervised_loss: 1.9648\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.5794 - stacked_triplets_loss: 1.8991 - supervised_loss: 1.2552\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 2.1660 - stacked_triplets_loss: 2.4700 - supervised_loss: 1.8627\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.6797 - stacked_triplets_loss: 1.9567 - supervised_loss: 1.4027\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.8879 - stacked_triplets_loss: 2.1183 - supervised_loss: 1.6505\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.9103 - stacked_triplets_loss: 1.2028 - supervised_loss: 0.6131\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7623 - stacked_triplets_loss: 1.7329 - supervised_loss: 1.7917\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.6048 - stacked_triplets_loss: 1.6683 - supervised_loss: 1.5411\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.2889 - stacked_triplets_loss: 1.2545 - supervised_loss: 1.3234\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.3175 - stacked_triplets_loss: 1.5216 - supervised_loss: 1.1106\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.2315 - stacked_triplets_loss: 1.1594 - supervised_loss: 1.3014\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.9216 - stacked_triplets_loss: 0.9505 - supervised_loss: 0.8903\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.4922 - stacked_triplets_loss: 1.5512 - supervised_loss: 1.4220\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.2239 - stacked_triplets_loss: 1.3440 - supervised_loss: 1.1029\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.3041 - stacked_triplets_loss: 1.5609 - supervised_loss: 1.0447\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7736 - stacked_triplets_loss: 0.5878 - supervised_loss: 0.9593\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.3688 - stacked_triplets_loss: 1.6532 - supervised_loss: 1.0677\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.2019 - stacked_triplets_loss: 1.2388 - supervised_loss: 1.1650\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2650 - stacked_triplets_loss: 1.5123 - supervised_loss: 1.0143\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7680 - stacked_triplets_loss: 0.8251 - supervised_loss: 0.7091\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.8323 - stacked_triplets_loss: 1.7385 - supervised_loss: 1.9112\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.2652 - stacked_triplets_loss: 1.3777 - supervised_loss: 1.1545\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.1871 - stacked_triplets_loss: 1.4200 - supervised_loss: 0.9543\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7144 - stacked_triplets_loss: 0.7771 - supervised_loss: 0.6525\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.0809 - stacked_triplets_loss: 1.1216 - supervised_loss: 1.0452\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.0455 - stacked_triplets_loss: 0.9263 - supervised_loss: 1.1564\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6705 - stacked_triplets_loss: 0.5980 - supervised_loss: 0.7435\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.1902 - stacked_triplets_loss: 1.4631 - supervised_loss: 0.9173\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0656 - stacked_triplets_loss: 1.3183 - supervised_loss: 0.8107\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7591 - stacked_triplets_loss: 0.9807 - supervised_loss: 0.5394\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.9866 - stacked_triplets_loss: 0.9101 - supervised_loss: 1.0631\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.2130 - stacked_triplets_loss: 1.1950 - supervised_loss: 1.2309\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9462 - stacked_triplets_loss: 1.1267 - supervised_loss: 0.7646\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.8375 - stacked_triplets_loss: 0.8642 - supervised_loss: 0.8132\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9014 - stacked_triplets_loss: 1.0094 - supervised_loss: 0.7935\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1.0572 - stacked_triplets_loss: 1.1451 - supervised_loss: 0.9638\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.9910 - stacked_triplets_loss: 1.1269 - supervised_loss: 0.8574\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.8401 - stacked_triplets_loss: 0.7974 - supervised_loss: 0.8828\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.9819 - stacked_triplets_loss: 1.1372 - supervised_loss: 0.8259\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7435 - stacked_triplets_loss: 0.9063 - supervised_loss: 0.5849\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7821 - stacked_triplets_loss: 0.8694 - supervised_loss: 0.6876\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.0375 - stacked_triplets_loss: 1.2131 - supervised_loss: 0.8619\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.7755 - stacked_triplets_loss: 0.9026 - supervised_loss: 0.6471\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.7372 - stacked_triplets_loss: 0.6907 - supervised_loss: 0.7807\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7589 - stacked_triplets_loss: 0.9267 - supervised_loss: 0.5950\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0856 - stacked_triplets_loss: 1.1219 - supervised_loss: 1.0493\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.9269 - stacked_triplets_loss: 1.1523 - supervised_loss: 0.7038\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8218 - stacked_triplets_loss: 0.7837 - supervised_loss: 0.8633\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.8136 - stacked_triplets_loss: 0.8577 - supervised_loss: 0.7663\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8169 - stacked_triplets_loss: 0.9558 - supervised_loss: 0.6742\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7821 - stacked_triplets_loss: 0.6242 - supervised_loss: 0.9352\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7453 - stacked_triplets_loss: 0.8932 - supervised_loss: 0.5982\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5780 - stacked_triplets_loss: 0.6975 - supervised_loss: 0.4579\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8600 - stacked_triplets_loss: 0.8246 - supervised_loss: 0.8953\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9136 - stacked_triplets_loss: 0.9114 - supervised_loss: 0.9102\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.6891 - stacked_triplets_loss: 0.6991 - supervised_loss: 0.6760\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.8601 - stacked_triplets_loss: 0.8962 - supervised_loss: 0.8229\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4038 - stacked_triplets_loss: 0.3825 - supervised_loss: 0.4245\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.8575 - stacked_triplets_loss: 0.8385 - supervised_loss: 0.8764\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.9142 - stacked_triplets_loss: 0.9465 - supervised_loss: 0.8779\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6060 - stacked_triplets_loss: 0.5386 - supervised_loss: 0.6704\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.7216 - stacked_triplets_loss: 0.6913 - supervised_loss: 0.7483\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.8500 - stacked_triplets_loss: 1.0033 - supervised_loss: 0.6938\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6536 - stacked_triplets_loss: 0.6523 - supervised_loss: 0.6549\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4950 - stacked_triplets_loss: 0.6586 - supervised_loss: 0.3340\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.8617 - stacked_triplets_loss: 0.8501 - supervised_loss: 0.8661\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7260 - stacked_triplets_loss: 0.7537 - supervised_loss: 0.6982\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7123 - stacked_triplets_loss: 0.7113 - supervised_loss: 0.7150\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7468 - stacked_triplets_loss: 0.8174 - supervised_loss: 0.6731\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4549 - stacked_triplets_loss: 0.5611 - supervised_loss: 0.3468\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6974 - stacked_triplets_loss: 0.5918 - supervised_loss: 0.8031\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6847 - stacked_triplets_loss: 0.6230 - supervised_loss: 0.7444\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6735 - stacked_triplets_loss: 0.6034 - supervised_loss: 0.7416\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6112 - stacked_triplets_loss: 0.5510 - supervised_loss: 0.6713\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5969 - stacked_triplets_loss: 0.5793 - supervised_loss: 0.6121\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6543 - stacked_triplets_loss: 0.7396 - supervised_loss: 0.5685\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4451 - stacked_triplets_loss: 0.4631 - supervised_loss: 0.4265\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.7439 - stacked_triplets_loss: 0.5760 - supervised_loss: 0.9118\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6112 - stacked_triplets_loss: 0.5299 - supervised_loss: 0.6872\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.4645 - stacked_triplets_loss: 0.4252 - supervised_loss: 0.5044\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.7692 - stacked_triplets_loss: 0.7845 - supervised_loss: 0.7522\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4077 - stacked_triplets_loss: 0.4165 - supervised_loss: 0.3990\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.8174 - stacked_triplets_loss: 0.6121 - supervised_loss: 1.0166\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4890 - stacked_triplets_loss: 0.4391 - supervised_loss: 0.5405\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5780 - stacked_triplets_loss: 0.5121 - supervised_loss: 0.6405\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6468 - stacked_triplets_loss: 0.5216 - supervised_loss: 0.7692\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3367 - stacked_triplets_loss: 0.4368 - supervised_loss: 0.2364\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6553 - stacked_triplets_loss: 0.4172 - supervised_loss: 0.8933\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5250 - stacked_triplets_loss: 0.4753 - supervised_loss: 0.5749\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4880 - stacked_triplets_loss: 0.4184 - supervised_loss: 0.5588\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6534 - stacked_triplets_loss: 0.6098 - supervised_loss: 0.6970\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.5431 - stacked_triplets_loss: 0.4184 - supervised_loss: 0.6656\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.4012 - stacked_triplets_loss: 0.3992 - supervised_loss: 0.4033\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7819 - stacked_triplets_loss: 0.5895 - supervised_loss: 0.9693\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4401 - stacked_triplets_loss: 0.4568 - supervised_loss: 0.4245\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.6143 - stacked_triplets_loss: 0.5526 - supervised_loss: 0.6715\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6011 - stacked_triplets_loss: 0.4928 - supervised_loss: 0.7094\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5669 - stacked_triplets_loss: 0.5568 - supervised_loss: 0.5770\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5506 - stacked_triplets_loss: 0.4940 - supervised_loss: 0.6075\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5741 - stacked_triplets_loss: 0.4691 - supervised_loss: 0.6777\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4160 - stacked_triplets_loss: 0.3292 - supervised_loss: 0.5043\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4866 - stacked_triplets_loss: 0.4696 - supervised_loss: 0.5017\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6115 - stacked_triplets_loss: 0.4051 - supervised_loss: 0.8154\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3265 - stacked_triplets_loss: 0.3433 - supervised_loss: 0.3090\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6587 - stacked_triplets_loss: 0.5730 - supervised_loss: 0.7413\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4857 - stacked_triplets_loss: 0.4189 - supervised_loss: 0.5526\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3766 - stacked_triplets_loss: 0.3645 - supervised_loss: 0.3881\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.8360 - stacked_triplets_loss: 0.5293 - supervised_loss: 1.1427\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3743 - stacked_triplets_loss: 0.3205 - supervised_loss: 0.4293\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4456 - stacked_triplets_loss: 0.3569 - supervised_loss: 0.5348\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6381 - stacked_triplets_loss: 0.4224 - supervised_loss: 0.8512\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4800 - stacked_triplets_loss: 0.4154 - supervised_loss: 0.5439\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3186 - stacked_triplets_loss: 0.3816 - supervised_loss: 0.2539\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4771 - stacked_triplets_loss: 0.3350 - supervised_loss: 0.6192\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.5852 - stacked_triplets_loss: 0.5793 - supervised_loss: 0.5886\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5399 - stacked_triplets_loss: 0.5390 - supervised_loss: 0.5408\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5384 - stacked_triplets_loss: 0.4566 - supervised_loss: 0.6205\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4829 - stacked_triplets_loss: 0.4649 - supervised_loss: 0.5009\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3624 - stacked_triplets_loss: 0.2801 - supervised_loss: 0.4447\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5287 - stacked_triplets_loss: 0.4232 - supervised_loss: 0.6314\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5457 - stacked_triplets_loss: 0.5151 - supervised_loss: 0.5760\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5361 - stacked_triplets_loss: 0.5046 - supervised_loss: 0.5681\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3584 - stacked_triplets_loss: 0.4055 - supervised_loss: 0.3126\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.6819 - stacked_triplets_loss: 0.4594 - supervised_loss: 0.9045\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3823 - stacked_triplets_loss: 0.4050 - supervised_loss: 0.3589\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5003 - stacked_triplets_loss: 0.4398 - supervised_loss: 0.5576\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.4583 - stacked_triplets_loss: 0.3512 - supervised_loss: 0.5655\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3416 - stacked_triplets_loss: 0.3817 - supervised_loss: 0.3011\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5482 - stacked_triplets_loss: 0.4210 - supervised_loss: 0.6719\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.5197 - stacked_triplets_loss: 0.4252 - supervised_loss: 0.6129\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4295 - stacked_triplets_loss: 0.3615 - supervised_loss: 0.4964\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3998 - stacked_triplets_loss: 0.2685 - supervised_loss: 0.5311\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5450 - stacked_triplets_loss: 0.4481 - supervised_loss: 0.6405\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3134 - stacked_triplets_loss: 0.3301 - supervised_loss: 0.2979\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4444 - stacked_triplets_loss: 0.3286 - supervised_loss: 0.5587\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4325 - stacked_triplets_loss: 0.3268 - supervised_loss: 0.5367\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4369 - stacked_triplets_loss: 0.3604 - supervised_loss: 0.5130\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4386 - stacked_triplets_loss: 0.3966 - supervised_loss: 0.4805\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3703 - stacked_triplets_loss: 0.2984 - supervised_loss: 0.4401\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3723 - stacked_triplets_loss: 0.3019 - supervised_loss: 0.4419\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4273 - stacked_triplets_loss: 0.2644 - supervised_loss: 0.5901\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3851 - stacked_triplets_loss: 0.3408 - supervised_loss: 0.4265\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3267 - stacked_triplets_loss: 0.2777 - supervised_loss: 0.3751\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4620 - stacked_triplets_loss: 0.3690 - supervised_loss: 0.5551\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.4568 - stacked_triplets_loss: 0.3795 - supervised_loss: 0.5306\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4583 - stacked_triplets_loss: 0.3286 - supervised_loss: 0.5879\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4343 - stacked_triplets_loss: 0.3424 - supervised_loss: 0.5229\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4234 - stacked_triplets_loss: 0.2890 - supervised_loss: 0.5579\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2827 - stacked_triplets_loss: 0.2491 - supervised_loss: 0.3162\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.5648 - stacked_triplets_loss: 0.4316 - supervised_loss: 0.6980\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3271 - stacked_triplets_loss: 0.2692 - supervised_loss: 0.3845\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2866 - stacked_triplets_loss: 0.2540 - supervised_loss: 0.3181\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6847 - stacked_triplets_loss: 0.4242 - supervised_loss: 0.9452\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3531 - stacked_triplets_loss: 0.2624 - supervised_loss: 0.4428\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3214 - stacked_triplets_loss: 0.2582 - supervised_loss: 0.3840\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4079 - stacked_triplets_loss: 0.3274 - supervised_loss: 0.4862\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3757 - stacked_triplets_loss: 0.2577 - supervised_loss: 0.4937\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4322 - stacked_triplets_loss: 0.3915 - supervised_loss: 0.4713\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3704 - stacked_triplets_loss: 0.2842 - supervised_loss: 0.4567\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3833 - stacked_triplets_loss: 0.2303 - supervised_loss: 0.5333\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2619 - stacked_triplets_loss: 0.2522 - supervised_loss: 0.2716\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4705 - stacked_triplets_loss: 0.3029 - supervised_loss: 0.6347\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4543 - stacked_triplets_loss: 0.2784 - supervised_loss: 0.6294\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3772 - stacked_triplets_loss: 0.3158 - supervised_loss: 0.4379\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4057 - stacked_triplets_loss: 0.2976 - supervised_loss: 0.5131\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4095 - stacked_triplets_loss: 0.2758 - supervised_loss: 0.5431\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4181 - stacked_triplets_loss: 0.3142 - supervised_loss: 0.5198\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3692 - stacked_triplets_loss: 0.2534 - supervised_loss: 0.4828\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3024 - stacked_triplets_loss: 0.2278 - supervised_loss: 0.3768\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3914 - stacked_triplets_loss: 0.3137 - supervised_loss: 0.4671\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3534 - stacked_triplets_loss: 0.2552 - supervised_loss: 0.4497\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2995 - stacked_triplets_loss: 0.2156 - supervised_loss: 0.3833\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5273 - stacked_triplets_loss: 0.3804 - supervised_loss: 0.6667\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3146 - stacked_triplets_loss: 0.2977 - supervised_loss: 0.3315\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3686 - stacked_triplets_loss: 0.2767 - supervised_loss: 0.4602\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3865 - stacked_triplets_loss: 0.2884 - supervised_loss: 0.4847\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3552 - stacked_triplets_loss: 0.1964 - supervised_loss: 0.5121\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3110 - stacked_triplets_loss: 0.3406 - supervised_loss: 0.2825\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.5517 - stacked_triplets_loss: 0.3392 - supervised_loss: 0.7598\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2684 - stacked_triplets_loss: 0.2548 - supervised_loss: 0.2816\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.4311 - stacked_triplets_loss: 0.3556 - supervised_loss: 0.5057\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4668 - stacked_triplets_loss: 0.3585 - supervised_loss: 0.5761\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2610 - stacked_triplets_loss: 0.2523 - supervised_loss: 0.2698\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4414 - stacked_triplets_loss: 0.2625 - supervised_loss: 0.6142\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4913 - stacked_triplets_loss: 0.2938 - supervised_loss: 0.6861\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3066 - stacked_triplets_loss: 0.2664 - supervised_loss: 0.3468\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3744 - stacked_triplets_loss: 0.2991 - supervised_loss: 0.4482\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2584 - stacked_triplets_loss: 0.2313 - supervised_loss: 0.2843\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5637 - stacked_triplets_loss: 0.2721 - supervised_loss: 0.8510\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3682 - stacked_triplets_loss: 0.2821 - supervised_loss: 0.4544\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.2925 - stacked_triplets_loss: 0.2232 - supervised_loss: 0.3620\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4021 - stacked_triplets_loss: 0.2251 - supervised_loss: 0.5774\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3848 - stacked_triplets_loss: 0.3690 - supervised_loss: 0.3985\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3631 - stacked_triplets_loss: 0.2149 - supervised_loss: 0.5089\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3707 - stacked_triplets_loss: 0.2503 - supervised_loss: 0.4911\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.4195 - stacked_triplets_loss: 0.3267 - supervised_loss: 0.5116\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3245 - stacked_triplets_loss: 0.2661 - supervised_loss: 0.3825\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3426 - stacked_triplets_loss: 0.2336 - supervised_loss: 0.4484\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3971 - stacked_triplets_loss: 0.2815 - supervised_loss: 0.5127\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3068 - stacked_triplets_loss: 0.2900 - supervised_loss: 0.3233\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4616 - stacked_triplets_loss: 0.3000 - supervised_loss: 0.6207\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2798 - stacked_triplets_loss: 0.2681 - supervised_loss: 0.2918\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5173 - stacked_triplets_loss: 0.2934 - supervised_loss: 0.7413\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2802 - stacked_triplets_loss: 0.1949 - supervised_loss: 0.3646\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4501 - stacked_triplets_loss: 0.2990 - supervised_loss: 0.5990\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3391 - stacked_triplets_loss: 0.2428 - supervised_loss: 0.4336\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3779 - stacked_triplets_loss: 0.2363 - supervised_loss: 0.5195\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.2775 - stacked_triplets_loss: 0.2324 - supervised_loss: 0.3217\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3621 - stacked_triplets_loss: 0.3031 - supervised_loss: 0.4201\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4678 - stacked_triplets_loss: 0.2848 - supervised_loss: 0.6471\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2939 - stacked_triplets_loss: 0.2466 - supervised_loss: 0.3419\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2549 - stacked_triplets_loss: 0.2472 - supervised_loss: 0.2625\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4313 - stacked_triplets_loss: 0.3013 - supervised_loss: 0.5588\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4328 - stacked_triplets_loss: 0.2862 - supervised_loss: 0.5794\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3904 - stacked_triplets_loss: 0.2607 - supervised_loss: 0.5204\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3335 - stacked_triplets_loss: 0.2169 - supervised_loss: 0.4512\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3623 - stacked_triplets_loss: 0.2225 - supervised_loss: 0.5005\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4268 - stacked_triplets_loss: 0.2893 - supervised_loss: 0.5616\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3246 - stacked_triplets_loss: 0.2456 - supervised_loss: 0.4036\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3415 - stacked_triplets_loss: 0.2375 - supervised_loss: 0.4472\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.3627 - stacked_triplets_loss: 0.2559 - supervised_loss: 0.4677\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4164 - stacked_triplets_loss: 0.2213 - supervised_loss: 0.6083\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3554 - stacked_triplets_loss: 0.2255 - supervised_loss: 0.4844\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3672 - stacked_triplets_loss: 0.2297 - supervised_loss: 0.5046\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3365 - stacked_triplets_loss: 0.1820 - supervised_loss: 0.4883\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.2923 - stacked_triplets_loss: 0.2800 - supervised_loss: 0.3047\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3738 - stacked_triplets_loss: 0.2070 - supervised_loss: 0.5378\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3122 - stacked_triplets_loss: 0.1952 - supervised_loss: 0.4287\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.3697 - stacked_triplets_loss: 0.2567 - supervised_loss: 0.4806\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3713 - stacked_triplets_loss: 0.2303 - supervised_loss: 0.5111\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3383 - stacked_triplets_loss: 0.2086 - supervised_loss: 0.4676\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.3770 - stacked_triplets_loss: 0.3578 - supervised_loss: 0.3963\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2172 - stacked_triplets_loss: 0.1895 - supervised_loss: 0.2439\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5131 - stacked_triplets_loss: 0.2906 - supervised_loss: 0.7356\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3543 - stacked_triplets_loss: 0.1939 - supervised_loss: 0.5133\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3938 - stacked_triplets_loss: 0.2940 - supervised_loss: 0.4936\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3055 - stacked_triplets_loss: 0.1750 - supervised_loss: 0.4361\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1952 - stacked_triplets_loss: 0.1706 - supervised_loss: 0.2196\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4241 - stacked_triplets_loss: 0.2297 - supervised_loss: 0.6186\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3363 - stacked_triplets_loss: 0.2489 - supervised_loss: 0.4221\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.3657 - stacked_triplets_loss: 0.2480 - supervised_loss: 0.4814\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3415 - stacked_triplets_loss: 0.2228 - supervised_loss: 0.4588\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3550 - stacked_triplets_loss: 0.2571 - supervised_loss: 0.4529\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3944 - stacked_triplets_loss: 0.2405 - supervised_loss: 0.5474\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.2090 - stacked_triplets_loss: 0.2386 - supervised_loss: 0.1785\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4167 - stacked_triplets_loss: 0.2236 - supervised_loss: 0.6097\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3740 - stacked_triplets_loss: 0.2291 - supervised_loss: 0.5165\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3854 - stacked_triplets_loss: 0.1972 - supervised_loss: 0.5728\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.2739 - stacked_triplets_loss: 0.2052 - supervised_loss: 0.3426\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4381 - stacked_triplets_loss: 0.2500 - supervised_loss: 0.6200\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2005 - stacked_triplets_loss: 0.1658 - supervised_loss: 0.2353\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4175 - stacked_triplets_loss: 0.2680 - supervised_loss: 0.5643\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3429 - stacked_triplets_loss: 0.2259 - supervised_loss: 0.4582\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3001 - stacked_triplets_loss: 0.2251 - supervised_loss: 0.3743\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3833 - stacked_triplets_loss: 0.2299 - supervised_loss: 0.5368\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4057 - stacked_triplets_loss: 0.2861 - supervised_loss: 0.5229\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.2566 - stacked_triplets_loss: 0.2240 - supervised_loss: 0.2882\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.3788 - stacked_triplets_loss: 0.2547 - supervised_loss: 0.5023\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.3748 - stacked_triplets_loss: 0.2550 - supervised_loss: 0.4946\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.3454 - stacked_triplets_loss: 0.2083 - supervised_loss: 0.4813\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3364 - stacked_triplets_loss: 0.2221 - supervised_loss: 0.4507\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 68ms/step - loss: 0.3463 - stacked_triplets_loss: 0.2378 - supervised_loss: 0.4531\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.2132 - stacked_triplets_loss: 0.1995 - supervised_loss: 0.2269\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4239 - stacked_triplets_loss: 0.1784 - supervised_loss: 0.6663\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3283 - stacked_triplets_loss: 0.1811 - supervised_loss: 0.4743\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.3586 - stacked_triplets_loss: 0.1960 - supervised_loss: 0.5209\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2207 - stacked_triplets_loss: 0.1945 - supervised_loss: 0.2464\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.5968 - stacked_triplets_loss: 0.2667 - supervised_loss: 0.9270\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3567 - stacked_triplets_loss: 0.2012 - supervised_loss: 0.5108\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2611 - stacked_triplets_loss: 0.1726 - supervised_loss: 0.3498\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3532 - stacked_triplets_loss: 0.2545 - supervised_loss: 0.4519\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2063 - stacked_triplets_loss: 0.1775 - supervised_loss: 0.2341\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5614 - stacked_triplets_loss: 0.2567 - supervised_loss: 0.8614\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.2183 - stacked_triplets_loss: 0.1694 - supervised_loss: 0.2675\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3341 - stacked_triplets_loss: 0.2293 - supervised_loss: 0.4375\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3220 - stacked_triplets_loss: 0.1692 - supervised_loss: 0.4735\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3364 - stacked_triplets_loss: 0.2037 - supervised_loss: 0.4692\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3287 - stacked_triplets_loss: 0.2041 - supervised_loss: 0.4532\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2009 - stacked_triplets_loss: 0.1813 - supervised_loss: 0.2210\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3879 - stacked_triplets_loss: 0.2098 - supervised_loss: 0.5660\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3937 - stacked_triplets_loss: 0.2574 - supervised_loss: 0.5244\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3179 - stacked_triplets_loss: 0.1837 - supervised_loss: 0.4521\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.3351 - stacked_triplets_loss: 0.1539 - supervised_loss: 0.5149\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3603 - stacked_triplets_loss: 0.2348 - supervised_loss: 0.4842\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.2756 - stacked_triplets_loss: 0.1510 - supervised_loss: 0.4002\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2545 - stacked_triplets_loss: 0.1661 - supervised_loss: 0.3409\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4440 - stacked_triplets_loss: 0.1843 - supervised_loss: 0.7038\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.2220 - stacked_triplets_loss: 0.1511 - supervised_loss: 0.2928\n",
      "745/745 [==============================] - 3s 5ms/sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ivis = Ivis(embedding_dims=3, k=5)\n",
    "x_red = ivis.fit_transform(np.array(x), np.array(y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_red, y)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       140\n",
      "           1       0.71      0.43      0.53        47\n",
      "\n",
      "    accuracy                           0.81       187\n",
      "   macro avg       0.77      0.68      0.71       187\n",
      "weighted avg       0.80      0.81      0.80       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       140\n",
      "           1       0.67      0.43      0.52        47\n",
      "\n",
      "    accuracy                           0.80       187\n",
      "   macro avg       0.75      0.68      0.70       187\n",
      "weighted avg       0.79      0.80      0.79       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity check with AdaBoost\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "print(classification_report(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LipschitzLR (ivis: dims=3, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "\n",
    "    Kz = 0.\n",
    "    for i in range((len(x_train) - 1) // batch_size + 1):\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        xb = x_train[start_i:end_i]\n",
    "    \n",
    "        activ = np.linalg.norm(func([xb]))\n",
    "        if activ > Kz:\n",
    "            Kz = activ\n",
    "\n",
    "    K_ = ((num_classes - 1) * Kz) / (num_classes * batch_size)\n",
    "    lr = 1 / K_\n",
    "    print('Epoch', epoch + 1, 'LR =', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1 LR = 31.704782892261203\n",
      "558/558 [==============================] - 13s 23ms/step - loss: 2.7242 - acc: 0.7867\n",
      "Epoch 2/100\n",
      "Epoch 2 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 135us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 3/100\n",
      "Epoch 3 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 147us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 4/100\n",
      "Epoch 4 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 140us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 5/100\n",
      "Epoch 5 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 142us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 6/100\n",
      "Epoch 6 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 139us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 7/100\n",
      "Epoch 7 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 148us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 8/100\n",
      "Epoch 8 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 140us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 9/100\n",
      "Epoch 9 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 151us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 10/100\n",
      "Epoch 10 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 138us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 11/100\n",
      "Epoch 11 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 149us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 12/100\n",
      "Epoch 12 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 140us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 13/100\n",
      "Epoch 13 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 157us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 14/100\n",
      "Epoch 14 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 150us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 15/100\n",
      "Epoch 15 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 158us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 16/100\n",
      "Epoch 16 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 157us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 17/100\n",
      "Epoch 17 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 18/100\n",
      "Epoch 18 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 133us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 19/100\n",
      "Epoch 19 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 145us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 20/100\n",
      "Epoch 20 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 157us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 21/100\n",
      "Epoch 21 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 151us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 22/100\n",
      "Epoch 22 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 147us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 23/100\n",
      "Epoch 23 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 177us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 24/100\n",
      "Epoch 24 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 180us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 25/100\n",
      "Epoch 25 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 148us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 26/100\n",
      "Epoch 26 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 164us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 27/100\n",
      "Epoch 27 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 152us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 28/100\n",
      "Epoch 28 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 157us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 29/100\n",
      "Epoch 29 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 156us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 30/100\n",
      "Epoch 30 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 156us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 31/100\n",
      "Epoch 31 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 155us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 32/100\n",
      "Epoch 32 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 145us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 33/100\n",
      "Epoch 33 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 153us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 34/100\n",
      "Epoch 34 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 152us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 35/100\n",
      "Epoch 35 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 152us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 36/100\n",
      "Epoch 36 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 154us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 37/100\n",
      "Epoch 37 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 132us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 38/100\n",
      "Epoch 38 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 148us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 39/100\n",
      "Epoch 39 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 151us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 40/100\n",
      "Epoch 40 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 150us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 41/100\n",
      "Epoch 41 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 160us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 42/100\n",
      "Epoch 42 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 148us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 43/100\n",
      "Epoch 43 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 129us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 44/100\n",
      "Epoch 44 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 138us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 45/100\n",
      "Epoch 45 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 160us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 46/100\n",
      "Epoch 46 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 158us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 47/100\n",
      "Epoch 47 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 158us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 48/100\n",
      "Epoch 48 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 160us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 49/100\n",
      "Epoch 49 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 140us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 50/100\n",
      "Epoch 50 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 139us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 51/100\n",
      "Epoch 51 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 139us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 52/100\n",
      "Epoch 52 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 146us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 53/100\n",
      "Epoch 53 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 54/100\n",
      "Epoch 54 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 146us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 55/100\n",
      "Epoch 55 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 147us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 56/100\n",
      "Epoch 56 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 136us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 57/100\n",
      "Epoch 57 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 146us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 58/100\n",
      "Epoch 58 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 145us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 59/100\n",
      "Epoch 59 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 132us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 60/100\n",
      "Epoch 60 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 144us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 61/100\n",
      "Epoch 61 LR = 0.0005500884694285244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 0s 139us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 62/100\n",
      "Epoch 62 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 139us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 63/100\n",
      "Epoch 63 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 155us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 64/100\n",
      "Epoch 64 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 143us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 65/100\n",
      "Epoch 65 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 66/100\n",
      "Epoch 66 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 157us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 67/100\n",
      "Epoch 67 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 147us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 68/100\n",
      "Epoch 68 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 140us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 69/100\n",
      "Epoch 69 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 136us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 70/100\n",
      "Epoch 70 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 136us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 71/100\n",
      "Epoch 71 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 135us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 72/100\n",
      "Epoch 72 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 144us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 73/100\n",
      "Epoch 73 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 145us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 74/100\n",
      "Epoch 74 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 143us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 75/100\n",
      "Epoch 75 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 135us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 76/100\n",
      "Epoch 76 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 139us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 77/100\n",
      "Epoch 77 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 144us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 78/100\n",
      "Epoch 78 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 79/100\n",
      "Epoch 79 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 143us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 80/100\n",
      "Epoch 80 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 134us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 81/100\n",
      "Epoch 81 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 142us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 82/100\n",
      "Epoch 82 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 150us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 83/100\n",
      "Epoch 83 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 84/100\n",
      "Epoch 84 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 143us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 85/100\n",
      "Epoch 85 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 86/100\n",
      "Epoch 86 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 162us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 87/100\n",
      "Epoch 87 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 88/100\n",
      "Epoch 88 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 137us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 89/100\n",
      "Epoch 89 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 152us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 90/100\n",
      "Epoch 90 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 138us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 91/100\n",
      "Epoch 91 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 142us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 92/100\n",
      "Epoch 92 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 131us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 93/100\n",
      "Epoch 93 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 189us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 94/100\n",
      "Epoch 94 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 149us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 95/100\n",
      "Epoch 95 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 133us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 96/100\n",
      "Epoch 96 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 144us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 97/100\n",
      "Epoch 97 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 137us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 98/100\n",
      "Epoch 98 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 134us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 99/100\n",
      "Epoch 99 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 138us/step - loss: 3.4374 - acc: 0.7867\n",
      "Epoch 100/100\n",
      "Epoch 100 LR = 0.0005500884694285244\n",
      "558/558 [==============================] - 0s 141us/step - loss: 3.4374 - acc: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20254c09d0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(3,)),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('sgd', 'binary_crossentropy', metrics=['accuracy'])\n",
    "func = K.function([model.layers[0].input], [model.layers[-2].output])\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=batch_size, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       140\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.75       187\n",
      "   macro avg       0.37      0.50      0.43       187\n",
      "weighted avg       0.56      0.75      0.64       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LipschitzLR does not help here, possibly. More investigation needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parabolic activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabola(x):\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "558/558 [==============================] - 8s 15ms/step - loss: 3.3577 - acc: 0.7796\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 0s 271us/step - loss: 3.3411 - acc: 0.7796\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 0s 259us/step - loss: 3.3325 - acc: 0.7814\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 3.3286 - acc: 0.7814\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 0s 288us/step - loss: 3.3229 - acc: 0.7849\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 0s 278us/step - loss: 3.3213 - acc: 0.7867\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 3.3198 - acc: 0.7867\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 0s 275us/step - loss: 3.3188 - acc: 0.7867\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 0s 290us/step - loss: 3.3179 - acc: 0.7867\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 0s 319us/step - loss: 3.3172 - acc: 0.7867\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 3.3166 - acc: 0.7867\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 0s 264us/step - loss: 3.3158 - acc: 0.7867\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 3.3130 - acc: 0.7867\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 0s 315us/step - loss: 3.2993 - acc: 0.7867\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 0s 302us/step - loss: 3.2946 - acc: 0.7867\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 0s 276us/step - loss: 3.2910 - acc: 0.7867\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 0s 296us/step - loss: 3.2892 - acc: 0.7867\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 0s 315us/step - loss: 3.2881 - acc: 0.7867\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 0s 296us/step - loss: 3.2873 - acc: 0.7867\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 0s 262us/step - loss: 3.2869 - acc: 0.7867\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 3.2832 - acc: 0.7867\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 0s 283us/step - loss: 3.2615 - acc: 0.7867\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 0s 300us/step - loss: 3.2523 - acc: 0.7867\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 0s 313us/step - loss: 3.4878 - acc: 0.7724\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 0s 303us/step - loss: 3.4052 - acc: 0.7724\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 0s 315us/step - loss: 3.4274 - acc: 0.7706\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 0s 295us/step - loss: 3.1825 - acc: 0.7867\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 0s 320us/step - loss: 3.2007 - acc: 0.7867\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 0s 318us/step - loss: 3.1939 - acc: 0.7867\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 0s 281us/step - loss: 3.1778 - acc: 0.7867\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 3.1907 - acc: 0.7867\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 0s 323us/step - loss: 3.1912 - acc: 0.7867\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 0s 266us/step - loss: 3.1897 - acc: 0.7867\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 0s 262us/step - loss: 3.1883 - acc: 0.7867\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 3.1875 - acc: 0.7867\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 0s 266us/step - loss: 3.1848 - acc: 0.7867\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 0s 269us/step - loss: 3.1650 - acc: 0.7867\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 3.1570 - acc: 0.7867\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 0s 329us/step - loss: 3.1560 - acc: 0.7867\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 0s 314us/step - loss: 3.1555 - acc: 0.7832\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 0s 338us/step - loss: 3.1551 - acc: 0.7832\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 0s 306us/step - loss: 3.1549 - acc: 0.7796\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 0s 334us/step - loss: 3.1547 - acc: 0.7796\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 0s 325us/step - loss: 3.1545 - acc: 0.7814\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 0s 284us/step - loss: 3.1545 - acc: 0.7796\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 0s 328us/step - loss: 3.1541 - acc: 0.7796\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 3.1541 - acc: 0.7796\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 0s 327us/step - loss: 3.1539 - acc: 0.7796\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 0s 317us/step - loss: 3.1538 - acc: 0.7796\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 0s 312us/step - loss: 3.1536 - acc: 0.7796\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 0s 331us/step - loss: 3.4291 - acc: 0.7616\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 0s 288us/step - loss: 3.3880 - acc: 0.7688\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 3.3258 - acc: 0.7706\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 0s 289us/step - loss: 3.2313 - acc: 0.7814\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 0s 321us/step - loss: 3.1877 - acc: 0.7814\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 3.1881 - acc: 0.7832\n",
      "Epoch 57/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 3.1875 - acc: 0.7832\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 0s 285us/step - loss: 3.1866 - acc: 0.7832\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 0s 276us/step - loss: 3.1858 - acc: 0.7832\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 0s 293us/step - loss: 3.1851 - acc: 0.7832\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 3.1843 - acc: 0.7832\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 0s 332us/step - loss: 3.1836 - acc: 0.7832\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 3.1833 - acc: 0.7849\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 3.1827 - acc: 0.7849\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 0s 334us/step - loss: 3.1824 - acc: 0.7867\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 0s 305us/step - loss: 3.1822 - acc: 0.7849\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 3.1820 - acc: 0.7849\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 0s 309us/step - loss: 3.1818 - acc: 0.7849\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 0s 309us/step - loss: 3.1818 - acc: 0.7849\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 3.1816 - acc: 0.7832\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 0s 280us/step - loss: 3.1814 - acc: 0.7849\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 0s 377us/step - loss: 3.1813 - acc: 0.7832\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 0s 287us/step - loss: 3.1810 - acc: 0.7832\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 0s 316us/step - loss: 3.1811 - acc: 0.7832\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 0s 339us/step - loss: 3.1810 - acc: 0.7832\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 3.1809 - acc: 0.7849\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 0s 274us/step - loss: 3.1808 - acc: 0.7849\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 0s 283us/step - loss: 3.1807 - acc: 0.7867\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 0s 273us/step - loss: 3.1806 - acc: 0.7885\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 0s 272us/step - loss: 3.1806 - acc: 0.7885\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 0s 282us/step - loss: 3.1805 - acc: 0.7885\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 0s 338us/step - loss: 3.1805 - acc: 0.7885\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 0s 338us/step - loss: 3.1804 - acc: 0.7885\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 0s 304us/step - loss: 3.1803 - acc: 0.7885\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 0s 335us/step - loss: 3.1802 - acc: 0.7885\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 0s 278us/step - loss: 3.1802 - acc: 0.7885\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 0s 294us/step - loss: 3.1801 - acc: 0.7885\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 0s 286us/step - loss: 3.1802 - acc: 0.7885\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 0s 240us/step - loss: 3.1801 - acc: 0.7867\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 3.1800 - acc: 0.7867\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 0s 302us/step - loss: 3.1800 - acc: 0.7867\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 0s 270us/step - loss: 3.1800 - acc: 0.7867\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 0s 279us/step - loss: 3.1800 - acc: 0.7867\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 0s 332us/step - loss: 3.1798 - acc: 0.7867\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 0s 348us/step - loss: 3.1789 - acc: 0.7867\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 0s 291us/step - loss: 3.1833 - acc: 0.7867\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 0s 303us/step - loss: 3.1832 - acc: 0.7867\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 0s 308us/step - loss: 3.1820 - acc: 0.7867\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 0s 277us/step - loss: 3.1805 - acc: 0.7867\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 0s 268us/step - loss: 3.1803 - acc: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2021a9b950>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(3,)),\n",
    "    Lambda(parabola),\n",
    "    \n",
    "    Dense(3),\n",
    "    Lambda(parabola),\n",
    "    \n",
    "    Dense(3),\n",
    "    Lambda(parabola),\n",
    "    \n",
    "    Dense(1),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parabola didn't work either. Is this a problem with the net itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "558/558 [==============================] - 10s 18ms/step - loss: 1.1632 - acc: 0.4086\n",
      "Epoch 2/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 1.0935 - acc: 0.4427\n",
      "Epoch 3/100\n",
      "558/558 [==============================] - 0s 360us/step - loss: 1.0709 - acc: 0.4265\n",
      "Epoch 4/100\n",
      "558/558 [==============================] - 0s 374us/step - loss: 1.0096 - acc: 0.4462\n",
      "Epoch 5/100\n",
      "558/558 [==============================] - 0s 358us/step - loss: 0.9606 - acc: 0.4624\n",
      "Epoch 6/100\n",
      "558/558 [==============================] - 0s 413us/step - loss: 0.9241 - acc: 0.4534\n",
      "Epoch 7/100\n",
      "558/558 [==============================] - 0s 361us/step - loss: 0.8863 - acc: 0.4659\n",
      "Epoch 8/100\n",
      "558/558 [==============================] - 0s 334us/step - loss: 0.8621 - acc: 0.4713\n",
      "Epoch 9/100\n",
      "558/558 [==============================] - 0s 363us/step - loss: 0.8233 - acc: 0.4910\n",
      "Epoch 10/100\n",
      "558/558 [==============================] - 0s 444us/step - loss: 0.7976 - acc: 0.4982\n",
      "Epoch 11/100\n",
      "558/558 [==============================] - 0s 436us/step - loss: 0.7792 - acc: 0.5323\n",
      "Epoch 12/100\n",
      "558/558 [==============================] - 0s 357us/step - loss: 0.7546 - acc: 0.5556\n",
      "Epoch 13/100\n",
      "558/558 [==============================] - 0s 337us/step - loss: 0.7386 - acc: 0.5538\n",
      "Epoch 14/100\n",
      "558/558 [==============================] - 0s 381us/step - loss: 0.7207 - acc: 0.6004\n",
      "Epoch 15/100\n",
      "558/558 [==============================] - 0s 364us/step - loss: 0.7120 - acc: 0.6129\n",
      "Epoch 16/100\n",
      "558/558 [==============================] - 0s 378us/step - loss: 0.6983 - acc: 0.6380\n",
      "Epoch 17/100\n",
      "558/558 [==============================] - 0s 357us/step - loss: 0.6830 - acc: 0.6595\n",
      "Epoch 18/100\n",
      "558/558 [==============================] - 0s 349us/step - loss: 0.6725 - acc: 0.6720\n",
      "Epoch 19/100\n",
      "558/558 [==============================] - 0s 370us/step - loss: 0.6686 - acc: 0.6900\n",
      "Epoch 20/100\n",
      "558/558 [==============================] - 0s 344us/step - loss: 0.6502 - acc: 0.7258\n",
      "Epoch 21/100\n",
      "558/558 [==============================] - 0s 373us/step - loss: 0.6506 - acc: 0.7186\n",
      "Epoch 22/100\n",
      "558/558 [==============================] - 0s 363us/step - loss: 0.6427 - acc: 0.7097\n",
      "Epoch 23/100\n",
      "558/558 [==============================] - 0s 345us/step - loss: 0.6308 - acc: 0.7509\n",
      "Epoch 24/100\n",
      "558/558 [==============================] - 0s 373us/step - loss: 0.6314 - acc: 0.7348\n",
      "Epoch 25/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 0.6200 - acc: 0.7563\n",
      "Epoch 26/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 0.6166 - acc: 0.7545\n",
      "Epoch 27/100\n",
      "558/558 [==============================] - 0s 384us/step - loss: 0.6100 - acc: 0.7599\n",
      "Epoch 28/100\n",
      "558/558 [==============================] - 0s 424us/step - loss: 0.6032 - acc: 0.7670\n",
      "Epoch 29/100\n",
      "558/558 [==============================] - 0s 382us/step - loss: 0.6014 - acc: 0.7849\n",
      "Epoch 30/100\n",
      "558/558 [==============================] - 0s 411us/step - loss: 0.6006 - acc: 0.7616\n",
      "Epoch 31/100\n",
      "558/558 [==============================] - 0s 430us/step - loss: 0.5971 - acc: 0.7778\n",
      "Epoch 32/100\n",
      "558/558 [==============================] - 0s 446us/step - loss: 0.5918 - acc: 0.7778\n",
      "Epoch 33/100\n",
      "558/558 [==============================] - 0s 432us/step - loss: 0.5860 - acc: 0.7939\n",
      "Epoch 34/100\n",
      "558/558 [==============================] - 0s 404us/step - loss: 0.5849 - acc: 0.7903\n",
      "Epoch 35/100\n",
      "558/558 [==============================] - 0s 352us/step - loss: 0.5810 - acc: 0.7867\n",
      "Epoch 36/100\n",
      "558/558 [==============================] - 0s 364us/step - loss: 0.5763 - acc: 0.7921\n",
      "Epoch 37/100\n",
      "558/558 [==============================] - 0s 431us/step - loss: 0.5798 - acc: 0.7867\n",
      "Epoch 38/100\n",
      "558/558 [==============================] - 0s 431us/step - loss: 0.5756 - acc: 0.7849\n",
      "Epoch 39/100\n",
      "558/558 [==============================] - 0s 346us/step - loss: 0.5714 - acc: 0.7760\n",
      "Epoch 40/100\n",
      "558/558 [==============================] - 0s 350us/step - loss: 0.5685 - acc: 0.7796\n",
      "Epoch 41/100\n",
      "558/558 [==============================] - 0s 348us/step - loss: 0.5682 - acc: 0.7796\n",
      "Epoch 42/100\n",
      "558/558 [==============================] - 0s 446us/step - loss: 0.5617 - acc: 0.7993\n",
      "Epoch 43/100\n",
      "558/558 [==============================] - 0s 456us/step - loss: 0.5616 - acc: 0.7939\n",
      "Epoch 44/100\n",
      "558/558 [==============================] - 0s 363us/step - loss: 0.5566 - acc: 0.7903\n",
      "Epoch 45/100\n",
      "558/558 [==============================] - 0s 362us/step - loss: 0.5532 - acc: 0.7885\n",
      "Epoch 46/100\n",
      "558/558 [==============================] - 0s 473us/step - loss: 0.5538 - acc: 0.7867\n",
      "Epoch 47/100\n",
      "558/558 [==============================] - 0s 376us/step - loss: 0.5510 - acc: 0.7957\n",
      "Epoch 48/100\n",
      "558/558 [==============================] - 0s 333us/step - loss: 0.5480 - acc: 0.7867\n",
      "Epoch 49/100\n",
      "558/558 [==============================] - 0s 331us/step - loss: 0.5450 - acc: 0.7849\n",
      "Epoch 50/100\n",
      "558/558 [==============================] - 0s 297us/step - loss: 0.5412 - acc: 0.7849\n",
      "Epoch 51/100\n",
      "558/558 [==============================] - 0s 427us/step - loss: 0.5371 - acc: 0.7849\n",
      "Epoch 52/100\n",
      "558/558 [==============================] - 0s 359us/step - loss: 0.5352 - acc: 0.7885\n",
      "Epoch 53/100\n",
      "558/558 [==============================] - 0s 353us/step - loss: 0.5369 - acc: 0.7849\n",
      "Epoch 54/100\n",
      "558/558 [==============================] - 0s 404us/step - loss: 0.5295 - acc: 0.7885\n",
      "Epoch 55/100\n",
      "558/558 [==============================] - 0s 385us/step - loss: 0.5248 - acc: 0.7957\n",
      "Epoch 56/100\n",
      "558/558 [==============================] - 0s 373us/step - loss: 0.5238 - acc: 0.7939\n",
      "Epoch 57/100\n",
      "558/558 [==============================] - 0s 371us/step - loss: 0.5222 - acc: 0.7903\n",
      "Epoch 58/100\n",
      "558/558 [==============================] - 0s 389us/step - loss: 0.5188 - acc: 0.7867\n",
      "Epoch 59/100\n",
      "558/558 [==============================] - 0s 379us/step - loss: 0.5147 - acc: 0.7921\n",
      "Epoch 60/100\n",
      "558/558 [==============================] - 0s 428us/step - loss: 0.5124 - acc: 0.7778\n",
      "Epoch 61/100\n",
      "558/558 [==============================] - 0s 394us/step - loss: 0.5099 - acc: 0.7885\n",
      "Epoch 62/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 0.5080 - acc: 0.7885\n",
      "Epoch 63/100\n",
      "558/558 [==============================] - 0s 337us/step - loss: 0.5034 - acc: 0.7814\n",
      "Epoch 64/100\n",
      "558/558 [==============================] - 0s 383us/step - loss: 0.4968 - acc: 0.7903\n",
      "Epoch 65/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 0.4939 - acc: 0.7867\n",
      "Epoch 66/100\n",
      "558/558 [==============================] - 0s 339us/step - loss: 0.4919 - acc: 0.7957\n",
      "Epoch 67/100\n",
      "558/558 [==============================] - 0s 393us/step - loss: 0.4908 - acc: 0.7885\n",
      "Epoch 68/100\n",
      "558/558 [==============================] - 0s 346us/step - loss: 0.4927 - acc: 0.7849\n",
      "Epoch 69/100\n",
      "558/558 [==============================] - 0s 348us/step - loss: 0.4888 - acc: 0.7921\n",
      "Epoch 70/100\n",
      "558/558 [==============================] - 0s 369us/step - loss: 0.4812 - acc: 0.7849\n",
      "Epoch 71/100\n",
      "558/558 [==============================] - 0s 366us/step - loss: 0.4826 - acc: 0.7760\n",
      "Epoch 72/100\n",
      "558/558 [==============================] - 0s 358us/step - loss: 0.4784 - acc: 0.7867\n",
      "Epoch 73/100\n",
      "558/558 [==============================] - 0s 353us/step - loss: 0.4679 - acc: 0.7867\n",
      "Epoch 74/100\n",
      "558/558 [==============================] - 0s 366us/step - loss: 0.4659 - acc: 0.7939\n",
      "Epoch 75/100\n",
      "558/558 [==============================] - 0s 363us/step - loss: 0.4669 - acc: 0.7867\n",
      "Epoch 76/100\n",
      "558/558 [==============================] - 0s 368us/step - loss: 0.4623 - acc: 0.7903\n",
      "Epoch 77/100\n",
      "558/558 [==============================] - 0s 360us/step - loss: 0.4537 - acc: 0.7885\n",
      "Epoch 78/100\n",
      "558/558 [==============================] - 0s 354us/step - loss: 0.4523 - acc: 0.7849\n",
      "Epoch 79/100\n",
      "558/558 [==============================] - 0s 338us/step - loss: 0.4563 - acc: 0.7939\n",
      "Epoch 80/100\n",
      "558/558 [==============================] - 0s 361us/step - loss: 0.4489 - acc: 0.7903\n",
      "Epoch 81/100\n",
      "558/558 [==============================] - 0s 353us/step - loss: 0.4503 - acc: 0.7975\n",
      "Epoch 82/100\n",
      "558/558 [==============================] - 0s 362us/step - loss: 0.4475 - acc: 0.7814\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558/558 [==============================] - 0s 343us/step - loss: 0.4432 - acc: 0.7885\n",
      "Epoch 84/100\n",
      "558/558 [==============================] - 0s 374us/step - loss: 0.4450 - acc: 0.7849\n",
      "Epoch 85/100\n",
      "558/558 [==============================] - 0s 387us/step - loss: 0.4363 - acc: 0.8029\n",
      "Epoch 86/100\n",
      "558/558 [==============================] - 0s 408us/step - loss: 0.4362 - acc: 0.7867\n",
      "Epoch 87/100\n",
      "558/558 [==============================] - 0s 383us/step - loss: 0.4298 - acc: 0.8190\n",
      "Epoch 88/100\n",
      "558/558 [==============================] - 0s 346us/step - loss: 0.4305 - acc: 0.7885\n",
      "Epoch 89/100\n",
      "558/558 [==============================] - 0s 335us/step - loss: 0.4371 - acc: 0.8136\n",
      "Epoch 90/100\n",
      "558/558 [==============================] - 0s 367us/step - loss: 0.4317 - acc: 0.7975\n",
      "Epoch 91/100\n",
      "558/558 [==============================] - 0s 371us/step - loss: 0.4324 - acc: 0.8047\n",
      "Epoch 92/100\n",
      "558/558 [==============================] - 0s 363us/step - loss: 0.4339 - acc: 0.8100\n",
      "Epoch 93/100\n",
      "558/558 [==============================] - 0s 343us/step - loss: 0.4285 - acc: 0.8100\n",
      "Epoch 94/100\n",
      "558/558 [==============================] - 0s 351us/step - loss: 0.4380 - acc: 0.8118\n",
      "Epoch 95/100\n",
      "558/558 [==============================] - 0s 340us/step - loss: 0.4251 - acc: 0.8029\n",
      "Epoch 96/100\n",
      "558/558 [==============================] - 0s 347us/step - loss: 0.4296 - acc: 0.8011\n",
      "Epoch 97/100\n",
      "558/558 [==============================] - 0s 335us/step - loss: 0.4226 - acc: 0.8136\n",
      "Epoch 98/100\n",
      "558/558 [==============================] - 0s 357us/step - loss: 0.4247 - acc: 0.8154 0s - loss: 0.4270 - acc: 0.812\n",
      "Epoch 99/100\n",
      "558/558 [==============================] - 0s 384us/step - loss: 0.4376 - acc: 0.8065\n",
      "Epoch 100/100\n",
      "558/558 [==============================] - 0s 371us/step - loss: 0.4188 - acc: 0.8226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20213fb890>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(3, input_shape=(3,)),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(3),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    \n",
    "    Dense(1),\n",
    "    Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       140\n",
      "           1       0.76      0.47      0.58        47\n",
      "\n",
      "    accuracy                           0.83       187\n",
      "   macro avg       0.80      0.71      0.74       187\n",
      "weighted avg       0.82      0.83      0.81       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict_classes(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So maybe you shouldn't use cleverness here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
